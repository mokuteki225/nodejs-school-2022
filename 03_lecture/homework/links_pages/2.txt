<!DOCTYPE html><html lang="en" data-rh="lang"><head><title>Neural Network Pruning 101. All you need to know not to get lost | by Hugo Tessier | Towards Data Science</title><meta data-rh="true" charset="utf-8"><meta data-rh="true" name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1,maximum-scale=1"><meta data-rh="true" name="theme-color" content="#000000"><meta data-rh="true" name="twitter:app:name:iphone" content="Medium"><meta data-rh="true" name="twitter:app:id:iphone" content="828256236"><meta data-rh="true" property="al:ios:app_name" content="Medium"><meta data-rh="true" property="al:ios:app_store_id" content="828256236"><meta data-rh="true" property="al:android:package" content="com.medium.reader"><meta data-rh="true" property="fb:app_id" content="542599432471018"><meta data-rh="true" property="og:site_name" content="Medium"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2021-09-13T07:52:05.992Z"><meta data-rh="true" name="title" content="Neural Network Pruning 101. All you need to know not to get lost | by Hugo Tessier | Towards Data Science"><meta data-rh="true" property="og:title" content="Neural Network Pruning 101"><meta data-rh="true" property="twitter:title" content="Neural Network Pruning 101"><meta data-rh="true" name="twitter:site" content="@TDataScience"><meta data-rh="true" name="twitter:app:url:iphone" content="medium://p/af816aaea61"><meta data-rh="true" property="al:android:url" content="medium://p/af816aaea61"><meta data-rh="true" property="al:ios:url" content="medium://p/af816aaea61"><meta data-rh="true" property="al:android:app_name" content="Medium"><meta data-rh="true" name="description" content="Whether it is in computer vision, natural language processing or image generation, deep neural networks yield the state of the art. However, their cost in terms of computational power, memory or…"><meta data-rh="true" property="og:description" content="All you need to know not to get lost"><meta data-rh="true" property="twitter:description" content="All you need to know not to get lost"><meta data-rh="true" property="og:url" content="https://towardsdatascience.com/neural-network-pruning-101-af816aaea61"><meta data-rh="true" property="al:web:url" content="https://towardsdatascience.com/neural-network-pruning-101-af816aaea61"><meta data-rh="true" property="og:image" content="https://miro.medium.com/max/1200/1*7qwYH1r-h6VOGiE6C2tpGg.png"><meta data-rh="true" name="twitter:image:src" content="https://miro.medium.com/max/1200/1*7qwYH1r-h6VOGiE6C2tpGg.png"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="article:author" content="https://medium.com/@hugo.tessier"><meta data-rh="true" name="author" content="Hugo Tessier"><meta data-rh="true" name="robots" content="index,follow,max-image-preview:large"><meta data-rh="true" name="referrer" content="unsafe-url"><meta data-rh="true" name="twitter:label1" content="Reading time"><meta data-rh="true" name="twitter:data1" content="22 min read"><link data-rh="true" rel="search" type="application/opensearchdescription+xml" title="Medium" href="/osd.xml"><link data-rh="true" rel="apple-touch-icon" sizes="152x152" href="https://miro.medium.com/fit/c/152/152/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"><link data-rh="true" rel="apple-touch-icon" sizes="120x120" href="https://miro.medium.com/fit/c/120/120/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"><link data-rh="true" rel="apple-touch-icon" sizes="76x76" href="https://miro.medium.com/fit/c/76/76/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"><link data-rh="true" rel="apple-touch-icon" sizes="60x60" href="https://miro.medium.com/fit/c/60/60/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"><link data-rh="true" rel="mask-icon" href="https://cdn-static-1.medium.com/_/fp/icons/Medium-Avatar-500x500.svg" color="#171717"><link data-rh="true" id="glyph_preload_link" rel="preload" as="style" type="text/css" href="https://glyph.medium.com/css/unbound.css"><link data-rh="true" id="glyph_link" rel="stylesheet" type="text/css" href="https://glyph.medium.com/css/unbound.css"><link data-rh="true" rel="author" href="https://medium.com/@hugo.tessier"><link data-rh="true" rel="canonical" href="https://towardsdatascience.com/neural-network-pruning-101-af816aaea61"><link data-rh="true" rel="alternate" href="android-app://com.medium.reader/https/medium.com/p/af816aaea61"><style type="text/css" data-fela-rehydration="537" data-fela-type="STATIC">html{box-sizing:border-box}*, *:before, *:after{box-sizing:inherit}body{margin:0;padding:0;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;color:rgba(0,0,0,0.8);position:relative;min-height:100vh}h1, h2, h3, h4, h5, h6, dl, dd, ol, ul, menu, figure, blockquote, p, pre, form{margin:0}menu, ol, ul{padding:0;list-style:none;list-style-image:none}main{display:block}a{color:inherit;text-decoration:none}a, button, input{-webkit-tap-highlight-color:transparent}img, svg{vertical-align:middle}button{background:transparent;overflow:visible}button, input, optgroup, select, textarea{margin:0}:root{--reach-tabs:1;--reach-menu-button:1}#speechify-root{font-family:Sohne, sans-serif}</style><style type="text/css" data-fela-rehydration="537" data-fela-type="KEYFRAME">@-webkit-keyframes k1{0%{opacity:0;transform:translateY(-60px)}100%{opacity:1;transform:translateY(0px)}}@-moz-keyframes k1{0%{opacity:0;transform:translateY(-60px)}100%{opacity:1;transform:translateY(0px)}}@keyframes k1{0%{opacity:0;transform:translateY(-60px)}100%{opacity:1;transform:translateY(0px)}}@-webkit-keyframes k2{0%{opacity:1;transform:translateY(0px)}100%{opacity:0;transform:translateY(-60px)}}@-moz-keyframes k2{0%{opacity:1;transform:translateY(0px)}100%{opacity:0;transform:translateY(-60px)}}@keyframes k2{0%{opacity:1;transform:translateY(0px)}100%{opacity:0;transform:translateY(-60px)}}@-webkit-keyframes k3{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@-moz-keyframes k3{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@keyframes k3{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}</style><style type="text/css" data-fela-rehydration="537" data-fela-type="RULE">.a{font-family:medium-content-sans-serif-font, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Open Sans", "Helvetica Neue", sans-serif}.b{font-weight:400}.c{background-color:rgba(255, 255, 255, 1)}.l{height:100vh}.m{width:100vw}.n{display:flex}.o{align-items:center}.p{justify-content:center}.q{height:25px}.r{fill:rgba(41, 41, 41, 1)}.s{display:block}.t{margin-bottom:36px}.v{width:100%}.z{flex:0 0 auto}.ab{justify-self:flex-end}.ac{z-index:500}.ae{visibility:visible}.af{overflow-x:scroll}.ag{white-space:nowrap}.ah{scrollbar-width:none}.ai{-ms-overflow-style:none}.aj::-webkit-scrollbar{display:none}.ak{box-shadow:inset 0 -1px 0 rgba(230, 230, 230, 1)}.al{min-height:184px}.ao{flex-direction:column}.ap{background-color:#355876}.aq{display:none}.as{border-bottom:none}.at{position:relative}.az{max-width:1192px}.ba{min-width:0}.bb{height:62px}.bc{flex-direction:row}.bd{flex:1 0 auto}.be{margin-right:16px}.bf{font-family:sohne, "Helvetica Neue", Helvetica, Arial, sans-serif}.bg{font-size:14px}.bh{line-height:20px}.bi{color:rgba(233, 241, 250, 1)}.bj{padding:7px 16px 9px}.bk{background:0}.bl{fill:rgba(233, 241, 250, 1)}.bm{border-color:rgba(215, 226, 238, 1)}.br:disabled{cursor:inherit !important}.bs:disabled{opacity:0.3}.bt:disabled:hover{color:rgba(233, 241, 250, 1)}.bu:disabled:hover{fill:rgba(233, 241, 250, 1)}.bv:disabled:hover{border-color:rgba(215, 226, 238, 1)}.bw{border-radius:99em}.bx{border-width:1px}.by{border-style:solid}.bz{box-sizing:border-box}.ca{display:inline-block}.cb{text-decoration:none}.cc{margin-left:0px}.cd{color:rgba(197, 210, 225, 1)}.ce{font-size:inherit}.cf{border:inherit}.cg{font-family:inherit}.ch{letter-spacing:inherit}.ci{font-weight:inherit}.cj{padding:0}.ck{margin:0}.cl:disabled{cursor:default}.cm:disabled{color:rgba(163, 208, 162, 0.5)}.cn:disabled{fill:rgba(163, 208, 162, 0.5)}.co{min-height:115px}.cp{justify-content:space-between}.cv{align-items:flex-start}.cw{margin-bottom:0px}.cx{margin-top:-32px}.cy{flex-wrap:wrap}.db{margin-top:32px}.dc{margin-right:24px}.de{height:35px}.df{width:112px}.dg{margin-bottom:-3px}.dh{margin-left:14px}.di{margin-top:-3px}.dj{fill:rgba(251, 255, 255, 1)}.dk{padding-top:1px}.dl{height:70px}.dn{font-size:16px}.do{line-height:24px}.dp:before{margin-bottom:-10px}.dq:before{content:""}.dr:before{display:table}.ds:before{border-collapse:collapse}.dt:after{margin-top:-6px}.du:after{content:""}.dv:after{display:table}.dw:after{border-collapse:collapse}.dx{color:rgba(117, 117, 117, 1)}.dy{margin-right:12px}.dz{margin-bottom:-16px}.ea{margin-top:-14px}.eb{color:rgba(255, 255, 255, 1)}.ec{fill:rgba(255, 255, 255, 1)}.ed{background:rgba(102, 138, 170, 1)}.ee{border-color:rgba(102, 138, 170, 1)}.eh:disabled:hover{background:rgba(102, 138, 170, 1)}.ei:disabled:hover{border-color:rgba(102, 138, 170, 1)}.ej{display:inline-flex}.ek{color:inherit}.el{fill:inherit}.eo:disabled{color:rgba(117, 117, 117, 1)}.ep:disabled{fill:rgba(117, 117, 117, 1)}.eq{margin-left:12px}.er{margin:0 12px}.es{position:absolute}.et{right:24px}.eu{margin:0px}.ev{border:0px}.ew{padding:0px}.ex{cursor:pointer}.ey{stroke:rgba(117, 117, 117, 1)}.fb{left:0}.fc{opacity:0}.fd{position:fixed}.fe{right:0}.ff{top:0}.fg{visibility:hidden}.fi{height:60px}.fl{height:100%}.fo{color:rgba(102, 138, 170, 1)}.fp{fill:rgba(102, 138, 170, 1)}.fs:disabled:hover{color:rgba(102, 138, 170, 1)}.ft:disabled:hover{fill:rgba(102, 138, 170, 1)}.fu{margin-left:16px}.ga{margin-left:auto}.gb{margin-right:auto}.gc{max-width:728px}.gd{background:rgba(255, 255, 255, 1)}.ge{border:1px solid rgba(230, 230, 230, 1)}.gf{border-radius:4px}.gg{box-shadow:0 1px 4px rgba(230, 230, 230, 1)}.gh{max-height:100vh}.gi{overflow-y:auto}.gj{top:calc(100vh + 100px)}.gk{bottom:calc(100vh + 100px)}.gl{width:10px}.gm{pointer-events:none}.gn{word-break:break-word}.go{word-wrap:break-word}.gp:after{display:block}.gq:after{clear:both}.gr{max-width:680px}.gs{line-height:1.23}.gt{letter-spacing:0}.gu{font-style:normal}.gv{font-weight:700}.hq{margin-bottom:-0.27em}.hr{color:rgba(41, 41, 41, 1)}.hs{line-height:1.394}.ii{margin-bottom:-0.42em}.im{box-shadow:inset 0 0 0 1px rgba(0, 0, 0, 0.05)}.in{border-radius:50%}.io{height:28px}.ip{width:28px}.iq{margin-left:8px}.ir{flex-wrap:nowrap}.is{margin:0 4px}.it{margin:0 7px}.iu{align-items:flex-end}.jd{margin:0 6px 0 7px}.je path{fill:rgba(41, 41, 41, 1)}.jh{line-height:1.58}.ji{letter-spacing:-0.004em}.jj{font-family:charter, Georgia, Cambria, "Times New Roman", Times, serif}.jx{margin-top:24px}.jy{margin-bottom:-0.46em}.ke{line-height:1.12}.kf{letter-spacing:-0.022em}.kg{font-weight:500}.kz{margin-bottom:-0.28em}.lf{max-width:2430px}.ll{clear:both}.ln{cursor:zoom-in}.lo{z-index:auto}.lq{transition:opacity 100ms 400ms}.lr{overflow:hidden}.ls{will-change:transform}.lt{transform:translateZ(0)}.lu{margin:auto}.lv{background-color:rgba(242, 242, 242, 1)}.lw{padding-bottom:59.142857142857146%}.lx{height:0}.ly{filter:blur(20px)}.lz{transform:scale(1.1)}.ma{margin-top:10px}.mb{text-align:center}.me{line-height:1.18}.mm{margin-bottom:-0.31em}.mn{font-style:italic}.mo{text-decoration:underline}.mp{max-width:2268px}.mq{padding-bottom:86%}.mr{max-width:2048px}.ms{padding-bottom:43%}.mt{max-width:2058px}.mu{padding-bottom:40.85714285714286%}.mv{padding-bottom:59.42857142857143%}.mw{padding-bottom:100%}.mx{will-change:opacity}.my{width:188px}.mz{left:50%}.na{transform:translateX(406px)}.nb{top:calc(65px + 54px + 14px)}.ne{will-change:opacity, transform}.nf{transform:translateY(159px)}.nh{width:197px}.ni{margin-bottom:20px}.nj{padding-bottom:5px}.nk{padding-top:2px}.nl{padding-top:20px}.nm{stroke:rgba(242, 242, 242, 1)}.nn{height:36px}.no{width:36px}.np{color:rgba(242, 242, 242, 1)}.nq{fill:rgba(242, 242, 242, 1)}.nr{background:rgba(242, 242, 242, 1)}.ns{border-color:rgba(242, 242, 242, 1)}.ny{padding-top:32px}.nz{border-top:1px solid rgba(230, 230, 230, 1)}.oa{justify-content:space-evenly}.ob{margin-right:20px}.oh{-webkit-user-select:none}.oi{outline:0}.oj{border:0}.ok{user-select:none}.ol> svg{pointer-events:none}.ow button{text-align:left}.ox{margin-top:2px}.oy{fill:rgba(61, 61, 61, 1)}.oz{opacity:1}.pa{margin-top:1px}.pb{margin-top:40px}.pc{font-size:13px}.pd{padding-bottom:25px}.pe{margin-top:25px}.pf{max-width:155px}.pm{top:1px}.pp{margin-left:24px}.pq{margin-top:4px}.pr{padding-bottom:40px}.ps{list-style-type:none}.pt{margin-right:8px}.pu{margin-bottom:8px}.pv{line-height:22px}.pw{border-radius:3px}.px{padding:5px 10px}.py{padding-bottom:4px}.pz{background-color:rgba(250, 250, 250, 1)}.qp{text-overflow:ellipsis}.qq{display:-webkit-box}.qr{-webkit-line-clamp:2}.qs{-webkit-box-orient:vertical}.qu{padding-top:5px}.qv{padding-top:25px}.rb{max-width:100%}.rc{margin-bottom:96px}.rd{margin-bottom:40px}.re{padding-bottom:16px}.rf{border-bottom:1px solid rgba(230, 230, 230, 1)}.rg{margin-bottom:24px}.ss{flex-grow:0}.st{padding-bottom:24px}.su{max-width:500px}.sv{flex:0 1 auto}.sx{padding-bottom:8px}.bn:hover{color:rgba(251, 255, 255, 1)}.bo:hover{fill:rgba(251, 255, 255, 1)}.bp:hover{border-color:rgba(251, 255, 255, 1)}.bq:hover{cursor:pointer}.ef:hover{background:rgba(90, 118, 144, 1)}.eg:hover{border-color:rgba(90, 118, 144, 1)}.em:hover{color:rgba(25, 25, 25, 1)}.en:hover{fill:rgba(25, 25, 25, 1)}.fq:hover{color:rgba(90, 118, 144, 1)}.fr:hover{fill:rgba(90, 118, 144, 1)}.jf:hover{fill:rgba(8, 8, 8, 1)}.nt:hover{background:rgba(242, 242, 242, 1)}.nu:hover{border-color:rgba(242, 242, 242, 1)}.nv:hover{cursor:wait}.nw:hover{color:rgba(242, 242, 242, 1)}.nx:hover{fill:rgba(242, 242, 242, 1)}.oo:hover{fill:rgba(117, 117, 117, 1)}.tf:hover{text-decoration:underline}.jg:focus{fill:rgba(8, 8, 8, 1)}.lp:focus{transform:scale(1.01)}.on:focus{fill:rgba(117, 117, 117, 1)}.om:active{border-style:none}</style><style type="text/css" data-fela-rehydration="537" data-fela-type="RULE" media="all and (min-width: 1080px)">.d{display:none}.w{display:flex}.ay{margin:0 64px}.fz{padding:0 16px}.hm{font-size:46px}.hn{margin-top:0.6em}.ho{line-height:56px}.hp{letter-spacing:-0.011em}.if{font-size:22px}.ig{margin-top:0.92em}.ih{line-height:28px}.jb{margin-left:30px}.ju{font-size:21px}.jv{line-height:32px}.jw{letter-spacing:-0.003em}.kd{margin-top:2em}.kv{font-size:30px}.kw{margin-top:1.95em}.kx{line-height:36px}.ky{letter-spacing:0}.le{margin-top:0.86em}.lk{margin-top:56px}.ml{margin-top:1.72em}.og{margin-right:5px}.ov{margin-top:0px}.pl{margin-top:5px}.po{display:inline-block}.qm{font-size:20px}.qn{line-height:24px}.qo{max-height:48px}.ra{margin:0}.rv{width:calc(100% + 32px)}.rw{margin-left:-16px}.rx{margin-right:-16px}.so{padding-left:16px}.sp{padding-right:16px}.sq{flex-basis:25%}.sr{max-width:25%}.tc{font-size:16px}.td{line-height:20px}.tq{min-width:70px}.tr{min-height:70px}</style><style type="text/css" data-fela-rehydration="537" data-fela-type="RULE" media="all and (max-width: 1079.98px)">.e{display:none}.ja{margin-left:30px}.mc{margin-left:auto}.md{text-align:center}.ou{margin-top:0px}.pk{margin-top:5px}.pn{display:inline-block}</style><style type="text/css" data-fela-rehydration="537" data-fela-type="RULE" media="all and (max-width: 903.98px)">.f{display:none}.iz{margin-left:30px}.ot{margin-top:0px}.pi{display:inline-block}.pj{margin-top:5px}.sw{margin-right:16px}</style><style type="text/css" data-fela-rehydration="537" data-fela-type="RULE" media="all and (max-width: 727.98px)">.g{display:none}.u{margin-bottom:20px}.am{box-shadow:inset 0 -1px 0 rgba(230, 230, 230, 1)}.an{min-height:230px}.ar{display:block}.cq{min-height:98px}.cr{display:flex}.cs{align-items:flex-start}.ct{flex-direction:column}.cu{justify-content:flex-end}.cz{margin-bottom:28px}.da{margin-top:0px}.dd{margin-top:28px}.dm{margin:0}.ez{border-top:1px solid rgba(230, 230, 230, 1)}.fa{border-bottom:1px solid rgba(230, 230, 230, 1)}.fm{align-items:center}.fn{flex:1 0 auto}.ik{margin-top:32px}.il{flex-direction:column-reverse}.ix{margin-bottom:30px}.iy{margin-left:0px}.or{margin-top:2px}.os{margin-right:16px}.ph{display:inline-block}.rh{padding-bottom:12px}.ri{margin-top:16px}.tg{margin-left:16px}.th{margin-right:0px}</style><style type="text/css" data-fela-rehydration="537" data-fela-type="RULE" media="all and (max-width: 551.98px)">.h{display:none}.au{margin:0 24px}.fj{display:block}.fv{padding:0 8px}.gw{font-size:32px}.gx{margin-top:0.64em}.gy{line-height:40px}.gz{letter-spacing:-0.016em}.ht{font-size:18px}.hu{margin-top:0.79em}.hv{line-height:24px}.ij{margin-top:32px}.iv{margin-bottom:30px}.iw{margin-left:0px}.jk{line-height:28px}.jl{letter-spacing:-0.003em}.jz{margin-top:1.56em}.kh{font-size:22px}.ki{margin-top:1.2em}.kj{letter-spacing:0}.la{margin-top:0.67em}.lg{margin-top:40px}.mf{font-size:20px}.mg{margin-top:1.23em}.oc{margin-left:8px}.op{margin-top:2px}.oq{margin-right:16px}.pg{display:inline-block}.qa{font-size:16px}.qb{line-height:20px}.qc{max-height:40px}.qw{margin:0}.rj{width:calc(100% + 24px)}.rk{margin-left:-12px}.rl{margin-right:-12px}.ry{padding-left:12px}.rz{padding-right:12px}.sa{flex-basis:100%}.sb{max-width:100%}.te{margin-bottom:0px}.ti{min-width:48px}.tj{min-height:48px}</style><style type="text/css" data-fela-rehydration="537" data-fela-type="RULE" media="all and (min-width: 904px) and (max-width: 1079.98px)">.i{display:none}.x{display:flex}.ax{margin:0 64px}.fy{padding:0 16px}.hi{font-size:46px}.hj{margin-top:0.6em}.hk{line-height:56px}.hl{letter-spacing:-0.011em}.ic{font-size:22px}.id{margin-top:0.92em}.ie{line-height:28px}.jr{font-size:21px}.js{line-height:32px}.jt{letter-spacing:-0.003em}.kc{margin-top:2em}.kr{font-size:30px}.ks{margin-top:1.95em}.kt{line-height:36px}.ku{letter-spacing:0}.ld{margin-top:0.86em}.lj{margin-top:56px}.mk{margin-top:1.72em}.of{margin-right:5px}.qj{font-size:20px}.qk{line-height:24px}.ql{max-height:48px}.qz{margin:0}.rs{width:calc(100% + 32px)}.rt{margin-left:-16px}.ru{margin-right:-16px}.sk{padding-left:16px}.sl{padding-right:16px}.sm{flex-basis:25%}.sn{max-width:25%}.ta{font-size:16px}.tb{line-height:20px}.to{min-width:70px}.tp{min-height:70px}</style><style type="text/css" data-fela-rehydration="537" data-fela-type="RULE" media="all and (min-width: 728px) and (max-width: 903.98px)">.j{display:none}.y{display:flex}.aw{margin:0 48px}.fx{padding:0 16px}.he{font-size:46px}.hf{margin-top:0.6em}.hg{line-height:56px}.hh{letter-spacing:-0.011em}.hz{font-size:22px}.ia{margin-top:0.92em}.ib{line-height:28px}.jo{font-size:21px}.jp{line-height:32px}.jq{letter-spacing:-0.003em}.kb{margin-top:2em}.kn{font-size:30px}.ko{margin-top:1.95em}.kp{line-height:36px}.kq{letter-spacing:0}.lc{margin-top:0.86em}.li{margin-top:56px}.mj{margin-top:1.72em}.oe{margin-right:5px}.qg{font-size:20px}.qh{line-height:24px}.qi{max-height:48px}.qy{margin:0}.rp{width:calc(100% + 28px)}.rq{margin-left:-14px}.rr{margin-right:-14px}.sg{padding-left:14px}.sh{padding-right:14px}.si{flex-basis:50%}.sj{max-width:50%}.sy{font-size:16px}.sz{line-height:20px}.tm{min-width:48px}.tn{min-height:48px}</style><style type="text/css" data-fela-rehydration="537" data-fela-type="RULE" media="all and (min-width: 552px) and (max-width: 727.98px)">.k{display:none}.av{margin:0 24px}.fk{display:block}.fw{padding:0 8px}.ha{font-size:32px}.hb{margin-top:0.64em}.hc{line-height:40px}.hd{letter-spacing:-0.016em}.hw{font-size:18px}.hx{margin-top:0.79em}.hy{line-height:24px}.jm{line-height:28px}.jn{letter-spacing:-0.003em}.ka{margin-top:1.56em}.kk{font-size:22px}.kl{margin-top:1.2em}.km{letter-spacing:0}.lb{margin-top:0.67em}.lh{margin-top:40px}.mh{font-size:20px}.mi{margin-top:1.23em}.od{margin-left:8px}.qd{font-size:16px}.qe{line-height:20px}.qf{max-height:40px}.qx{margin:0}.rm{width:calc(100% + 24px)}.rn{margin-left:-12px}.ro{margin-right:-12px}.sc{padding-left:12px}.sd{padding-right:12px}.se{flex-basis:100%}.sf{max-width:100%}.tk{min-width:48px}.tl{min-height:48px}</style><style type="text/css" data-fela-rehydration="537" data-fela-type="RULE" media="print">.jc{display:none}</style><style type="text/css" data-fela-rehydration="537" data-fela-type="RULE" media="(prefers-reduced-motion: no-preference)">.fh{animation:k2 .2s ease-in-out both}.lm{transition:transform 300ms cubic-bezier(0.2, 0, 0.2, 1)}.nc{transition:opacity 200ms}</style><style type="text/css" data-fela-rehydration="537" data-fela-type="RULE" media="all and (max-width: 1230px)">.nd{display:none}</style><style type="text/css" data-fela-rehydration="537" data-fela-type="RULE" media="all and (max-width: 1240px)">.ng{display:none}</style><style type="text/css" data-fela-rehydration="537" data-fela-type="RULE" media="(orientation: landscape) and (max-width: 903.98px)">.qt{max-height:none}</style><link rel="icon" href="https://miro.medium.com/fit/c/128/128/1*ChFMdf--f5jbm-AYv6VdYA@2x.png" data-rh="true"><script async="" src="https://cdn.branch.io/branch-latest.min.js"></script><script async="" src="https://www.google-analytics.com/analytics.js"></script><script type="application/ld+json" data-rh="true">{"@context":"http:\u002F\u002Fschema.org","@type":"NewsArticle","image":["https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F1200\u002F1*7qwYH1r-h6VOGiE6C2tpGg.png"],"url":"https:\u002F\u002Ftowardsdatascience.com\u002Fneural-network-pruning-101-af816aaea61","dateCreated":"2021-09-09T06:36:56.338Z","datePublished":"2021-09-09T06:36:56.338Z","dateModified":"2022-01-05T13:54:23.953Z","headline":"Neural Network Pruning 101 - Towards Data Science","name":"Neural Network Pruning 101 - Towards Data Science","description":"Whether it is in computer vision, natural language processing or image generation, deep neural networks yield the state of the art. However, their cost in terms of computational power, memory or…","identifier":"af816aaea61","author":{"@type":"Person","name":"Hugo Tessier","url":"https:\u002F\u002Ftowardsdatascience.com\u002F@hugo.tessier"},"creator":["Hugo Tessier"],"publisher":{"@type":"Organization","name":"Towards Data Science","url":"towardsdatascience.com","logo":{"@type":"ImageObject","width":165,"height":60,"url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F165\u002F1*mG6i4Bh_LgixUYXJgQpYsg@2x.png"}},"mainEntityOfPage":"https:\u002F\u002Ftowardsdatascience.com\u002Fneural-network-pruning-101-af816aaea61"}</script><script data-rh="true">(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-24232453-2', 'auto');
ga('send', 'pageview');</script><script type="text/javascript" data-rh="true">(function(b,r,a,n,c,h,_,s,d,k){if(!b[n]||!b[n]._q){for(;s<_.length;)c(h,_[s++]);d=r.createElement(a);d.async=1;d.src="https://cdn.branch.io/branch-latest.min.js";k=r.getElementsByTagName(a)[0];k.parentNode.insertBefore(d,k);b[n]=h}})(window,document,"script","branch",function(b,r){b[r]=function(){b._q.push([r,arguments])}},{_q:[],_v:1},"addListener applyCode autoAppIndex banner closeBanner closeJourney creditHistory credits data deepview deepviewCta first getCode init link logout redeem referrals removeListener sendSMS setBranchViewData setIdentity track validateCode trackCommerceEvent logEvent".split(" "), 0);
branch.init('key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm', {metadata: {}, 'no_journeys': true, 'disable_exit_animation': true, 'disable_entry_animation': true, 'tracking_disabled': null}, function(err, data) {});</script></head><body><div id="root"><div class="a b c"><div class="d e f g h i j k"></div><script>document.domain = document.domain;</script><div><script>if (window.self !== window.top) window.location = "about:blank"</script></div><div class="s"><div class="t s u"><div class="ak al s am an"><div class="n ao ap"><div class="aq ar"><div class="as s at ac"><div class="n p"><div class="au av aw ax ay az ba v"><div class="bb n o"><div class="n o bc bd"><div class="be s"><span><a class="bf b bg bh bi bj bk bl bm bn bo bp bq br bs bt bu bv bw bx by bz ca cb" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-network-pruning-101-af816aaea61&amp;source=post_page-----af816aaea61---------------------nav_reg--------------" rel="noopener follow">Get started</a></span></div><div class="ag"><div class="cc aq ar"><span class="bf b bg bh cd"><a class="bi bl ce cf cg ch ci cj ck bq bn bo cl cm cn" href="https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Faf816aaea61&amp;%7Efeature=LoOpenInAppButton&amp;%7Echannel=ShowPostUnderCollection&amp;%7Estage=mobileNavBar&amp;source=post_page-----af816aaea61-----------------------------------" rel="noopener follow">Open in app</a></span></div></div></div><a aria-label="Homepage" href="https://medium.com/?source=post_page-----af816aaea61-----------------------------------" rel="noopener follow"><svg viewBox="0 0 1043.63 592.71" class="q bl"><g data-name="Layer 2"><g data-name="Layer 1"><path d="M588.67 296.36c0 163.67-131.78 296.35-294.33 296.35S0 460 0 296.36 131.78 0 294.34 0s294.33 132.69 294.33 296.36M911.56 296.36c0 154.06-65.89 279-147.17 279s-147.17-124.94-147.17-279 65.88-279 147.16-279 147.17 124.9 147.17 279M1043.63 296.36c0 138-23.17 249.94-51.76 249.94s-51.75-111.91-51.75-249.94 23.17-249.94 51.75-249.94 51.76 111.9 51.76 249.94"></path></g></g></svg></a></div></div></div></div></div><div class="n p"><div class="au av aw ax ay az ba v"><div class="co n o bc cp cq cr cs ct cu"><div class="v n cv cp"><div class="n v"><div class="cw cx v n o bc cy cz da cr cs ct"><div class="db dc s dd"><a aria-label="Publication Homepage" rel="noopener follow" href="/?source=post_page-----af816aaea61-----------------------------------"><div class="de df s"><img alt="Towards Data Science" class="" src="https://miro.medium.com/max/112/1*AGyTPCaRzVqL77kFwUwHKg.png" width="112" height="35"></div></a></div></div></div><div class="w x y k h z ab o ac ae"><p class="bf b bg bh cd"><span><a class="bi bl ce cf cg ch ci cj ck bq bn bo cl cm cn" href="https://medium.com/m/signin?operation=login&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-network-pruning-101-af816aaea61&amp;source=post_page-----af816aaea61---------------------nav_reg--------------" rel="noopener follow">Sign in</a></span></p><div class="dg dh di dc s"><span><a class="bf b bg bh bi bj bk bl bm bn bo bp bq br bs bt bu bv bw bx by bz ca cb" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-network-pruning-101-af816aaea61&amp;source=post_page-----af816aaea61---------------------nav_reg--------------" rel="noopener follow">Get started</a></span></div><a aria-label="Homepage" href="https://medium.com/?source=post_page-----af816aaea61-----------------------------------" rel="noopener follow"><svg viewBox="0 0 1043.63 592.71" class="q dj"><g data-name="Layer 2"><g data-name="Layer 1"><path d="M588.67 296.36c0 163.67-131.78 296.35-294.33 296.35S0 460 0 296.36 131.78 0 294.34 0s294.33 132.69 294.33 296.36M911.56 296.36c0 154.06-65.89 279-147.17 279s-147.17-124.94-147.17-279 65.88-279 147.16-279 147.17 124.9 147.17 279M1043.63 296.36c0 138-23.17 249.94-51.76 249.94s-51.75-111.91-51.75-249.94 23.17-249.94 51.75-249.94 51.76 111.9 51.76 249.94"></path></g></g></svg></a></div></div></div></div></div></div><div class="s"><div class="n p"><div class="au av aw ax ay az ba v"><div class="af ag ah ai aj"><div class="dk dl n o"><div class="s dm"><span class="bf b dn do dp dq dr ds dt du dv dw dx"><div class="n o"><div class="tv s"><div class="dz ea s"><div class="ca" aria-hidden="false" aria-describedby="collectionFollowPopover" aria-labelledby="collectionFollowPopover"><span><a class="bf b bg bh eb bj ec ed ee ef eg bq br bs eh ei bw bx by bz ca cb" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-network-pruning-101-af816aaea61&amp;collection=Towards+Data+Science&amp;collectionId=7f60cf5620c9&amp;source=post_page-----af816aaea61---------------------follow_header--------------" rel="noopener follow"><div class="n bc">Follow</div></a></span></div></div></div><div class="dy ej ao"><span class="bf b dn do dx"><button class="ek el ce cf cg ch ci cj ck bq em en cl eo ep">622K Followers</button></span></div><div class="eq s g">·</div><div class="eq s g"><nav class="n o"><span class="er n ao"><a class="ek el ce cf cg ch ci cj ck bq em en cl eo ep" rel="noopener follow" href="/tagged/editors-pick?source=post_page-----af816aaea61-----------------------------------">Editors' Picks</a></span><span class="er n ao"><a class="ek el ce cf cg ch ci cj ck bq em en cl eo ep" rel="noopener follow" href="/tagged/tds-features?source=post_page-----af816aaea61-----------------------------------">Features</a></span><span class="er n ao"><a class="ek el ce cf cg ch ci cj ck bq em en cl eo ep" rel="noopener follow" href="/tagged/deep-dives?source=post_page-----af816aaea61-----------------------------------">Deep Dives</a></span><span class="er n ao"><a class="ek el ce cf cg ch ci cj ck bq em en cl eo ep" rel="noopener follow" href="/how-to-get-the-most-out-of-towards-data-science-3bf37f75a345?source=post_page-----af816aaea61-----------------------------------">Grow</a></span><span class="er n ao"><a class="ek el ce cf cg ch ci cj ck bq em en cl eo ep" rel="noopener follow" href="/questions-96667b06af5?source=post_page-----af816aaea61-----------------------------------">Contribute</a></span></nav></div><div class="s h"></div><div class="eq n ao g"><a class="ek el ce cf cg ch ci cj ck bq em en cl eo ep" rel="noopener follow" href="/about?source=post_page-----af816aaea61-----------------------------------">About</a></div></div></span></div><div class="aq es et ar"><button class="n o p eu ev ew ex" aria-label="Expand navbar"><svg width="14" height="14" class="ey"><path d="M0 .5h14M0 7h14M0 13.5h14"></path></svg></button></div></div></div></div></div></div></div><div class="ez fa c fb fc fd fe ff fg ac fh"><div class="n p"><div class="au av aw ax ay az ba v"><div class="fi v fj fk j i d ff ac"><div class="fl n o"><div class="aq cr fm fn"><span><a class="bf b bg bh fo bj bk fp ee fq fr eg bq br bs fs ft ei bw bx by bz ca cb" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-network-pruning-101-af816aaea61&amp;source=post_page-----af816aaea61---------------------nav_reg--------------" rel="noopener follow">Get started</a></span><div class="fu aq ar"><span class="bf b bg bh dx"><a class="fo fp ce cf cg ch ci cj ck bq fq fr cl cm cn" href="https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Faf816aaea61&amp;%7Efeature=LoOpenInAppButton&amp;%7Echannel=ShowPostUnderCollection&amp;%7Estage=mobileNavBar&amp;source=post_page-----af816aaea61-----------------------------------" rel="noopener follow">Open in app</a></span></div></div><a aria-label="Homepage" href="https://medium.com/?source=post_page-----af816aaea61-----------------------------------" rel="noopener follow"><svg viewBox="0 0 1043.63 592.71" class="q r"><g data-name="Layer 2"><g data-name="Layer 1"><path d="M588.67 296.36c0 163.67-131.78 296.35-294.33 296.35S0 460 0 296.36 131.78 0 294.34 0s294.33 132.69 294.33 296.36M911.56 296.36c0 154.06-65.89 279-147.17 279s-147.17-124.94-147.17-279 65.88-279 147.16-279 147.17 124.9 147.17 279M1043.63 296.36c0 138-23.17 249.94-51.76 249.94s-51.75-111.91-51.75-249.94 23.17-249.94 51.75-249.94 51.76 111.9 51.76 249.94"></path></g></g></svg></a></div></div></div></div></div></div><div class="jc" role="dialog" aria-modal="true" tabindex="-1"><div class="ul um v fl fd un uo ex fc gm up" aria-hidden="true" role="presentation"></div><div class="uq fd ur us ut ul fl bz uu uv uw oz ux uy fg uz va vb vc vd ve" aria-hidden="true"><div class="vf vg n o bc cp"><div class="n bc"><h2 class="bf kg vh do gt hr">Responses</h2></div><div class="n bc"><div><div class="ca" role="tooltip" aria-hidden="false" aria-describedby="59" aria-labelledby="59"><a class="oy en" href="https://policy.medium.com/medium-rules-30e5502c4eb4?source=responses-----af816aaea61-----------------------------------" rel="noopener follow" target="_blank"><svg width="25" height="25" viewBox="0 0 25 25"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.99 5.04c.26-.21.64-.22.91-.01.97.72 1.77 1.21 2.6 1.54.83.32 1.72.48 2.89.5.41.01.74.35.74.76-.02 3.62-.43 6.26-1.45 8.21-1.03 1.98-2.66 3.21-4.97 4.08a.75.75 0 0 1-.53 0c-2.25-.87-3.86-2.1-4.9-4.07-1.02-1.95-1.46-4.59-1.48-8.22 0-.41.33-.75.75-.76 1.19-.02 2.1-.18 2.92-.5.82-.32 1.6-.81 2.52-1.53zm.46.9c-.9.69-1.71 1.21-2.62 1.56a8.9 8.9 0 0 1-3.02.57c.03 3.45.46 5.82 1.36 7.51.88 1.69 2.25 2.77 4.28 3.57 2.1-.8 3.47-1.89 4.34-3.57.89-1.7 1.3-4.07 1.34-7.51a8.8 8.8 0 0 1-3-.57 11.8 11.8 0 0 1-2.68-1.56zm0 9.15a2.67 2.67 0 1 0 0-5.34 2.67 2.67 0 0 0 0 5.34zm0 1a3.67 3.67 0 1 0 0-7.34 3.67 3.67 0 0 0 0 7.34zm-1.82-3.77l.53-.53.91.92 1.63-1.63.52.53-2.15 2.15-1.44-1.44z"></path></svg></a></div></div><div class="s at vi"><div class="s at ff fe"><button class="ek el ce cf cg ch ci cj ck bq em en cl eo ep" data-testid="close-button" aria-label="close"><svg width="25" height="25" viewBox="0 0 25 25" class="ty"><path d="M18.13 6.11l-5.61 5.61-5.6-5.61-.81.8 5.61 5.61-5.61 5.61.8.8 5.61-5.6 5.61 5.6.8-.8-5.6-5.6 5.6-5.62"></path></svg></button></div></div></div></div><div><div class="bf b bg bh hr"><div class="do"><div class="vl ni s"><div class="us yd gf n ao ye yf yg"><div class="n ao"><span><a class="ek el ce cf cg ch ci cj ck bq em en cl eo ep" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-network-pruning-101-af816aaea61&amp;source=responses-----af816aaea61---------------------respond_sidebar--------------" rel="noopener follow"><div class="yj s"><p class="bf b bg bh dx">What are your thoughts?</p></div></a></span><div class="cp yh dx n ya fc yb"><span class="bf b bg bh dx"><div class="n"><div><div class="ca" role="tooltip" aria-hidden="false" aria-describedby="213" aria-labelledby="213"><span class="is yk yl ym gf ej p yn yo"><svg width="21" height="21"><path d="M10.3 18H4.4l.1-.9.8-.12c.55-.11.78-.23.78-.45V5.37c0-.22-.11-.34-.9-.45H4.5l-.11-.9h6.25c4.02 0 5.58 1.24 5.58 3.14 0 1.9-1.78 3.12-3.79 3.46v.11c2.7.34 4.25 1.56 4.25 3.57 0 2.35-2 3.7-6.37 3.7h.02-.02zM9.98 5.02h-1v5.47h1.23c1.79 0 2.79-1.23 2.79-2.68 0-1.69-1-2.8-3-2.8v.01zm-.22 6.36h-.78V17l1.22.22h.22c1.67 0 3.01-1 3.01-2.8 0-2.11-1.56-3-3.69-3h.02z" fill-rule="evenodd"></path></svg></span></div></div><div><div class="ca" role="tooltip" aria-hidden="false" aria-describedby="214" aria-labelledby="214"><span class="is yk yl ym gf ej p yn yo"><svg width="21" height="21"><path d="M9.85 18.04c-.54 0-2.03-.64-1.92-.85L9.95 9.5l-.64-.22-1.38 1.5-.43-.43c.53-1.17 1.7-2.67 2.77-2.67.54 0 2.24.54 2.14.86l-2.14 7.78.54.22 1.6-1.07.42.43c-.64 1.06-1.92 2.13-2.98 2.13zm2.34-11.73c-.96 0-1.38-.64-1.38-1.39 0-1.07.74-1.92 1.49-1.92.85 0 1.39.64 1.39 1.5-.11 1.06-.75 1.8-1.5 1.8z" fill-rule="evenodd"></path></svg></span></div></div></div></span><div class="xy xz n ya fc yb"><div class="yc"><button class="bf b bg bh hr yp r bk yq yr jf ys bq br bs yt yu yv bw bx by bz ca cb">Cancel</button></div><button class="bf b bg bh eb yp ec yw yx yy yz bq br bs za zb bw bx by bz ca cb" disabled="">Respond</button></div></div></div></div><div class="yi n ya fc yb"><span role="checkbox" aria-checked="false" tabindex="0"><label class="n o"><div class="pt zs zt n zu at"><input class="zc zd ze es fc zf zg zh zi zj zk zl" type="checkbox" disabled=""><span class="o nr zm bx by zn bz eb zo n ec zp p zq"><svg width="11" height="11" viewBox="0 0 11 11" class="ec zr"><path d="M0 6.31l3.7 3.7.9.91.67-1.1 5.3-8.79L8.84 0l-5.3 8.8 1.57-.2-3.7-3.7L0 6.3z"></path></svg></span></div><div class="s"><p class="bf b pc bh dx">Also publish to my profile</p></div></label></span></div></div></div></div></div><div class="vj mb n ao p o mn vk"><p class="bf b dn do dx">There are currently no responses for this story.</p><p class="bf b dn do dx">Be the first to respond.</p></div></div></div><article><div class="fv fw fx fy fz ga gb v gc bz s"></div><span class="s"></span><section><div><div class="es fb tw gk gl gm"></div><div class="ga gb gc at"><div class="s h g f e"><aside class="ut es ff" style="width: 768px;"><div class="xw rb es xx ag v"><p class="bf b pc bh dx"><span class="ca rb ag lr qp">Top highlight</span></p></div></aside></div></div><div class="gn go gp du gq"><div class="n p"><div class="au av aw ax ay gr ba v"><div class=""><h1 id="06b7" class="pw-post-title gs gt gu bf gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho hp hq hr" data-selectable-paragraph="">Neural Network Pruning 101</h1></div><div class=""><h2 id="c2f6" class="pw-subtitle-paragraph hs gt gu bf b ht hu hv hw hx hy hz ia ib ic id ie if ig ih ii dx" data-selectable-paragraph="">All you need to know not to get lost</h2><div class="db"><div class="n cp ij ik il"><div class="o n"><div><a href="https://medium.com/@hugo.tessier?source=post_page-----af816aaea61-----------------------------------" rel="noopener follow"><div class="s at"><img alt="Hugo Tessier" class="s bz in io ip" src="https://miro.medium.com/fit/c/56/56/1*PAy1sna3YNoKY4jQl9znVw.jpeg" width="28" height="28"><div class="im in s io ip es ff"></div></div></a></div><div class="iq v n ir"><div class="n"><div style="flex:1"><span class="bf b bg bh hr"><div><div class="ca" role="tooltip" aria-hidden="false" aria-describedby="7" aria-labelledby="7"><a class="" href="https://medium.com/@hugo.tessier?source=post_page-----af816aaea61-----------------------------------" rel="noopener follow"><p class="bf b bg bh fo">Hugo Tessier</p></a></div></div></span></div></div><div class="s z"><span class="bf b bg bh dx"><a class="" rel="noopener follow" href="/neural-network-pruning-101-af816aaea61?source=post_page-----af816aaea61-----------------------------------"><p class="bf b bg bh dx"><span class="is"></span><span>Sep 9, 2021</span><span class="it">·</span>22 min read</p></a></span></div></div></div><div class="n iu iv iw ix iy iz ja jb jc"><div class="n o"><div class="tx s z"><div><div class="ca" role="tooltip" aria-hidden="false" aria-describedby="8" aria-labelledby="8"><button class="ek el ce cf cg ch ci cj ck bq em en cl eo ep" aria-label="Share on twitter"><svg width="30" height="30" viewBox="0 0 30 30" fill="none" class="ty tz"><path fill-rule="evenodd" clip-rule="evenodd" d="M15 27a12 12 0 1 0 0-24 12 12 0 0 0 0 24zm4.95-16.17a2.67 2.67 0 0 0-4.6 1.84c0 .2.03.41.05.62a7.6 7.6 0 0 1-5.49-2.82 3 3 0 0 0-.38 1.34c.02.94.49 1.76 1.2 2.23a2.53 2.53 0 0 1-1.2-.33v.04c0 1.28.92 2.36 2.14 2.62-.23.05-.46.08-.71.1l-.21-.02-.27-.03a2.68 2.68 0 0 0 2.48 1.86A5.64 5.64 0 0 1 9 19.38a7.62 7.62 0 0 0 4.1 1.19c4.9 0 7.58-4.07 7.57-7.58v-.39c.52-.36.97-.83 1.33-1.38-.48.23-1 .37-1.53.43.56-.33.96-.86 1.15-1.48-.5.31-1.07.53-1.67.66z" fill="#292929"></path></svg></button></div></div></div><div class="tx s z"><div><div class="ca" role="tooltip" aria-hidden="false" aria-describedby="9" aria-labelledby="9"><button class="ek el ce cf cg ch ci cj ck bq em en cl eo ep" aria-label="Share on facebook"><svg width="30" height="30" viewBox="0 0 30 30" fill="none" class="ty tz"><path fill-rule="evenodd" clip-rule="evenodd" d="M15 27a12 12 0 1 0 0-24 12 12 0 0 0 0 24zm-1.23-6.03V15.6H12v-2.15h1.77v-1.6C13.77 10 14.85 9 16.42 9c.75 0 1.4.06 1.58.08v1.93h-1.09c-.85 0-1.02.43-1.02 1.05v1.38h2.04l-.27 2.15H15.9V21l-2.13-.03z" fill="#292929"></path></svg></button></div></div></div><div class="tx s z"><div><div class="ca" role="tooltip" aria-hidden="false" aria-describedby="10" aria-labelledby="10"><button class="ek el ce cf cg ch ci cj ck bq em en cl eo ep" aria-label="Share on linkedin"><svg width="30" height="30" viewBox="0 0 30 30" fill="none" class="ty tz"><path fill-rule="evenodd" clip-rule="evenodd" d="M27 15a12 12 0 1 1-24 0 12 12 0 0 1 24 0zm-14.61 5v-7.42h-2.26V20h2.26zm-1.13-8.44c.79 0 1.28-.57 1.28-1.28-.02-.73-.5-1.28-1.26-1.28-.78 0-1.28.55-1.28 1.28 0 .71.49 1.28 1.25 1.28h.01zM15.88 20h-2.5s.04-6.5 0-7.17h2.5v1.02l-.02.02h.02v-.02a2.5 2.5 0 0 1 2.25-1.18c1.64 0 2.87 1.02 2.87 3.22V20h-2.5v-3.83c0-.97-.36-1.62-1.26-1.62-.69 0-1.1.44-1.28.87-.06.15-.08.36-.08.58v4z" fill="#292929"></path></svg></button></div></div></div><div class="s z"><div><div class="ca" role="tooltip" aria-hidden="false" aria-describedby="11" aria-labelledby="11"><button class="ek el ce cf cg ch ci cj ck bq em en cl eo ep"><svg width="30" height="30" viewBox="0 0 30 30" fill="none" class="ty tz"><path fill-rule="evenodd" clip-rule="evenodd" d="M15 27a12 12 0 1 0 0-24 12 12 0 0 0 0 24zM9.29 16.28c-.2.36-.29.75-.29 1.17a2.57 2.57 0 0 0 .78 1.84l1.01.96c.53.5 1.17.75 1.92.75s1.38-.25 1.9-.75l1.2-1.15.75-.71.51-.5a2.51 2.51 0 0 0 .72-2.34.7.7 0 0 0-.03-.18 2.74 2.74 0 0 0-.23-.5v-.02l-.08-.14-.02-.03-.02-.01a.33.33 0 0 0-.07-.1c0-.02-.01-.03-.03-.05a.2.2 0 0 0-.03-.03l-.03-.04v-.01l-.02-.03-.04-.03a.85.85 0 0 1-.13-.13l-.43-.42-.06.06-.9.84-.05.09a.26.26 0 0 0-.03.1l.37.38c.04.03.08.07.1.11l.01.01.01.03.02.01.04.1.03.04.06.1v.02l.01.02c.03.1.05.2.05.33a1 1 0 0 1-.12.49c-.07.13-.15.22-.22.29l-.88.85-.61.57-.95.92c-.22.2-.5.3-.82.3-.31 0-.58-.1-.8-.3l-.98-.96a1.15 1.15 0 0 1-.3-.42 1.4 1.4 0 0 1-.04-.35c0-.1.01-.2.04-.3a1 1 0 0 1 .3-.49l1.5-1.46v-.24c0-.21 0-.42.04-.6a3.5 3.5 0 0 1 .92-1.72c-.41.1-.78.32-1.11.62l-.01.02-.01.01-2.46 2.33c-.2.21-.35.4-.44.6h-.02c0 .02 0 .02-.02.02v.02l-.01.01zm3.92-1.8a1.83 1.83 0 0 0 .02.97c0 .06 0 .13.02.19.06.17.14.34.22.5v.02l.06.12.02.03.01.02.08.1c0 .02.02.03.04.05l.08.1h.01c0 .01 0 .03.02.03l.14.14.43.41.08-.06.88-.84.05-.09.03-.1-.36-.37a.4.4 0 0 1-.12-.13v-.02l-.02-.02-.05-.09-.04-.04-.04-.1v-.02l-.02-.02a1.16 1.16 0 0 1 .06-.82c.09-.14.16-.24.23-.3l.9-.85.6-.58.93-.92c.23-.2.5-.3.82-.3a1.2 1.2 0 0 1 .82.3l1 .96c.13.15.23.29.28.42a1.43 1.43 0 0 1 0 .66c-.03.17-.12.33-.26.48l-1.54 1.45.02.25a3.28 3.28 0 0 1-.96 2.32 2.5 2.5 0 0 0 1.1-.62l.01-.01 2.46-2.34c.19-.2.35-.4.46-.6l.02-.02v-.02h.01a2.45 2.45 0 0 0 .21-1.82 2.53 2.53 0 0 0-.7-1.19l-1-.96a2.68 2.68 0 0 0-1.91-.75c-.75 0-1.38.25-1.9.76l-1.2 1.14-.76.72-.5.49c-.4.37-.64.83-.74 1.37z" fill="#292929"></path></svg></button></div></div></div><div class="jd s"><span><a class="ek el ce cf cg ch ci cj ck bq em en cl eo ep" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Faf816aaea61&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-network-pruning-101-af816aaea61&amp;source=post_actions_header--------------------------bookmark_preview--------------" rel="noopener follow"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="je"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></a></span></div><div class="ca" aria-hidden="false"><button class="ek el ce cf cg ch ci cj ck bq em en cl eo ep" aria-label="More options"><svg class="r jf jg" width="25" height="25"><path d="M5 12.5c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59.55 0 1.02-.2 1.41-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.59-1.41A1.93 1.93 0 0 0 7 10.5c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41zm5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59.55 0 1.02-.2 1.41-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59-.39.39-.58.86-.58 1.41zm5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59.56 0 1.03-.2 1.42-.59.39-.39.58-.86.58-1.41 0-.55-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59-.39.39-.58.86-.58 1.41z" fill-rule="evenodd"></path></svg></button></div></div></div></div></div></div><p id="ca09" class="pw-post-body-paragraph jh ji gu jj b ht jk jl hw jm jn jo jp jq jr js jt ju jv jw jx jy gn hr" data-selectable-paragraph="">Whether it is in computer vision, natural language processing or image generation, deep neural networks yield the state of the art. However, their cost in terms of computational power, memory or energy consumption can be prohibitive, making some of them downright unaffordable for most limited hardware. Yet, many domains would benefit from neural networks, hence the need to reduce their cost while maintaining their performance.</p><p id="375f" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">That is the whole point of neural n<span id="rmm"><span id="rmm"><span id="rmm"><span id="rmm"><span id="rmm"><span id="rmm"><span id="rmm"><span id="rmm"><span id="rmm"><span id="rmm"><span id="rmm"><span id="rmm"><span id="rmm"><span id="rmm"><span id="rmm"><span id="rmm">e</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>tworks compression. This field counts multiple families of methods, such as quantization [11], factorization [13], distillation [32] or, and this will be the focus of this post, pruning.</p><p id="24e1" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">Neural network pruning is a method that revolves around the intuitive idea of removing superfluous parts of a network that performs well but costs a lot of resources. Indeed, even though large neural networks have proven countless times how well they could learn, it turns out that not all of their parts are still useful after the training process is over. The idea is to eliminate these parts without impacting the network’s performance.</p><p id="9a45" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">Unfortunately, the dozens, if not hundreds, of papers published each year are revealing the hidden complexity of a supposedly straight-forward idea. Indeed, a quick overview of the literature yields countless ways of identifying said useless parts or removing them before, during or after training; it even turns out that not all kinds of pruning actually allow for accelerating neural networks, which is supposed to be the whole point.</p><p id="b038" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">The goal of this post is to provide a solid foundation to tackle the intimidatingly wild literature around neural network pruning. We will review successively three questions that seem to be at the core of the whole domain: “What kind of part should I prune?”, “How to tell which parts can be pruned?” and “<mark class="xu xv ex">How to prune parts without harming the network?</mark>”. To sum it up, we will detail <strong class="jj gv">pruning structures</strong>, <strong class="jj gv">pruning criteria</strong> and <strong class="jj gv">pruning methods</strong>.</p><h1 id="1f16" class="ke kf gu bf kg kh ki jk kj kk kl jm km kn ko kp kq kr ks kt ku kv kw kx ky kz hr" data-selectable-paragraph="">1 — Pruning structures</h1><h1 id="8cb0" class="ke kf gu bf kg kh ki jk kj kk kl jm km kn ko kp kq kr ks kt ku kv kw kx ky kz hr" data-selectable-paragraph="">1.1 — Unstructured pruning</h1><p id="fdc8" class="pw-post-body-paragraph jh ji gu jj b ht la jk jl hw lb jm jn jo lc jp jq jr ld js jt ju le jv jw jy gn hr" data-selectable-paragraph="">When talking about the cost of neural networks, the count of parameters is surely one of the most widely used metrics, along with FLOPS (floating-point operations per second). It is indeed intimidating to see networks displaying astronomical amounts of weights (up to billions for some), often correlated with stellar performance. Therefore, it is quite intuitive to aim at reducing directly this count by removing parameters themselves. Actually, pruning connections is one of the most widespread paradigms in the literature, enough to be considered as the default framework when dealing with pruning. The seminal work of Han et al.[26] presented this kind of pruning and served as a basis for numerous contributions [18, 21, 25].</p><p id="462b" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">Directly pruning parameters has many advantages. First, it is simple, since replacing the value of their weight with zero, within the parameter tensors, is enough to prune a connection. Widespread deep learning frameworks, such as Pytorch, allow to easily access all the parameters of a network, making it extremely simple to implement. Still, the greatest advantage of pruning connections remains yet that they are the smallest, most fundamental elements of networks and, therefore, they are numerous enough to prune them in large quantities without impacting performance. Such a fine granularity allows pruning very subtle patterns, up to parameters within convolution kernels, for example. As pruning weights is not limited by any constraint at all and is the finest way to prune a network, such a paradigm is called <strong class="jj gv">unstructured pruning</strong>.</p><p id="67a2" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">However, this method presents a major, fatal drawback: most frameworks and hardware cannot accelerate sparse matrices’ computation, meaning that no matter how many zeros you fill the parameter tensors with, it will not impact the actual cost of the network. What does impact it, however, is pruning in a way that directly alters the very architecture of the network, which any framework can handle.</p><figure class="lg lh li lj lk ll ga gb paragraph-image"><div role="button" tabindex="0" class="lm ln at lo v lp"><div class="ga gb lf"><div class="lu s at lv"><div class="lw lx s"><div class="oz ua es ff fb fl v lr ls lt"><img alt="" class="es ff fb fl v ly lz ae" src="https://miro.medium.com/max/60/1*7qwYH1r-h6VOGiE6C2tpGg.png?q=20" width="700" height="414" role="presentation"></div><img alt="" class="fc lq es ff fb fl v c" width="700" height="414" role="presentation"><noscript><img alt="" class="es ff fb fl v" src="https://miro.medium.com/max/1400/1*7qwYH1r-h6VOGiE6C2tpGg.png" width="700" height="414" srcSet="https://miro.medium.com/max/552/1*7qwYH1r-h6VOGiE6C2tpGg.png 276w, https://miro.medium.com/max/1104/1*7qwYH1r-h6VOGiE6C2tpGg.png 552w, https://miro.medium.com/max/1280/1*7qwYH1r-h6VOGiE6C2tpGg.png 640w, https://miro.medium.com/max/1400/1*7qwYH1r-h6VOGiE6C2tpGg.png 700w" sizes="700px" role="presentation"/></noscript></div></div></div></div><figcaption class="ma mb gc ga gb mc md bf b bg bh dx" data-selectable-paragraph="">Difference between unstructured (left) and structured (right) pruning: structured pruning removes both convolution filters and rows of kernels instead of just pruning connections. This leads to fewer feature maps within intermediate representations. (image by author)</figcaption></figure><h2 id="01ae" class="me kf gu bf kg mf mg hv kj mh mi hy km hz mj ib kq ic mk ie ku if ml ih ky mm hr" data-selectable-paragraph="">1.2 — Structured pruning</h2><p id="d73b" class="pw-post-body-paragraph jh ji gu jj b ht la jk jl hw lb jm jn jo lc jp jq jr ld js jt ju le jv jw jy gn hr" data-selectable-paragraph="">This is the reason why many works have focused on pruning larger structures, such as whole neurons [36] or, for its direct equivalent within the more modern deep convolutional networks, convolution filters [40, 41, 66]. Filter pruning allows for an exploitable and yet fine enough granularity, as large networks tend to include numerous convolution layers, each counting up to hundreds or thousands of filters. Not only does removing such structures result in sparse layers that can be directly instantiated as thinner ones, but doing so also eliminates the feature maps that are the outputs of such filters.</p><p id="4a73" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">Therefore, not only are such networks lighter to store, due to fewer parameters, but also they require less computations and generate lighter intermediate representations, hence needing less memory during runtime. Actually, it is sometimes more beneficial to reduce bandwidth rather than the parameter count. Indeed, for tasks that involve large images, such as semantic segmentation or object detection, intermediate representations may be prohibitively memory-consuming, way more than the network itself. For these reasons, filter pruning is now seen as the default kind of <strong class="jj gv">structured pruning</strong>.</p><p id="b13b" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">Yet, when applying such a pruning, one should pay attention to the following aspects. Let’s consider how a convolution layer is built: for <em class="mn">Cin</em> input channels and <em class="mn">Cout</em> output ones, a convolution layer is made of <em class="mn">Cout</em> filters, each counting <em class="mn">Cin</em> kernels; each filter outputs one feature map and within each filter, one kernel is dedicated to each input channel. Considering this architecture, and acknowledging a regular convolutional network basically stacks convolution layers, when pruning whole filters, one may observe that pruning a filter, and then the feature map it outputs, actually results in pruning the corresponding kernels in the ensuing layer too. That means that, when pruning filters, one may actually prune twice the amount of parameters thought to be removed in the first place.</p><p id="920a" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">Let’s consider too that, when a whole layer happens to get pruned (which tends to happen because of layer collapse [62], but does not always break the network, depending on the architecture), the previous layer’s outputs are now totally unconnected, hence pruned too: pruning a whole layer may actually prune all its previous layers whose outputs are not somehow connected elsewhere (because of residual connections [28] or whole parallel paths [61]). Therefore, <strong class="jj gv">when pruning filters, one should consider computing the exact number of actually pruned parameters</strong>. Indeed, pruning the same amount of filters, depending on their distribution within the architecture, may not lead to the same actual amount of pruned parameters, making any result impossible to compare with.</p><p id="64ad" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">Before changing topic, let’s just mention that, albeit a minority, some works focus on pruning convolution kernels, intra-kernel structures [2,24, 46] or even <a class="ek mo" href="https://developer.nvidia.com/blog/accelerating-inference-with-sparsity-using-ampere-and-tensorrt/" rel="noopener ugc nofollow" target="_blank">specific parameter-wise structures</a>. However, such structures need special implementations to lead to any kind of speedup (as for unstructured pruning). Another kind of exploitable structure, though, is to turn convolutions into “shift layers” by pruning all but one parameter in each kernel, which can then be summed up as a combination of a shifting operation and a 1 × 1 convolution [24].</p><figure class="lg lh li lj lk ll ga gb paragraph-image"><div role="button" tabindex="0" class="lm ln at lo v lp"><div class="ga gb mp"><div class="lu s at lv"><div class="mq lx s"><div class="oz ua es ff fb fl v lr ls lt"><img alt="" class="es ff fb fl v ly lz ae" src="https://miro.medium.com/max/60/1*o0Qh-ORMytWTA2xdCFbPiQ.png?q=20" width="700" height="602" role="presentation"></div><img alt="" class="fc lq es ff fb fl v c" width="700" height="602" role="presentation"><noscript><img alt="" class="es ff fb fl v" src="https://miro.medium.com/max/1400/1*o0Qh-ORMytWTA2xdCFbPiQ.png" width="700" height="602" srcSet="https://miro.medium.com/max/552/1*o0Qh-ORMytWTA2xdCFbPiQ.png 276w, https://miro.medium.com/max/1104/1*o0Qh-ORMytWTA2xdCFbPiQ.png 552w, https://miro.medium.com/max/1280/1*o0Qh-ORMytWTA2xdCFbPiQ.png 640w, https://miro.medium.com/max/1400/1*o0Qh-ORMytWTA2xdCFbPiQ.png 700w" sizes="700px" role="presentation"/></noscript></div></div></div></div><figcaption class="ma mb gc ga gb mc md bf b bg bh dx" data-selectable-paragraph="">The danger of structured pruning: altering the input and output dimensions of layers can lead to some discrepancies. If on the left, both layers output the same number of feature maps, that can be summed up well afterward, their pruned counterparts on the right produce intermediate representations of different dimensions, that cannot be summed up without processing them. (image by author)</figcaption></figure><h1 id="7400" class="ke kf gu bf kg kh ki jk kj kk kl jm km kn ko kp kq kr ks kt ku kv kw kx ky kz hr" data-selectable-paragraph="">2 — Pruning criteria</h1><p id="af47" class="pw-post-body-paragraph jh ji gu jj b ht la jk jl hw lb jm jn jo lc jp jq jr ld js jt ju le jv jw jy gn hr" data-selectable-paragraph="">Once one has decided what kind of structure to prune, the next question one may ask could be: “Now, how do I figure out which ones to keep and which ones to prune?”. To answer that one needs a proper pruning criteria, that will rank the relative importance of the parameters, filters or else.</p><h2 id="a3f6" class="me kf gu bf kg mf mg hv kj mh mi hy km hz mj ib kq ic mk ie ku if ml ih ky mm hr" data-selectable-paragraph="">2.1 — Weight magnitude criterion</h2><p id="ab7c" class="pw-post-body-paragraph jh ji gu jj b ht la jk jl hw lb jm jn jo lc jp jq jr ld js jt ju le jv jw jy gn hr" data-selectable-paragraph="">One criterion that is quite intuitive and surprisingly efficient is pruning weights whose absolute value (or “magnitude”) is the smallest. Indeed, under the constraint of a weight-decay, those which do not contribute significantly to the function are expected to have their magnitude shrink during training. Therefore, the superfluous weights are expected to be those of lesser magnitude [8]. Notwithstanding its simplicity, the magnitude criterion is still widely used in modern works [21, 26, 58], making it a staple of the domain.</p><p id="b739" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">However, although this criterion seems trivial to implement in the case of unstructured pruning, one may wonder how to adapt it to structured pruning. One straightforward way is to order filters depending on their norm (L 1 or L 2 for example) [40, 70]. If this method is quite straightforward one may desire to encapsulate multiple sets of parameters within one measure: for example, a convolutional filter, its bias and its batch-normalization parameters together, or even corresponding filters within parallel layers whose outputs are then fused and whose channels we would like to reduce.</p><p id="44f2" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">One way to do that, without having to compute the combined norm of these parameters, involves inserting a learnable multiplicative parameter for each feature map after each set of layers you want to prune. This gate, when reduced to zero, effectively prunes the whole set of parameters responsible for this channel and the magnitude of this gate accounts for the importance of all of them. The method hence consists in pruning the gates of lesser magnitude [36, 41].</p><h2 id="a4d6" class="me kf gu bf kg mf mg hv kj mh mi hy km hz mj ib kq ic mk ie ku if ml ih ky mm hr" data-selectable-paragraph="">2.2 — Gradient magnitude pruning</h2><p id="e034" class="pw-post-body-paragraph jh ji gu jj b ht la jk jl hw lb jm jn jo lc jp jq jr ld js jt ju le jv jw jy gn hr" data-selectable-paragraph="">Magnitude of the weight is not the only popular criterion (or family of criteria) that exists. Actually, the other main criterion to have lasted up to now is the magnitude of the gradient. Indeed, back in the 80's some fundamental works [37, 53] theorized, through a Taylor decomposition of the impact of removing a parameter on the loss, that some metrics, derived from the back-propagated gradient, may provide a good way to determine which parameters could be pruned without damaging the network.</p><p id="50c3" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">More modern implementations of this criterion [4, 50] actually accumulate gradients over a minibatch of training data and prune on the basis of the product between this gradient and the corresponding weight of each parameter. This criterion can be applied to the aforementioned gates too [49].</p><h2 id="f74e" class="me kf gu bf kg mf mg hv kj mh mi hy km hz mj ib kq ic mk ie ku if ml ih ky mm hr" data-selectable-paragraph="">2.3 — Global or local pruning</h2><p id="7f2b" class="pw-post-body-paragraph jh ji gu jj b ht la jk jl hw lb jm jn jo lc jp jq jr ld js jt ju le jv jw jy gn hr" data-selectable-paragraph="">One final aspect to take into consideration is whether the chosen criterion is applied globally to all parameters or filters of the network, or if it is computed independently for each layer. While global pruning has proven many times to yield better results, it can lead to layer collapse [62]. A simple way to avoid this problem is to resort to layer-wise local pruning, namely pruning the same rate at each layer, when the used method cannot prevent layer collapse.</p><figure class="lg lh li lj lk ll ga gb paragraph-image"><div role="button" tabindex="0" class="lm ln at lo v lp"><div class="ga gb mr"><div class="lu s at lv"><div class="ms lx s"><div class="oz ua es ff fb fl v lr ls lt"><img alt="" class="es ff fb fl v ly lz ae" src="https://miro.medium.com/max/60/1*rMLCgVa380ZBcgM0Iqg84Q.png?q=20" width="700" height="301" role="presentation"></div><img alt="" class="fc lq es ff fb fl v c" width="700" height="301" role="presentation"><noscript><img alt="" class="es ff fb fl v" src="https://miro.medium.com/max/1400/1*rMLCgVa380ZBcgM0Iqg84Q.png" width="700" height="301" srcSet="https://miro.medium.com/max/552/1*rMLCgVa380ZBcgM0Iqg84Q.png 276w, https://miro.medium.com/max/1104/1*rMLCgVa380ZBcgM0Iqg84Q.png 552w, https://miro.medium.com/max/1280/1*rMLCgVa380ZBcgM0Iqg84Q.png 640w, https://miro.medium.com/max/1400/1*rMLCgVa380ZBcgM0Iqg84Q.png 700w" sizes="700px" role="presentation"/></noscript></div></div></div></div><figcaption class="ma mb gc ga gb mc md bf b bg bh dx" data-selectable-paragraph="">Difference between local pruning (left) and global pruning (right): local pruning applies the same rate to each layer while global applies it on the whole network at once. (image by author)</figcaption></figure><h1 id="703c" class="ke kf gu bf kg kh ki jk kj kk kl jm km kn ko kp kq kr ks kt ku kv kw kx ky kz hr" data-selectable-paragraph="">3 — Pruning method</h1><p id="e967" class="pw-post-body-paragraph jh ji gu jj b ht la jk jl hw lb jm jn jo lc jp jq jr ld js jt ju le jv jw jy gn hr" data-selectable-paragraph="">Now that we have got our pruning structure and criterion, the only parameter left is which method should we use to prune a network. This is actually the topic on which the literature can be the most confusing, as each paper will bring its own quirks and gimmicks, so much that one may get lost between what is methodically relevant and what is just a specificity of a given paper.</p><p id="7b8d" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">This is why we will thematically overview some of the most popular families of method to prune neural networks, in an order that highlights the evolution of the use of sparsity during training.</p><h2 id="45d5" class="me kf gu bf kg mf mg hv kj mh mi hy km hz mj ib kq ic mk ie ku if ml ih ky mm hr" data-selectable-paragraph="">3.1 — The classic framework: train, prune and fine-tune</h2><p id="f197" class="pw-post-body-paragraph jh ji gu jj b ht la jk jl hw lb jm jn jo lc jp jq jr ld js jt ju le jv jw jy gn hr" data-selectable-paragraph="">The first basic framework to know is the train, prune and fine-tune method, which obviously involves 1) training the network 2) pruning it by setting to 0 all parameters targeted by the pruning structures and criterion (these parameters cannot recover afterwhile) and 3) training the network for a few extra epochs, with the lowest learning rate, to give it a chance to recover from the loss in performance induced by pruning. Usually, these last two steps can be iterated, with each time a growing pruning rate.</p><p id="50e4" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">The method proposed by Han et al. [26] applies this method, with 5 iterations between pruning and fine-tuning, to weight magnitude pruning. Iterating has shown to improve performance, at the cost of extra computation and training time. This simple framework serves as a basis for many works [26, 40, 41, 50, 66] and can be seen as the default method over which all the others have built.</p><h2 id="62f4" class="me kf gu bf kg mf mg hv kj mh mi hy km hz mj ib kq ic mk ie ku if ml ih ky mm hr" data-selectable-paragraph="">3.2 — Extending the classic framework</h2><p id="3d86" class="pw-post-body-paragraph jh ji gu jj b ht la jk jl hw lb jm jn jo lc jp jq jr ld js jt ju le jv jw jy gn hr" data-selectable-paragraph="">While not straying too far, some methods have brought significant modifications to the aforementioned classic framework by Han et al. [26]. Gale et al. [21] have pushed the principle of iterations further by removing an increasing amount of weights progressively all along the training process, which allows benefiting from the advantages of iterations and to remove the whole fine-tuning process. He et al. [29] reduce prunable filters to 0, at each epoch, while not preventing them from learning and being updated afterward, in order to let their weights grow back after pruning while enforcing sparsity during training.</p><p id="67de" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">Finally, the method of Renda et al. [58] involves fully retraining a network once it is pruned. Unlike fine-tuning, which is performed at the lowest learning-rate, retraining follows the same learning-rate schedule as training, hence its name: “Learning-Rate Rewinding”. This retraining has shown to yield better performance than mere fine-tuning, at a significantly higher cost.</p><h2 id="062d" class="me kf gu bf kg mf mg hv kj mh mi hy km hz mj ib kq ic mk ie ku if ml ih ky mm hr" data-selectable-paragraph="">3.3 — Pruning at initialization</h2><p id="6ba9" class="pw-post-body-paragraph jh ji gu jj b ht la jk jl hw lb jm jn jo lc jp jq jr ld js jt ju le jv jw jy gn hr" data-selectable-paragraph="">In order to speed up training, avoid fine-tuning and prevent any alteration of the architecture during or after training, multiple works have focused on pruning before training. In the wake of SNIP [39], many works have studied the use of the work of Le Cun et al. [37] or of Mozer and Smolensky [53] to prune at initialization [12, 64], including intensive theoretical studies [27, 38, 62]. However, Optimal Brain Damage [37] relies on multiple approximations including an “extremal” approximation that “assumes that parameter deletion will be performed after training has converged” [37]; this fact is rarely mentioned, even among works that are based on it. Some works have raised reservations about the ability of such methods to generate masks whose relevance outshines random ones of similar distribution per layer [20].</p><p id="98e1" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">Another family of methods that study the relationship between pruning and initialization gravitates around the “Lottery Ticket Hypothesis” [18]. This hypothesis states that “randomly-initialized, dense neural network contains a subnet-work that is initialized such that — when trained in isolation — it can match the test accuracy of the original network after training for at most the same number of iterations”. In practice, this literature studies how well a pruning mask, defined using an already converged network, can be applied to the network back when it was just initialized. Multiple works have expanded, stabilized or studied this hypothesis [14, 19, 45, 51, 69]. However, once again multiple works tend to question the validity of the hypothesis and of the method used to study it [21, 42] and some even tend to show that its benefits rather came from the principle of fully training with the definitive mask instead of a hypothetical “Winning Ticket” [58].</p><figure class="lg lh li lj lk ll ga gb paragraph-image"><div role="button" tabindex="0" class="lm ln at lo v lp"><div class="ga gb mt"><div class="lu s at lv"><div class="mu lx s"><div class="oz ua es ff fb fl v lr ls lt"><img alt="" class="es ff fb fl v ly lz ae" src="https://miro.medium.com/max/60/1*ALVyE5U7jC692UGVKCVY8Q.png?q=20" width="700" height="286" role="presentation"></div><img alt="" class="fc lq es ff fb fl v c" width="700" height="286" role="presentation"><noscript><img alt="" class="es ff fb fl v" src="https://miro.medium.com/max/1400/1*ALVyE5U7jC692UGVKCVY8Q.png" width="700" height="286" srcSet="https://miro.medium.com/max/552/1*ALVyE5U7jC692UGVKCVY8Q.png 276w, https://miro.medium.com/max/1104/1*ALVyE5U7jC692UGVKCVY8Q.png 552w, https://miro.medium.com/max/1280/1*ALVyE5U7jC692UGVKCVY8Q.png 640w, https://miro.medium.com/max/1400/1*ALVyE5U7jC692UGVKCVY8Q.png 700w" sizes="700px" role="presentation"/></noscript></div></div></div></div><figcaption class="ma mb gc ga gb mc md bf b bg bh dx" data-selectable-paragraph="">Comparison between the classic “train, prune and fine-tune” framework [26], the lottery ticket experiment [18] and learning rate rewinding [58]. (image by author)</figcaption></figure><h2 id="0d30" class="me kf gu bf kg mf mg hv kj mh mi hy km hz mj ib kq ic mk ie ku if ml ih ky mm hr" data-selectable-paragraph="">3.4 — Sparse training</h2><p id="fd21" class="pw-post-body-paragraph jh ji gu jj b ht la jk jl hw lb jm jn jo lc jp jq jr ld js jt ju le jv jw jy gn hr" data-selectable-paragraph="">The previous methods are linked by a seemingly shared underlying theme: training under sparsity constraints. This principle is at the core of a family of methods, called <strong class="jj gv">sparse training</strong>, which consists in enforcing a constant rate of sparsity during training while its distribution varies and is progressively adjusted. Introduced by Mocanu et al. [47], it involves: 1) initializing the network with a random mask that prunes a certain proportion of the network 2) training this pruned network during one epoch 3) pruning a certain amount of weights of lower magnitude and 4) regrowing the same amount of random weights.</p><p id="4cad" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">That way, the pruning mask, at first random, is progressively adjusted to target the least import weights while enforcing sparsity all throughout training. The sparsity level can be the same for each layer [47] or global [52]. Other methods have extended sparse training by using a certain criterion to regrow weights instead of choosing them randomly [15, 17].</p><figure class="lg lh li lj lk ll ga gb paragraph-image"><div role="button" tabindex="0" class="lm ln at lo v lp"><div class="ga gb mr"><div class="lu s at lv"><div class="mv lx s"><div class="oz ua es ff fb fl v lr ls lt"><img alt="" class="es ff fb fl v ly lz ae" src="https://miro.medium.com/max/60/1*3hP9xPMOSnsxqtLIvGrhOA.png?q=20" width="700" height="416" role="presentation"></div><img alt="" class="fc lq es ff fb fl v c" width="700" height="416" role="presentation"><noscript><img alt="" class="es ff fb fl v" src="https://miro.medium.com/max/1400/1*3hP9xPMOSnsxqtLIvGrhOA.png" width="700" height="416" srcSet="https://miro.medium.com/max/552/1*3hP9xPMOSnsxqtLIvGrhOA.png 276w, https://miro.medium.com/max/1104/1*3hP9xPMOSnsxqtLIvGrhOA.png 552w, https://miro.medium.com/max/1280/1*3hP9xPMOSnsxqtLIvGrhOA.png 640w, https://miro.medium.com/max/1400/1*3hP9xPMOSnsxqtLIvGrhOA.png 700w" sizes="700px" role="presentation"/></noscript></div></div></div></div><figcaption class="ma mb gc ga gb mc md bf b bg bh dx" data-selectable-paragraph="">Sparse training cuts and grows different weights periodically during training, which leads to an adjusted mask that should target only relevant parameters. (image by author)</figcaption></figure><h2 id="f9f3" class="me kf gu bf kg mf mg hv kj mh mi hy km hz mj ib kq ic mk ie ku if ml ih ky mm hr" data-selectable-paragraph="">3.5 — Mask learning</h2><p id="88ec" class="pw-post-body-paragraph jh ji gu jj b ht la jk jl hw lb jm jn jo lc jp jq jr ld js jt ju le jv jw jy gn hr" data-selectable-paragraph="">Instead of relying on arbitrary criteria to prune or regrow weights, multiple methods focus on learning a pruning mask during training. Two types of methods seem to prevail in this domain: 1) mask learning through separate networks or layers and 2) mask learning through auxiliary parameters. Multiple kinds of strategies can fit in the methods of the first type: training separate agents to prune as many filters of a layer as possible while maximizing the accuracy [33], inserting attention-based layers [68] or using reinforcement learning [30]. The second kind of methods aims at considering pruning as an optimization problem that tends to minimize both the L0 norm of the network and its supervised loss.</p><p id="1475" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">Since the L0 is non-differentiable, the various methods mainly involve circumventing this problem through the use of penalized auxiliary parameters that are multiplied with their corresponding parameter during the forward pass [59, 23]. Many methods [44, 60, 67] rely on a method analogous to that of “Binary Connect” [11], namely: applying stochastic gates over parameters whose values are each randomly drawn from their own Bernoulli distribution of parameter <em class="mn">p</em> that is learned using a “Straight Through Estimator” [3] or other means [44].</p><h2 id="7a36" class="me kf gu bf kg mf mg hv kj mh mi hy km hz mj ib kq ic mk ie ku if ml ih ky mm hr" data-selectable-paragraph="">3.6 — Penalty-based methods</h2><p id="b905" class="pw-post-body-paragraph jh ji gu jj b ht la jk jl hw lb jm jn jo lc jp jq jr ld js jt ju le jv jw jy gn hr" data-selectable-paragraph="">Many methods, instead of pruning connections manually or penalizing auxiliary parameters, rather apply various kinds of penalties to weights themselves to make them progressively shrink toward 0. This notion is actually pretty ancient [57], as weight-decay is already an essential element to the weight magnitude criterion. Beyond using a mere weight-decay, even back then multiple works focused on elaborating penalties specifically designed to enforce sparsity [55, 65]. Today, various methods apply different regularizations, on top of the weight decay, to increase further the sparsity (typically, using L 1 norm [41]).</p><p id="ba3b" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">Among modern works, multiple methods rely on the LASSO (Least Absolute Shrinkage and Selection Operator) [22, 31, 66] to prune weights or groups. Other methods develop penalties that target weak connections to increase the gap between the parameters to keep and those to prune, so that their removal has less impact [7, 16]. Some methods show that targeting a subset of weights with a penalization that grows all throughout training can progressively prune them and make their removal seamless [6, 9, 63]. The literature also counts a whole range of methods built around the principle of “Variational Dropout” [34], a method based on variational inference [5] applied to deep learning [35]. As a pruning method [48], it birthed multiple works that adapt its principle to structured pruning [43, 54].</p><h1 id="344e" class="ke kf gu bf kg kh ki jk kj kk kl jm km kn ko kp kq kr ks kt ku kv kw kx ky kz hr" data-selectable-paragraph="">4 — Available frameworks</h1><p id="d420" class="pw-post-body-paragraph jh ji gu jj b ht la jk jl hw lb jm jn jo lc jp jq jr ld js jt ju le jv jw jy gn hr" data-selectable-paragraph="">If most of these methods have to be implemented from scratch (or can be reused from the provided sources of each paper, if they do provide them), some frameworks exist to apply basic methods or make the aforementioned implementation easier.</p><h2 id="1145" class="me kf gu bf kg mf mg hv kj mh mi hy km hz mj ib kq ic mk ie ku if ml ih ky mm hr" data-selectable-paragraph="">4.1 — Pytorch</h2><p id="9c63" class="pw-post-body-paragraph jh ji gu jj b ht la jk jl hw lb jm jn jo lc jp jq jr ld js jt ju le jv jw jy gn hr" data-selectable-paragraph=""><em class="mn">Pytorch</em> [56] provide multiple quality-of-life features to help pruning networks. The provided tools allow to easily apply a mask to a network and maintain this mask during training, as well as it allows to easily revert that mask if needed. Pytorch also provide some basic pruning methods, such as global or local pruning, whether it is structured or not. Structured pruning can be applied on any dimension of the weights tensors, which lets pruning filters, rows of kernels or even some rows and columns inside kernels. Those in-built basic methods also allow pruning randomly or depending on various norms.</p><h2 id="3f1c" class="me kf gu bf kg mf mg hv kj mh mi hy km hz mj ib kq ic mk ie ku if ml ih ky mm hr" data-selectable-paragraph="">4.2 — Tensorflow</h2><p id="db73" class="pw-post-body-paragraph jh ji gu jj b ht la jk jl hw lb jm jn jo lc jp jq jr ld js jt ju le jv jw jy gn hr" data-selectable-paragraph="">The <em class="mn">Keras</em> [10] library from <em class="mn">Tensorflow</em> [1] provide some basic tools to prune weights of lower magnitudes. Such as in the work of Han et al [25], the efficiency of pruning is measured in terms of how much does the redundancy, introduced by all the inserted zeros, allows to compress the model better (which combines well with quantization).</p><h2 id="c61c" class="me kf gu bf kg mf mg hv kj mh mi hy km hz mj ib kq ic mk ie ku if ml ih ky mm hr" data-selectable-paragraph="">4.3 — ShrinkBench</h2><p id="29c2" class="pw-post-body-paragraph jh ji gu jj b ht la jk jl hw lb jm jn jo lc jp jq jr ld js jt ju le jv jw jy gn hr" data-selectable-paragraph="">Blalock et al. [4] provide in their work a custom library in an effort to help the community normalize how pruning algorithm are compared. Based on <em class="mn">Pytorch</em>, <em class="mn">ShrinkBench</em> aims at making the implementation of pruning methods easier while normalizing the conditions under which they are trained and tested. It provides different baselines, such as random pruning, global or layerwise and weight magnitude or gradient magnitude pruning.</p><h1 id="0db7" class="ke kf gu bf kg kh ki jk kj kk kl jm km kn ko kp kq kr ks kt ku kv kw kx ky kz hr" data-selectable-paragraph="">5 — Brief recap of reviewed methods</h1><p id="4f0a" class="pw-post-body-paragraph jh ji gu jj b ht la jk jl hw lb jm jn jo lc jp jq jr ld js jt ju le jv jw jy gn hr" data-selectable-paragraph="">In this article, many papers have been cited. Here is a simple table to roughly summarize what they do and what differentiates them (provided dates are those of first publication):</p><figure class="lg lh li lj lk ll"><div class="lu s at"><div class="mw lx s"></div></div></figure><h1 id="5fc5" class="ke kf gu bf kg kh ki jk kj kk kl jm km kn ko kp kq kr ks kt ku kv kw kx ky kz hr" data-selectable-paragraph="">6 — Conclusion</h1><p id="dbd7" class="pw-post-body-paragraph jh ji gu jj b ht la jk jl hw lb jm jn jo lc jp jq jr ld js jt ju le jv jw jy gn hr" data-selectable-paragraph="">In our quick overview of the literature, we saw that 1) pruning structures define which kind of gain to expect from pruning 2) pruning criteria are based on various theoretical or practical justifications and 3) pruning methods tend to revolve around introducing sparsity during training to reconcile performance and cost. We also saw that, even though its founding works date back from the late 80’s, neural network pruning is a very dynamic field that still experiences fundamental discoveries and new basic concepts today.</p><p id="8cda" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">Despite the daily contributions in the domain, there seems to be still plenty of room for exploration and innovation. If each subfamily of method can be seen as an attempt to answer a question (“How to regrow pruned weights ?”, “How to learn pruning masks through optimization ?”, “How to relax the weight removal by a softer mean ?”…), then the evolution of the literature seems to point out a certain direction: that of sparsity throughout training. This direction raises itself many questions, such as: “do pruning criteria work well on networks that haven’t converged yet?” or “how to tell the benefit of the choice of the weights to prune from that of training with any kind of sparsity from the start?”</p><h1 id="b0a7" class="ke kf gu bf kg kh ki jk kj kk kl jm km kn ko kp kq kr ks kt ku kv kw kx ky kz hr" data-selectable-paragraph="">References</h1><p id="333c" class="pw-post-body-paragraph jh ji gu jj b ht la jk jl hw lb jm jn jo lc jp jq jr ld js jt ju le jv jw jy gn hr" data-selectable-paragraph="">[1] Martı́n Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dandelion Mané, Rajat Monga, Sherry Moore, Derek Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Viégas, Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. TensorFlow: Large-scale machine learning on heterogeneous systems, 2015. Software available from tensorflow.org.</p><p id="1fba" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[2] Sajid Anwar, Kyuyeon Hwang, and Wonyong Sung. Structured pruning of deep convolutional neural networks. ACM Journal on Emerging Technologies in Computing Systems (JETC), 13(3):1–18, 2017.</p><p id="9ab6" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[3] Yoshua Bengio, Nicholas Léonard, and Aaron Courville. Estimating or propagating gradients through stochastic neurons for conditional computation. arXiv preprint arXiv:1308.3432, 2013.</p><p id="4225" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[4] Davis Blalock, Jose Javier Gonzalez Ortiz, Jonathan Frankle, and John Guttag. What is the state of neural network pruning? arXiv preprint arXiv:2003.03033, 2020.</p><p id="1893" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[5] David M Blei, Alp Kucukelbir, and Jon D McAuliffe. Variational inference: A review for statisticians. Journal of the American statistical Association, 112(518):859–877, 2017.</p><p id="4edf" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[6] Miguel A Carreira-Perpinán and Yerlan Idelbayev. “learning-compression” algorithms for neural net pruning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 8532–8541, 2018.</p><p id="5a92" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[7] Jing Chang and Jin Sha. Prune deep neural networks with the modified L1/2 penalty. IEEE Access, 7:2273–2280, 2018.</p><p id="7d74" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[8] Yves Chauvin. A back-propagation algorithm with optimal use of hidden units. In NIPS, volume 1, pages 519–526, 1988.</p><p id="2b0e" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[9] Yoojin Choi, Mostafa El-Khamy, and Jungwon Lee. Compression of deep convolutional neural networks under joint sparsity constraints. arXiv preprint arXiv:1805.08303, 2018.</p><p id="5860" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[10] Francois Chollet et al. Keras, 2015.</p><p id="a78f" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[11] Matthieu Courbariaux, Yoshua Bengio, and Jean-Pierre David. Binaryconnect: Training deep neural networks with binary weights during propagations. In NIPS, 2015.</p><p id="f314" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[12] Pau de Jorge, Amartya Sanyal, Harkirat S Behl, Philip HS Torr, Gregory Rogez, and Puneet K Dokania. Progressive skeletonization: Trimming more fat from a network at initialization. arXiv preprint arXiv:2006.09081, 2020.</p><p id="5849" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[13] Emily Denton, Wojciech Zaremba, Joan Bruna, Yann LeCun, and Rob Fergus. Exploiting linear structure within convolutional networks for efficient evaluation. In 28th Annual Conference on Neural Information Processing Systems 2014, NIPS 2014, pages 1269–1277. Neural information processing systems foundation, 2014.</p><p id="2aed" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[14] Shrey Desai, Hongyuan Zhan, and Ahmed Aly. Evaluating lottery tickets under distributional shifts. In Proceedings of the 2nd Workshop on Deep Learning Approaches for Low-Resource NLP (DeepLo 2019), pages 153–162, 2019.</p><p id="eb74" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[15] Tim Dettmers and Luke Zettlemoyer. Sparse networks from scratch: Faster training without losing performance. arXiv preprint arXiv:1907.04840, 2019.</p><p id="b415" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[16] Xiaohan Ding, Guiguang Ding, Xiangxin Zhou, Yuchen Guo, Jungong Han, and Ji Liu. Global sparse momentum sgd for pruning very deep neural networks. arXiv preprint arXiv:1909.12778, 2019.</p><p id="f184" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[17] Utku Evci, Trevor Gale, Jacob Menick, Pablo Samuel Castro, and Erich Elsen. Rigging the lottery: Making all tickets winners. In International Conference on Machine Learning, pages 2943–2952. PMLR, 2020.</p><p id="bf6f" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[18] Jonathan Frankle and Michael Carbin. The lottery ticket hypothesis: Finding sparse, trainable neural networks. arXiv preprint arXiv:1803.03635, 2018.</p><p id="3617" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[19] Jonathan Frankle, Gintare Karolina Dziugaite, Daniel M Roy, and Michael Carbin. Stabilizing the lottery ticket hypothesis. arXiv preprint arXiv:1903.01611, 2019.</p><p id="58c0" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[20] Jonathan Frankle, Gintare Karolina Dziugaite, Daniel M Roy, and Michael Carbin. Pruning neural networks at initialization: Why are we missing the mark? arXiv preprint arXiv:2009.08576, 2020.</p><p id="4f5f" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[21] Trevor Gale, Erich Elsen, and Sara Hooker. The state of sparsity in deep neural networks. arXiv preprint arXiv:1902.09574, 2019.</p><p id="74d8" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[22] Susan Gao, Xin Liu, Lung-Sheng Chien, William Zhang, and Jose M Alvarez. Vacl: Variance-aware cross-layer regularization for pruning deep residual networks. In Proceedings of the IEEE/CVF International Conference on Computer Vision Workshops, pages 0–0, 2019.</p><p id="a37e" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[23] Yiwen Guo, Anbang Yao, and Yurong Chen. Dynamic network surgery for efficient dnns. In NIPS, 2016.</p><p id="771a" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[24] Ghouthi Boukli Hacene, Carlos Lassance, Vincent Gripon, Matthieu Courbariaux, and Yoshua Bengio. Attention based pruning for shift networks. In 2020 25th International Conference on Pattern Recognition (ICPR), pages 4054–4061. IEEE, 2021.</p><p id="c933" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[25] Song Han, Huizi Mao, and William J Dally. Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding. arXiv preprint arXiv:1510.00149, 2015.</p><p id="a6e9" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[26] Song Han, Jeff Pool, John Tran, and William J Dally. Learning both weights and connections for efficient neural network. In NIPS, 2015.</p><p id="3b8d" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[27] Soufiane Hayou, Jean-Francois Ton, Arnaud Doucet, and Yee Whye Teh. Robust pruning at initialization.</p><p id="ff92" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[28] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770–778, 2016.</p><p id="9f85" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[29] Yang He, Guoliang Kang, Xuanyi Dong, Yanwei Fu, and Yi Yang. Soft filter pruning for accelerating deep convolutional neural networks. arXiv preprint arXiv:1808.06866, 2018.</p><p id="14d2" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[30] Yihui He, Ji Lin, Zhijian Liu, Hanrui Wang, Li-Jia Li, and Song Han. Amc: Automl for model compression and acceleration on mobile devices. In Proceedings of the European Conference on Computer Vision (ECCV), pages 784–800, 2018.</p><p id="af2f" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[31] Yihui He, Xiangyu Zhang, and Jian Sun. Channel pruning for accelerating very deep neural networks. In Proceedings of the IEEE International Conference on Computer Vision, pages 1389–1397, 2017.</p><p id="7371" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[32] Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distilling the knowledge in a neural network. stat, 1050:9, 2015.</p><p id="55ce" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[33] Qiangui Huang, Kevin Zhou, Suya You, and Ulrich Neumann. Learning to prune filters in convolutional neural networks. In 2018 IEEE Winter Conference on Applications of Computer Vision (WACV), pages 709–718. IEEE, 2018.</p><p id="3f8f" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[34] Diederik P Kingma, Tim Salimans, and Max Welling. Variational dropout and the local reparameterization trick. stat, 1050:8, 2015.</p><p id="93d7" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[35] Diederik P Kingma and Max Welling. Auto-encoding variational bayes. stat, 1050:1, 2014.</p><p id="38d1" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[36] John K Kruschke and Javier R Movellan. Benefits of gain: Speeded learning and minimal hidden layers in back-propagation networks. IEEE Transactions on systems, Man, and Cybernetics, 21(1):273–280, 1991.</p><p id="1b89" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[37] Yann LeCun, John S Denker, and Sara A Solla. Optimal brain damage. In Advances in neural information processing systems, pages 598–605, 1990.</p><p id="b9d6" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[38] Namhoon Lee, Thalaiyasingam Ajanthan, Stephen Gould, and Philip HS Torr. A signal propagation perspective for pruning neural networks at initialization. In International Conference on Learning Representations, 2019.</p><p id="c8c3" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[39] Namhoon Lee, Thalaiyasingam Ajanthan, and Philip HS Torr. Snip: Single-shot network pruning based on connection sensitivity. International Conference on Learning Representations, ICLR, 2019.</p><p id="fa53" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[40] Hao Li, Asim Kadav, Igor Durdanovic, Hanan Samet, and Hans Peter Graf. Pruning filters for efficient convnets. arXiv preprint arXiv:1608.08710, 2016.</p><p id="5975" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[41] Zhuang Liu, Jianguo Li, Zhiqiang Shen, Gao Huang, Shoumeng Yan, and Changshui Zhang. Learning efficient convolutional networks through network slimming. In Proceedings of the IEEE International Conference on Computer Vision, pages 2736–2744, 2017.</p><p id="3879" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[42] Zhuang Liu, Mingjie Sun, Tinghui Zhou, Gao Huang, and Trevor Darrell. Rethinking the value of network pruning. In International Conference on Learning Representations, 2018.</p><p id="8d02" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[43] C Louizos, K Ullrich, and M Welling. Bayesian compression for deep learning. In 31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA., 2017.</p><p id="eb44" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[44] Christos Louizos, Max Welling, and Diederik P Kingma. Learning sparse neural networks through l 0 regularization. arXiv preprint arXiv:1712.01312, 2017.</p><p id="4866" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[45] Eran Malach, Gilad Yehudai, Shai Shalev-Schwartz, and Ohad Shamir. Proving the lottery ticket hypothesis: Pruning is all you need. In International Conference on Machine Learning, pages 6682–6691. PMLR, 2020.</p><p id="235f" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[46] Huizi Mao, Song Han, Jeff Pool, Wenshuo Li, Xingyu Liu, Yu Wang, and William J Dally. Exploring the regularity of sparse structure in convolutional neural networks. arXiv preprint arXiv:1705.08922, 2017.</p><p id="6721" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[47] Decebal Constantin Mocanu, Elena Mocanu, Peter Stone, Phuong H Nguyen, Madeleine Gibescu, and Antonio Liotta. Scalable training of artificial neural networks with adaptive sparse connectivity inspired by network science. Nature communications, 9(1):1–12, 2018.</p><p id="2a85" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[48] Dmitry Molchanov, Arsenii Ashukha, and Dmitry Vetrov. Variational dropout sparsifies deep neural networks. In International Conference on Machine Learning, pages 2498–2507. PMLR, 2017.</p><p id="9f44" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[49] Pavlo Molchanov, Arun Mallya, Stephen Tyree, Iuri Frosio, and Jan Kautz. Importance estimation for neural network pruning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 11264–11272, 2019.</p><p id="1ef1" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[50] Pavlo Molchanov, Stephen Tyree, Tero Karras, Timo Aila, and Jan Kautz. Pruning convolutional neural networks for resource efficient inference. arXiv preprint arXiv:1611.06440, 2016.</p><p id="aa9b" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[51] Ari S Morcos, Haonan Yu, Michela Paganini, and Yuandong Tian. One ticket to win them all: generalizing lottery ticket initializations across datasets and optimizers. stat, 1050:6, 2019.</p><p id="79eb" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[52] Hesham Mostafa and Xin Wang. Parameter efficient training of deep convolutional neural networks by dynamic sparse reparameterization. In International Conference on Machine Learning, pages 4646–4655. PMLR, 2019.</p><p id="ce0a" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[53] Michael C Mozer and Paul Smolensky. Skeletonization: A technique for trimming the fat from a network via relevance assessment. In Advances in neural information processing systems, pages 107–115, 1989.</p><p id="d3f1" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[54] Kirill Neklyudov, Dmitry Molchanov, Arsenii Ashukha, and Dmitry Vetrov. Structured bayesian pruning via log-normal multiplicative noise. In Proceedings of the 31st International Conference on Neural Information Processing Systems, pages 6778–6787, 2017.</p><p id="bc88" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[55] Steven J Nowlan and Geoffrey E Hinton. Simplifying neural networks by soft weight-sharing. Neural Computation, 4(4):473–493, 1992.</p><p id="b046" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[56] Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic differentiation in pytorch. 2017.</p><p id="d7b3" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[57] Russell Reed. Pruning algorithms-a survey. IEEE transactions on Neural Networks, 4(5):740–747, 1993.</p><p id="3bf3" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[58] Alex Renda, Jonathan Frankle, and Michael Carbin. Comparing rewinding and fine-tuning in neural network pruning. arXiv preprint arXiv:2003.02389, 2020.</p><p id="3d25" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[59] Pedro Savarese, Hugo Silva, and Michael Maire. Winning the lottery with continuous sparsification. Advances in Neural Information Processing Systems, 33, 2020.</p><p id="5eb0" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[60] Suraj Srinivas, Akshayvarun Subramanya, and R Venkatesh Babu. Training sparse neural networks. In Proceedings of the IEEE conference on computer vision and pattern recognition workshops, pages 138–145, 2017.</p><p id="5fd8" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[61] Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going deeper with convolutions. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 1–9, 2015.</p><p id="1d5f" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[62] Hidenori Tanaka, Daniel Kunin, Daniel L Yamins, and Surya Ganguli. Pruning neural networks without any data by iteratively conserving synaptic flow. Advances in Neural Information Processing Systems, 33, 2020.</p><p id="44d2" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[63] Hugo Tessier, Vincent Gripon, Mathieu Léonardon, Matthieu Arzel, Thomas Hannagan, and David Bertrand. Rethinking weight decay for efficient neural network pruning. 2021.</p><p id="1727" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[64] Chaoqi Wang, Guodong Zhang, and Roger Grosse. Picking winning tickets before training by preserving gradient flow. In International Conference on Learning Representations, 2019.</p><p id="c94b" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[65] Andreas S Weigend, David E Rumelhart, and Bernardo A Huberman. Generalization by weight-elimination with application to forecasting. In Advances in neural information processing systems, pages 875–882, 1991.</p><p id="ce36" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[66] Wei Wen, Chunpeng Wu, Yandan Wang, Yiran Chen, and Hai Li. Learning structured sparsity in deep neural networks. In NIPS, 2016.</p><p id="45b5" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[67] Xia Xiao, Zigeng Wang, and Sanguthevar Rajasekaran. Autoprune: Automatic network pruning by regularizing auxiliary parameters. Advances in neural information processing systems, 32, 2019.</p><p id="8e2b" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[68] Kohei Yamamoto and Kurato Maeno. Pcas: Pruning channels with attention statistics for deep network compression. arXiv preprint arXiv:1806.05382, 2018.</p><p id="7479" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[69] Hattie Zhou, Janice Lan, Rosanne Liu, and Jason Yosinski. Deconstructing lottery tickets: Zeros, signs, and the supermask. arXiv preprint arXiv:1905.01067, 2019.</p><p id="726f" class="pw-post-body-paragraph jh ji gu jj b ht jz jk jl hw ka jm jn jo kb jp jq jr kc js jt ju kd jv jw jy gn hr" data-selectable-paragraph="">[70] Zhuangwei Zhuang, Mingkui Tan, Bohan Zhuang, Jing Liu, Yong Guo, Qingyao Wu, Junzhou Huang, and Jin-Hui Zhu. Discrimination-aware channel pruning for deep neural networks. In NeurIPS, 2018.</p></div></div></div></div></section></article><div class="fc gm fd ne v uk ff nc ng" data-test-id="post-sidebar"><div class="n p"><div class="au av aw ax ay az ba v"><div class="nh n ao"><div class="gm"><div><div class="ni s"><div class="nj s"><a class="ek el ce cf cg ch ci cj ck bq em en cl eo ep" href="https://medium.com/@hugo.tessier?source=post_sidebar--------------------------post_sidebar--------------" rel="noopener follow"><h2 class="bf kg dn bh gt hr gn">Hugo Tessier</h2></a></div><div class="nk s"><p class="bf b bg bh dx">PHD student in deep learning, working on neural network compression and, especially, pruning.</p></div><div class="nl n"><span><a class="bf b bg bh eb bj ec ed ee ef eg bq br bs eh ei bw bx by bz ca cb" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F524f24852f3c%2Faf816aaea61&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-network-pruning-101-af816aaea61&amp;user=Hugo+Tessier&amp;userId=524f24852f3c&amp;source=post_sidebar-524f24852f3c----af816aaea61---------------------follow_sidebar--------------" rel="noopener follow">Follow</a></span><div class="iq s"><div><div><div class="ca" role="tooltip" aria-hidden="false" aria-describedby="204" aria-labelledby="204"><div class="s"><span><a class="ek el ce cf cg ch ci cj ck bq em en cl eo ep" href="https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F71cc63d0ec07&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-network-pruning-101-af816aaea61&amp;newsletterV3=524f24852f3c&amp;newsletterV3Id=71cc63d0ec07&amp;user=Hugo+Tessier&amp;userId=524f24852f3c&amp;source=post_sidebar-----af816aaea61---------------------subscribe_user--------------" rel="noopener follow"><button class="bf b bg bh eb cj ec ed ee ef eg bq br bs eh ei bw bx by bz ca cb" aria-label="Subscribe"><svg width="38" height="38" viewBox="0 0 38 38" fill="none" class="vy nn no"><rect x="26.25" y="9.25" width="0.5" height="6.5" rx="0.25" stroke-width="0.5"></rect><rect x="29.75" y="12.25" width="0.5" height="6.5" rx="0.25" transform="rotate(90 29.75 12.25)" stroke-width="0.5"></rect><path d="M19.5 12.5h-7a1 1 0 0 0-1 1v11a1 1 0 0 0 1 1h13a1 1 0 0 0 1-1v-5" stroke-linecap="round"></path><path d="M11.5 14.5L19 20l4-3" stroke-linecap="round"></path></svg></button></a></span></div></div></div></div></div></div></div><div class="ny nz v n o bc oa"><div class="ob n"><div class="n o bc"><div class="pw-multi-vote-icon at oc od oe of og oh"><span><a class="ek el ce cf cg ch ci cj ck bq em en cl eo ep" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Faf816aaea61&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-network-pruning-101-af816aaea61&amp;user=Hugo+Tessier&amp;userId=524f24852f3c&amp;source=post_sidebar-----af816aaea61---------------------clap_sidebar--------------" rel="noopener follow"><div class="cj oi oj ok ex ol om oh r on oo"><svg width="29" height="29" aria-label="clap"><g fill-rule="evenodd"><path d="M13.74 1l.76 2.97.76-2.97zM16.82 4.78l1.84-2.56-1.43-.47zM10.38 2.22l1.84 2.56-.41-3.03zM22.38 22.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M9.1 22.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L6.1 15.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L6.4 11.26l-1.18-1.18a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L11.96 14a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L8.43 9.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L20.63 15c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM13 6.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 23 23.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></div></a></span></div><div class="pw-multi-vote-count s op oq or os ot ou ov"><div class="ow"><p class="bf b bg bh dx"><button class="ek el ce cf cg ch ci cj ck bq em en cl eo ep">258 </button></p></div></div></div></div><div class="ox ob s"><div class="n"><button class="ex oj cj" aria-label="responses"><div class="n o bc"><div class="n o"><div><div class="ca" role="tooltip" aria-hidden="false" aria-describedby="3" aria-labelledby="3"><svg width="25" height="25" aria-label="responses" class="oy oz ex oo"><path d="M19.07 21.12a6.33 6.33 0 0 1-3.53-1.1 7.8 7.8 0 0 1-.7-.52c-.77.21-1.57.32-2.38.32-4.67 0-8.46-3.5-8.46-7.8C4 7.7 7.79 4.2 12.46 4.2c4.66 0 8.46 3.5 8.46 7.8 0 2.06-.85 3.99-2.4 5.45a6.28 6.28 0 0 0 1.14 2.59c.15.21.17.48.06.7a.69.69 0 0 1-.62.38h-.03zm0-1v.5l.03-.5h-.03zm-3.92-1.64l.21.2a6.09 6.09 0 0 0 3.24 1.54 7.14 7.14 0 0 1-.83-1.84 5.15 5.15 0 0 1-.16-.75 2.4 2.4 0 0 1-.02-.29v-.23l.18-.15a6.6 6.6 0 0 0 2.3-4.96c0-3.82-3.4-6.93-7.6-6.93-4.19 0-7.6 3.11-7.6 6.93 0 3.83 3.41 6.94 7.6 6.94.83 0 1.64-.12 2.41-.35l.28-.08z" fill-rule="evenodd"></path></svg></div></div></div></div></button></div></div><div class="pa s"><span><a class="ek el ce cf cg ch ci cj ck bq em en cl eo ep" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Faf816aaea61&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-network-pruning-101-af816aaea61&amp;source=post_sidebar-----af816aaea61---------------------bookmark_sidebar--------------" rel="noopener follow"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="je"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></a></span></div></div></div></div></div></div></div></div><div class="fc gm mx fd my mz na nb nc nd"></div><div><div class="pb ll n ao p"><div class="n p"><div class="au av aw ax ay gr ba v"><div class="n cy"><div class="s"><p class="bf b pc bh dx">Thanks to <!-- -->Anne Bonner<!-- -->.&nbsp;</p></div></div><div class="n o cy"></div><div class="vz wa wb wc pz wd wp"><div class="wf s"><h2 class="bf kg mf hv kj mh hy km hz ib kq ic ie ku if ih ky hr">Sign up for The Variable</h2></div><div class="wg s"><h3 class="bf b pc bh hr">By Towards Data Science</h3></div><div class="wh wi s"><p class="bf b wj qb wk qe sy qh ta qk tc qn hr">Every Thursday, the Variable delivers the very best of Towards Data Science: from hands-on tutorials and cutting-edge research to original features you don't want to miss.&nbsp;<a class="ek el ce cf cg ch ci cj ck bq cl eo ep mo" href="https://medium.com/towards-data-science/newsletters/the-variable?source=newsletter_v3_promo--------------------------newsletter_v3_promo--------------" rel="noopener follow">Take a look.</a></p></div><div class="n cy"><div class="wl s wm"><span><a class="ek el ce cf cg ch ci cj ck bq em en cl eo ep" href="https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fd6fe9076899&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Ftowards-data-science%2Fnewsletters%2Fthe-variable&amp;collection=Towards+Data+Science&amp;collectionId=7f60cf5620c9&amp;newsletterV3=The+Variable&amp;newsletterV3Id=d6fe9076899&amp;user=Ludovic+Benistant&amp;userId=895063a310f4&amp;source=newsletter_v3_promo--------------------------newsletter_v3_promo----------d6fe9076899----" rel="noopener follow"><button class="bf b dn do eb wn ec ed ee ef eg bq br bs eh ei bw bx by bz ca cb"><div class="wo n o p"><span class="vy" aria-hidden="true"><svg width="38" height="38" viewBox="0 0 38 38" fill="none"><rect x="26.25" y="9.25" width="0.5" height="6.5" rx="0.25" stroke-width="0.5"></rect><rect x="29.75" y="12.25" width="0.5" height="6.5" rx="0.25" transform="rotate(90 29.75 12.25)" stroke-width="0.5"></rect><path d="M19.5 12.5h-7a1 1 0 0 0-1 1v11a1 1 0 0 0 1 1h13a1 1 0 0 0 1-1v-5" stroke-linecap="round"></path><path d="M11.5 14.5L19 20l4-3" stroke-linecap="round"></path></svg></span>Get this newsletter</div></button></a></span></div></div></div><div class="pe s"><ul class="cj ck"><li class="ca ps pt pu"><a href="/tagged/neural-networks" class="bf b pc pv dx pw px cb s nr">Neural Networks</a></li><li class="ca ps pt pu"><a href="/tagged/pruning" class="bf b pc pv dx pw px cb s nr">Pruning</a></li><li class="ca ps pt pu"><a href="/tagged/compression" class="bf b pc pv dx pw px cb s nr">Compression</a></li><li class="ca ps pt pu"><a href="/tagged/deep-learning" class="bf b pc pv dx pw px cb s nr">Deep Learning</a></li><li class="ca ps pt pu"><a href="/tagged/deep-dives" class="bf b pc pv dx pw px cb s nr">Deep Dives</a></li></ul></div><div class="pe s"><div class="n cp jc"><div class="n o bc"><div class="pf s"><span class="s pg ph pi e d"><div class="n o bc"><div class="pw-multi-vote-icon at oc od oe of og oh"><span><a class="ek el ce cf cg ch ci cj ck bq em en cl eo ep" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Faf816aaea61&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-network-pruning-101-af816aaea61&amp;user=Hugo+Tessier&amp;userId=524f24852f3c&amp;source=post_actions_footer-----af816aaea61---------------------clap_footer--------------" rel="noopener follow"><div class="cj oi oj ok ex ol om oh r on oo"><svg width="25" height="25" viewBox="0 0 25 25" aria-label="clap"><g fill-rule="evenodd"><path d="M11.74 0l.76 2.97.76-2.97zM14.81 3.78l1.84-2.56-1.42-.47zM8.38 1.22l1.84 2.56L9.8.75zM20.38 21.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M7.1 21.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L4.1 14.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L4.4 10.26 3.22 9.08a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L9.96 13a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L6.43 8.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L18.63 14c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM11 5.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 21 22.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></div></a></span></div><div class="pw-multi-vote-count s op oq or os pj pk pl"><div class="at pm ow"><p class="bf b bg bh hr"><button class="ek el ce cf cg ch ci cj ck bq em en cl eo ep">258<span class="s h g f pn po">&nbsp;claps</span></button><span class="s h g f pn po"></span></p></div></div></div></span><span class="s h g f pn po"><div class="n o bc"><div class="pw-multi-vote-icon at oc od oe of og oh"><span><a class="ek el ce cf cg ch ci cj ck bq em en cl eo ep" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Faf816aaea61&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-network-pruning-101-af816aaea61&amp;user=Hugo+Tessier&amp;userId=524f24852f3c&amp;source=post_actions_footer-----af816aaea61---------------------clap_footer--------------" rel="noopener follow"><div class="cj oi oj ok ex ol om oh r on oo"><svg width="25" height="25" viewBox="0 0 25 25" aria-label="clap"><g fill-rule="evenodd"><path d="M11.74 0l.76 2.97.76-2.97zM14.81 3.78l1.84-2.56-1.42-.47zM8.38 1.22l1.84 2.56L9.8.75zM20.38 21.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M7.1 21.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L4.1 14.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L4.4 10.26 3.22 9.08a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L9.96 13a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L6.43 8.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L18.63 14c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM11 5.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 21 22.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></div></a></span></div><div class="pw-multi-vote-count s op oq or os pj pk pl"><div class="ow"><p class="bf b bg bh dx"><button class="ek el ce cf cg ch ci cj ck bq em en cl eo ep">258 </button></p></div></div></div></span></div><div class="pp n"><div class="n"><button class="ex oj cj" aria-label="responses"><div class="n o bc"><div class="n o"><div><div class="ca" role="tooltip" aria-hidden="false" aria-describedby="14" aria-labelledby="14"><svg width="29" height="29" aria-label="responses" class="oy oz ex oo pq"><path d="M21.27 20.06a9.04 9.04 0 0 0 2.75-6.68C24.02 8.21 19.67 4 14.1 4S4 8.21 4 13.38c0 5.18 4.53 9.39 10.1 9.39 1 0 2-.14 2.95-.41.28.25.6.49.92.7a7.46 7.46 0 0 0 4.19 1.3c.27 0 .5-.13.6-.35a.63.63 0 0 0-.05-.65 8.08 8.08 0 0 1-1.29-2.58 5.42 5.42 0 0 1-.15-.75zm-3.85 1.32l-.08-.28-.4.12a9.72 9.72 0 0 1-2.84.43c-4.96 0-9-3.71-9-8.27 0-4.55 4.04-8.26 9-8.26 4.95 0 8.77 3.71 8.77 8.27 0 2.25-.75 4.35-2.5 5.92l-.24.21v.32a5.59 5.59 0 0 0 .21 1.29c.19.7.49 1.4.89 2.08a6.43 6.43 0 0 1-2.67-1.06c-.34-.22-.88-.48-1.16-.74z"></path></svg></div></div></div></div></button></div></div></div><div class="n o"><div class="tx s z"><div><div class="ca" role="tooltip" aria-hidden="false" aria-describedby="15" aria-labelledby="15"><button class="ek el ce cf cg ch ci cj ck bq em en cl eo ep" aria-label="Share on twitter"><svg width="30" height="30" viewBox="0 0 30 30" fill="none" class="ty tz"><path fill-rule="evenodd" clip-rule="evenodd" d="M15 27a12 12 0 1 0 0-24 12 12 0 0 0 0 24zm4.95-16.17a2.67 2.67 0 0 0-4.6 1.84c0 .2.03.41.05.62a7.6 7.6 0 0 1-5.49-2.82 3 3 0 0 0-.38 1.34c.02.94.49 1.76 1.2 2.23a2.53 2.53 0 0 1-1.2-.33v.04c0 1.28.92 2.36 2.14 2.62-.23.05-.46.08-.71.1l-.21-.02-.27-.03a2.68 2.68 0 0 0 2.48 1.86A5.64 5.64 0 0 1 9 19.38a7.62 7.62 0 0 0 4.1 1.19c4.9 0 7.58-4.07 7.57-7.58v-.39c.52-.36.97-.83 1.33-1.38-.48.23-1 .37-1.53.43.56-.33.96-.86 1.15-1.48-.5.31-1.07.53-1.67.66z" fill="#292929"></path></svg></button></div></div></div><div class="tx s z"><div><div class="ca" role="tooltip" aria-hidden="false" aria-describedby="16" aria-labelledby="16"><button class="ek el ce cf cg ch ci cj ck bq em en cl eo ep" aria-label="Share on facebook"><svg width="30" height="30" viewBox="0 0 30 30" fill="none" class="ty tz"><path fill-rule="evenodd" clip-rule="evenodd" d="M15 27a12 12 0 1 0 0-24 12 12 0 0 0 0 24zm-1.23-6.03V15.6H12v-2.15h1.77v-1.6C13.77 10 14.85 9 16.42 9c.75 0 1.4.06 1.58.08v1.93h-1.09c-.85 0-1.02.43-1.02 1.05v1.38h2.04l-.27 2.15H15.9V21l-2.13-.03z" fill="#292929"></path></svg></button></div></div></div><div class="tx s z"><div><div class="ca" role="tooltip" aria-hidden="false" aria-describedby="17" aria-labelledby="17"><button class="ek el ce cf cg ch ci cj ck bq em en cl eo ep" aria-label="Share on linkedin"><svg width="30" height="30" viewBox="0 0 30 30" fill="none" class="ty tz"><path fill-rule="evenodd" clip-rule="evenodd" d="M27 15a12 12 0 1 1-24 0 12 12 0 0 1 24 0zm-14.61 5v-7.42h-2.26V20h2.26zm-1.13-8.44c.79 0 1.28-.57 1.28-1.28-.02-.73-.5-1.28-1.26-1.28-.78 0-1.28.55-1.28 1.28 0 .71.49 1.28 1.25 1.28h.01zM15.88 20h-2.5s.04-6.5 0-7.17h2.5v1.02l-.02.02h.02v-.02a2.5 2.5 0 0 1 2.25-1.18c1.64 0 2.87 1.02 2.87 3.22V20h-2.5v-3.83c0-.97-.36-1.62-1.26-1.62-.69 0-1.1.44-1.28.87-.06.15-.08.36-.08.58v4z" fill="#292929"></path></svg></button></div></div></div><div class="s z"><div><div class="ca" role="tooltip" aria-hidden="false" aria-describedby="18" aria-labelledby="18"><button class="ek el ce cf cg ch ci cj ck bq em en cl eo ep"><svg width="30" height="30" viewBox="0 0 30 30" fill="none" class="ty tz"><path fill-rule="evenodd" clip-rule="evenodd" d="M15 27a12 12 0 1 0 0-24 12 12 0 0 0 0 24zM9.29 16.28c-.2.36-.29.75-.29 1.17a2.57 2.57 0 0 0 .78 1.84l1.01.96c.53.5 1.17.75 1.92.75s1.38-.25 1.9-.75l1.2-1.15.75-.71.51-.5a2.51 2.51 0 0 0 .72-2.34.7.7 0 0 0-.03-.18 2.74 2.74 0 0 0-.23-.5v-.02l-.08-.14-.02-.03-.02-.01a.33.33 0 0 0-.07-.1c0-.02-.01-.03-.03-.05a.2.2 0 0 0-.03-.03l-.03-.04v-.01l-.02-.03-.04-.03a.85.85 0 0 1-.13-.13l-.43-.42-.06.06-.9.84-.05.09a.26.26 0 0 0-.03.1l.37.38c.04.03.08.07.1.11l.01.01.01.03.02.01.04.1.03.04.06.1v.02l.01.02c.03.1.05.2.05.33a1 1 0 0 1-.12.49c-.07.13-.15.22-.22.29l-.88.85-.61.57-.95.92c-.22.2-.5.3-.82.3-.31 0-.58-.1-.8-.3l-.98-.96a1.15 1.15 0 0 1-.3-.42 1.4 1.4 0 0 1-.04-.35c0-.1.01-.2.04-.3a1 1 0 0 1 .3-.49l1.5-1.46v-.24c0-.21 0-.42.04-.6a3.5 3.5 0 0 1 .92-1.72c-.41.1-.78.32-1.11.62l-.01.02-.01.01-2.46 2.33c-.2.21-.35.4-.44.6h-.02c0 .02 0 .02-.02.02v.02l-.01.01zm3.92-1.8a1.83 1.83 0 0 0 .02.97c0 .06 0 .13.02.19.06.17.14.34.22.5v.02l.06.12.02.03.01.02.08.1c0 .02.02.03.04.05l.08.1h.01c0 .01 0 .03.02.03l.14.14.43.41.08-.06.88-.84.05-.09.03-.1-.36-.37a.4.4 0 0 1-.12-.13v-.02l-.02-.02-.05-.09-.04-.04-.04-.1v-.02l-.02-.02a1.16 1.16 0 0 1 .06-.82c.09-.14.16-.24.23-.3l.9-.85.6-.58.93-.92c.23-.2.5-.3.82-.3a1.2 1.2 0 0 1 .82.3l1 .96c.13.15.23.29.28.42a1.43 1.43 0 0 1 0 .66c-.03.17-.12.33-.26.48l-1.54 1.45.02.25a3.28 3.28 0 0 1-.96 2.32 2.5 2.5 0 0 0 1.1-.62l.01-.01 2.46-2.34c.19-.2.35-.4.46-.6l.02-.02v-.02h.01a2.45 2.45 0 0 0 .21-1.82 2.53 2.53 0 0 0-.7-1.19l-1-.96a2.68 2.68 0 0 0-1.91-.75c-.75 0-1.38.25-1.9.76l-1.2 1.14-.76.72-.5.49c-.4.37-.64.83-.74 1.37z" fill="#292929"></path></svg></button></div></div></div><div class="jd s z"><span><a class="ek el ce cf cg ch ci cj ck bq em en cl eo ep" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Faf816aaea61&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-network-pruning-101-af816aaea61&amp;source=post_actions_footer--------------------------bookmark_footer--------------" rel="noopener follow"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="je"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></a></span></div><div><div class="ca" role="tooltip" aria-hidden="false" aria-describedby="19" aria-labelledby="19"><div class="ca" aria-hidden="false"><button class="ek el ce cf cg ch ci cj ck bq em en cl eo ep" aria-label="More options"><svg class="r jf jg" width="25" height="25"><path d="M5 12.5c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59.55 0 1.02-.2 1.41-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.59-1.41A1.93 1.93 0 0 0 7 10.5c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41zm5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59.55 0 1.02-.2 1.41-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59-.39.39-.58.86-.58 1.41zm5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59.56 0 1.03-.2 1.42-.59.39-.39.58-.86.58-1.41 0-.55-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59-.39.39-.58.86-.58 1.41z" fill-rule="evenodd"></path></svg></button></div></div></div></div></div></div></div></div><div><div class="n p"><div class="au av aw ax ay gr ba v"></div></div><div class="s jc"><div class="py ny s pz"><div class="n p"><div class="au av aw ax ay gr ba v"><div class="n o cp"><h2 class="bf kg qa qb uc kj qd qe ud km qg qh ue kq qj qk uf ku qm qn ug ky lr qp qq uh qs ui qt hr"><a class="ek el ce cf cg ch ci cj ck bq em en cl eo ep" href="https://towardsdatascience.com/?source=follow_footer-----af816aaea61-----------------------------------" rel="noopener follow">More from Towards Data Science</a></h2><div class="ca" aria-hidden="false" aria-describedby="collectionFollowPopover" aria-labelledby="collectionFollowPopover"><span><a class="bf b bg bh eb bj ec ed ee ef eg bq br bs eh ei bw bx by bz ca cb" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Faf816aaea61&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-network-pruning-101-af816aaea61&amp;collection=Towards+Data+Science&amp;collectionId=7f60cf5620c9&amp;source=follow_footer-----af816aaea61---------------------follow_footer--------------" rel="noopener follow"><div class="n bc">Follow</div></a></span></div></div><div class="qu uj s"><p class="bf b bg bh dx">Your home for data science. A Medium publication sharing concepts, ideas and codes.</p></div></div></div></div></div><div class="qv s pz jc"><div class="n p"><div class="qw qx qy qz ra rb ba v"><div class="rc pb s"><div class="rb s mb"><a class="bf b bg bh eb bj ec ed ee ef eg bq br bs eh ei bw bx by bz ca cb" href="https://towardsdatascience.com/?source=follow_footer-----af816aaea61-----------------------------------" rel="noopener follow">Read more from <!-- -->Towards Data Science</a></div></div></div></div></div><div class="s gd jc"><div class="n p"><div class="au av aw ax ay az ba v"><div class="rd jx s"><div class="re rf rg jx s rh ri"><h2 class="bf kg mf hv kj mh hy km hz ib kq ic ie ku if ih ky hr">More From Medium</h2></div><div class="cv n bc cy rj rk rl rm rn ro rp rq rr rs rt ru rv rw rx"><div class="ry rz sa sb sc sd se sf sg sh si sj sk sl sm sn so sp sq sr ss"><div class="st su s"><div class="v fl"><div class="n cp"><div class="s sv oq os sw"><div class="sx s"><h2 class="bf kg qa qb kj qd qe km sy sz kq ta tb ku tc td ky hr"><a href="https://medium.com/@crawftv/analyzing-chess-with-pandas-to-learn-from-the-best-raise-my-rating-1bf22f28b83?source=post_internal_links---------0-------------------------------" rel="noopener follow">Analyzing Chess with Pandas to Learn from the Best and Raise My Rating.</a></h2></div><div class="o n"><div></div><div class="v s"><div class="n"><div style="flex:1"><span class="bf b bg bh hr"><div class="cw n o te"><span class="bf b pc bh hr"><a class="ek el ce cf cg ch ci cj ck bq tf cl eo ep" href="https://medium.com/@crawftv?source=post_internal_links---------0-------------------------------" rel="noopener follow">Crawford Collins</a></span></div></span></div></div></div></div></div><div class="eq pt s tg th"><a class="ek el ce cf cg ch ci cj ck bq em en cl eo ep s" href="https://medium.com/@crawftv/analyzing-chess-with-pandas-to-learn-from-the-best-raise-my-rating-1bf22f28b83?source=post_internal_links---------0-------------------------------" rel="noopener follow"><div class="lu s at lv"><div class="mw lx s"><div class="oz ua es ff fb fl v lr ls lt"><img class="es ff fb fl v ly lz ae" src="https://miro.medium.com/max/60/1*EYPZZTzfwaQauHg3O5cu6g.png?q=20" width="70" height="70" role="presentation"></div><img class="fc lq ti tj tk tl tm tn to tp tq tr c" width="70" height="70" role="presentation"><noscript><img class="ti tj tk tl tm tn to tp tq tr" src="https://miro.medium.com/fit/c/140/140/1*EYPZZTzfwaQauHg3O5cu6g.png" width="70" height="70" srcSet="https://miro.medium.com/fit/c/96/140/1*EYPZZTzfwaQauHg3O5cu6g.png 48w, https://miro.medium.com/fit/c/140/140/1*EYPZZTzfwaQauHg3O5cu6g.png 70w" sizes="70px" role="presentation"/></noscript></div></div></a></div></div></div></div></div><div class="ry rz sa sb sc sd se sf sg sh si sj sk sl sm sn so sp sq sr ss"><div class="st su s"><div class="v fl"><div class="n cp"><div class="s sv oq os sw"><div class="sx s"><h2 class="bf kg qa qb kj qd qe km sy sz kq ta tb ku tc td ky hr"><a href="https://maheshsai252.medium.com/exploring-udemy-courses-b6047b743220?source=post_internal_links---------1-------------------------------" rel="noopener follow">Exploring  Udemy Courses</a></h2></div><div class="o n"><div></div><div class="v s"><div class="n"><div style="flex:1"><span class="bf b bg bh hr"><div class="cw n o te"><span class="bf b pc bh hr"><a class="ek el ce cf cg ch ci cj ck bq tf cl eo ep" href="https://maheshsai252.medium.com/?source=post_internal_links---------1-------------------------------" rel="noopener follow">Sai Durga Mahesh</a></span></div></span></div></div></div></div></div><div class="eq pt s tg th"><a class="ek el ce cf cg ch ci cj ck bq em en cl eo ep s" href="https://maheshsai252.medium.com/exploring-udemy-courses-b6047b743220?source=post_internal_links---------1-------------------------------" rel="noopener follow"><div class="lu s at lv"><div class="mw lx s"><div class="oz ua es ff fb fl v lr ls lt"><img class="es ff fb fl v ly lz ae" src="https://miro.medium.com/max/60/1*JyzoGFreEkuApM7GVl9MBA.png?q=20" width="70" height="70" role="presentation"></div><img class="fc lq ti tj tk tl tm tn to tp tq tr c" width="70" height="70" role="presentation"><noscript><img class="ti tj tk tl tm tn to tp tq tr" src="https://miro.medium.com/fit/c/140/140/1*JyzoGFreEkuApM7GVl9MBA.png" width="70" height="70" srcSet="https://miro.medium.com/fit/c/96/140/1*JyzoGFreEkuApM7GVl9MBA.png 48w, https://miro.medium.com/fit/c/140/140/1*JyzoGFreEkuApM7GVl9MBA.png 70w" sizes="70px" role="presentation"/></noscript></div></div></a></div></div></div></div></div><div class="ry rz sa sb sc sd se sf sg sh si sj sk sl sm sn so sp sq sr ss"><div class="st su s"><div class="v fl"><div class="n cp"><div class="s sv oq os sw"><div class="sx s"><h2 class="bf kg qa qb kj qd qe km sy sz kq ta tb ku tc td ky hr"><a rel="noopener follow" href="/the-status-of-geo-data-science-competitions-d38df0893668?source=post_internal_links---------2-------------------------------">The status of (geo) data science competitions</a></h2></div><div class="o n"><div></div><div class="v s"><div class="n"><div style="flex:1"><span class="bf b bg bh hr"><div class="cw n o te"><span class="bf b pc bh hr"><a class="ek el ce cf cg ch ci cj ck bq tf cl eo ep" href="https://medium.com/@lenormand.maxime314?source=post_internal_links---------2-------------------------------" rel="noopener follow">Maxime LENORMAND</a><span> <!-- -->in<!-- --> <a class="ek el ce cf cg ch ci cj ck bq tf cl eo ep" href="https://towardsdatascience.com/?source=post_internal_links---------2-------------------------------" rel="noopener follow">Towards Data Science</a></span></span></div></span></div></div></div></div></div><div class="eq pt s tg th"><a class="ek el ce cf cg ch ci cj ck bq em en cl eo ep s" rel="noopener follow" href="/the-status-of-geo-data-science-competitions-d38df0893668?source=post_internal_links---------2-------------------------------"><div class="lu s at lv"><div class="mw lx s"><div class="oz ua es ff fb fl v lr ls lt"><img class="es ff fb fl v ly lz ae" src="https://miro.medium.com/max/60/1*ax1v3BR0cRwSqnB2AH_sYg.png?q=20" width="70" height="70" role="presentation"></div><img class="fc lq ti tj tk tl tm tn to tp tq tr c" width="70" height="70" role="presentation"><noscript><img class="ti tj tk tl tm tn to tp tq tr" src="https://miro.medium.com/fit/c/140/140/1*ax1v3BR0cRwSqnB2AH_sYg.png" width="70" height="70" srcSet="https://miro.medium.com/fit/c/96/140/1*ax1v3BR0cRwSqnB2AH_sYg.png 48w, https://miro.medium.com/fit/c/140/140/1*ax1v3BR0cRwSqnB2AH_sYg.png 70w" sizes="70px" role="presentation"/></noscript></div></div></a></div></div></div></div></div><div class="ry rz sa sb sc sd se sf sg sh si sj sk sl sm sn so sp sq sr ss"><div class="st su s"><div class="v fl"><div class="n cp"><div class="s sv oq os sw"><div class="sx s"><h2 class="bf kg qa qb kj qd qe km sy sz kq ta tb ku tc td ky hr"><a href="https://pub.towardsai.net/predicting-heart-failure-survival-with-machine-learning-models-part-i-7ff1ab58cff8?source=post_internal_links---------3-------------------------------" rel="noopener follow">Predicting Heart Failure Survival with Machine Learning Models — Part I</a></h2></div><div class="o n"><div></div><div class="v s"><div class="n"><div style="flex:1"><span class="bf b bg bh hr"><div class="cw n o te"><span class="bf b pc bh hr"><a class="ek el ce cf cg ch ci cj ck bq tf cl eo ep" href="https://wazzup-ani.medium.com/?source=post_internal_links---------3-------------------------------" rel="noopener follow">Anirudh Chandra</a><span> <!-- -->in<!-- --> <a class="ek el ce cf cg ch ci cj ck bq tf cl eo ep" href="https://pub.towardsai.net/?source=post_internal_links---------3-------------------------------" rel="noopener follow">Towards AI</a></span></span></div></span></div></div></div></div></div><div class="eq pt s tg th"><a class="ek el ce cf cg ch ci cj ck bq em en cl eo ep s" href="https://pub.towardsai.net/predicting-heart-failure-survival-with-machine-learning-models-part-i-7ff1ab58cff8?source=post_internal_links---------3-------------------------------" rel="noopener follow"><div class="lu s at lv"><div class="mw lx s"><div class="oz ua es ff fb fl v lr ls lt"><img class="es ff fb fl v ly lz ae" src="https://miro.medium.com/max/60/1*KBRYys-rO_HlD2XGt00ckw.jpeg?q=20" width="70" height="70" role="presentation"></div><img class="fc lq ti tj tk tl tm tn to tp tq tr c" width="70" height="70" role="presentation"><noscript><img class="ti tj tk tl tm tn to tp tq tr" src="https://miro.medium.com/fit/c/140/140/1*KBRYys-rO_HlD2XGt00ckw.jpeg" width="70" height="70" srcSet="https://miro.medium.com/fit/c/96/140/1*KBRYys-rO_HlD2XGt00ckw.jpeg 48w, https://miro.medium.com/fit/c/140/140/1*KBRYys-rO_HlD2XGt00ckw.jpeg 70w" sizes="70px" role="presentation"/></noscript></div></div></a></div></div></div></div></div><div class="ry rz sa sb sc sd se sf sg sh si sj sk sl sm sn so sp sq sr ss"><div class="st su s"><div class="v fl"><div class="n cp"><div class="s sv oq os sw"><div class="sx s"><h2 class="bf kg qa qb kj qd qe km sy sz kq ta tb ku tc td ky hr"><a href="https://edo-romani1.medium.com/developing-a-simple-udemy-online-course-tracker-with-tableau-962be7b348ce?source=post_internal_links---------4-------------------------------" rel="noopener follow">Developing a simple Udemy online course tracker with Tableau</a></h2></div><div class="o n"><div></div><div class="v s"><div class="n"><div style="flex:1"><span class="bf b bg bh hr"><div class="cw n o te"><span class="bf b pc bh hr"><a class="ek el ce cf cg ch ci cj ck bq tf cl eo ep" href="https://edo-romani1.medium.com/?source=post_internal_links---------4-------------------------------" rel="noopener follow">Edoardo Romani</a></span></div></span></div></div></div></div></div><div class="eq pt s tg th"><a class="ek el ce cf cg ch ci cj ck bq em en cl eo ep s" href="https://edo-romani1.medium.com/developing-a-simple-udemy-online-course-tracker-with-tableau-962be7b348ce?source=post_internal_links---------4-------------------------------" rel="noopener follow"><div class="lu s at lv"><div class="mw lx s"><div class="oz ua es ff fb fl v lr ls lt"><img class="es ff fb fl v ly lz ae" src="https://miro.medium.com/max/60/1*rE-uw8goXI-p4qNEHWWWLA.png?q=20" width="70" height="70" role="presentation"></div><img class="fc lq ti tj tk tl tm tn to tp tq tr c" width="70" height="70" role="presentation"><noscript><img class="ti tj tk tl tm tn to tp tq tr" src="https://miro.medium.com/fit/c/140/140/1*rE-uw8goXI-p4qNEHWWWLA.png" width="70" height="70" srcSet="https://miro.medium.com/fit/c/96/140/1*rE-uw8goXI-p4qNEHWWWLA.png 48w, https://miro.medium.com/fit/c/140/140/1*rE-uw8goXI-p4qNEHWWWLA.png 70w" sizes="70px" role="presentation"/></noscript></div></div></a></div></div></div></div></div><div class="ry rz sa sb sc sd se sf sg sh si sj sk sl sm sn so sp sq sr ss"><div class="st su s"><div class="v fl"><div class="n cp"><div class="s sv oq os sw"><div class="sx s"><h2 class="bf kg qa qb kj qd qe km sy sz kq ta tb ku tc td ky hr"><a rel="noopener follow" href="/topic-modelling-on-nyt-articles-using-gensim-lda-37caa2796cd9?source=post_internal_links---------5-------------------------------">Topic Modelling on NYT articles using Gensim, LDA</a></h2></div><div class="o n"><div></div><div class="v s"><div class="n"><div style="flex:1"><span class="bf b bg bh hr"><div class="cw n o te"><span class="bf b pc bh hr"><a class="ek el ce cf cg ch ci cj ck bq tf cl eo ep" href="https://ramyavidiyala.medium.com/?source=post_internal_links---------5-------------------------------" rel="noopener follow">Ramya Vidiyala</a><span> <!-- -->in<!-- --> <a class="ek el ce cf cg ch ci cj ck bq tf cl eo ep" href="https://towardsdatascience.com/?source=post_internal_links---------5-------------------------------" rel="noopener follow">Towards Data Science</a></span></span></div></span></div></div></div></div></div><div class="eq pt s tg th"><a class="ek el ce cf cg ch ci cj ck bq em en cl eo ep s" rel="noopener follow" href="/topic-modelling-on-nyt-articles-using-gensim-lda-37caa2796cd9?source=post_internal_links---------5-------------------------------"><div class="lu s at lv"><div class="mw lx s"><div class="oz ua es ff fb fl v lr ls lt"><img class="es ff fb fl v ly lz ae" src="https://miro.medium.com/max/60/0*6LqRJqfgGafAYgGA?q=20" width="70" height="70" role="presentation"></div><img class="fc lq ti tj tk tl tm tn to tp tq tr c" width="70" height="70" role="presentation"><noscript><img class="ti tj tk tl tm tn to tp tq tr" src="https://miro.medium.com/fit/c/140/140/0*6LqRJqfgGafAYgGA" width="70" height="70" srcSet="https://miro.medium.com/fit/c/96/140/0*6LqRJqfgGafAYgGA 48w, https://miro.medium.com/fit/c/140/140/0*6LqRJqfgGafAYgGA 70w" sizes="70px" role="presentation"/></noscript></div></div></a></div></div></div></div></div><div class="ry rz sa sb sc sd se sf sg sh si sj sk sl sm sn so sp sq sr ss"><div class="st su s"><div class="v fl"><div class="n cp"><div class="s sv oq os sw"><div class="sx s"><h2 class="bf kg qa qb kj qd qe km sy sz kq ta tb ku tc td ky hr"><a href="https://kirtipurohit025.medium.com/linux-python-modules-for-data-analysis-installation-and-basics-with-jupyter-notebook-ec7ea0c2a3f3?source=post_internal_links---------6-------------------------------" rel="noopener follow">Linux-Python Modules for Data Analysis Installation and basics with Jupyter NoteBook</a></h2></div><div class="o n"><div></div><div class="v s"><div class="n"><div style="flex:1"><span class="bf b bg bh hr"><div class="cw n o te"><span class="bf b pc bh hr"><a class="ek el ce cf cg ch ci cj ck bq tf cl eo ep" href="https://kirtipurohit025.medium.com/?source=post_internal_links---------6-------------------------------" rel="noopener follow">Kirtipurohit</a></span></div></span></div></div></div></div></div><div class="eq pt s tg th"><a class="ek el ce cf cg ch ci cj ck bq em en cl eo ep s" href="https://kirtipurohit025.medium.com/linux-python-modules-for-data-analysis-installation-and-basics-with-jupyter-notebook-ec7ea0c2a3f3?source=post_internal_links---------6-------------------------------" rel="noopener follow"><div class="lu s at lv"><div class="mw lx s"><div class="oz ua es ff fb fl v lr ls lt"><img class="es ff fb fl v ly lz ae" src="https://miro.medium.com/max/60/0*Dj2kfLv07TGdHiG4.jpg?q=20" width="70" height="70" role="presentation"></div><img class="fc lq ti tj tk tl tm tn to tp tq tr c" width="70" height="70" role="presentation"><noscript><img class="ti tj tk tl tm tn to tp tq tr" src="https://miro.medium.com/fit/c/140/140/0*Dj2kfLv07TGdHiG4.jpg" width="70" height="70" srcSet="https://miro.medium.com/fit/c/96/140/0*Dj2kfLv07TGdHiG4.jpg 48w, https://miro.medium.com/fit/c/140/140/0*Dj2kfLv07TGdHiG4.jpg 70w" sizes="70px" role="presentation"/></noscript></div></div></a></div></div></div></div></div><div class="ry rz sa sb sc sd se sf sg sh si sj sk sl sm sn so sp sq sr ss"><div class="st su s"><div class="v fl"><div class="n cp"><div class="s sv oq os sw"><div class="sx s"><h2 class="bf kg qa qb kj qd qe km sy sz kq ta tb ku tc td ky hr"><a href="https://ksalmamater.medium.com/getting-into-the-world-of-data-science-56b6c6f1963e?source=post_internal_links---------7-------------------------------" rel="noopener follow">Getting into the world of Data Science</a></h2></div><div class="o n"><div></div><div class="v s"><div class="n"><div style="flex:1"><span class="bf b bg bh hr"><div class="cw n o te"><span class="bf b pc bh hr"><a class="ek el ce cf cg ch ci cj ck bq tf cl eo ep" href="https://ksalmamater.medium.com/?source=post_internal_links---------7-------------------------------" rel="noopener follow">Kishor Shankaranarayan</a></span></div></span></div></div></div></div></div><div class="eq pt s tg th"><a class="ek el ce cf cg ch ci cj ck bq em en cl eo ep s" href="https://ksalmamater.medium.com/getting-into-the-world-of-data-science-56b6c6f1963e?source=post_internal_links---------7-------------------------------" rel="noopener follow"><div class="lu s at lv"><div class="mw lx s"><div class="oz ua es ff fb fl v lr ls lt"><img class="es ff fb fl v ly lz ae" src="https://miro.medium.com/max/60/1*KFujX6iiYrzH5C8bm7JW3g.png?q=20" width="70" height="70" role="presentation"></div><img class="fc lq ti tj tk tl tm tn to tp tq tr c" width="70" height="70" role="presentation"><noscript><img class="ti tj tk tl tm tn to tp tq tr" src="https://miro.medium.com/fit/c/140/140/1*KFujX6iiYrzH5C8bm7JW3g.png" width="70" height="70" srcSet="https://miro.medium.com/fit/c/96/140/1*KFujX6iiYrzH5C8bm7JW3g.png 48w, https://miro.medium.com/fit/c/140/140/1*KFujX6iiYrzH5C8bm7JW3g.png 70w" sizes="70px" role="presentation"/></noscript></div></div></a></div></div></div></div></div></div></div></div></div></div></div></div></div><div class="vn s wq wr"><div class="n p"><div class="au av aw ax ay az ba v"><div class="n ao"><div class="n ws wt wu wv ww wx wy wz xa xb cp"><a class="ek el ce cf cg ch ci cj ck bq xc xd cl xe xf" aria-label="Go to homepage" href="https://medium.com/?source=post_page-----af816aaea61-----------------------------------" rel="noopener follow"><svg viewBox="0 0 3940 610" class="ec xg"><path d="M594.79 308.2c0 163.76-131.85 296.52-294.5 296.52S5.8 472 5.8 308.2 137.65 11.69 300.29 11.69s294.5 132.75 294.5 296.51M917.86 308.2c0 154.16-65.93 279.12-147.25 279.12s-147.25-125-147.25-279.12S689.29 29.08 770.61 29.08s147.25 125 147.25 279.12M1050 308.2c0 138.12-23.19 250.08-51.79 250.08s-51.79-112-51.79-250.08 23.19-250.08 51.8-250.08S1050 170.09 1050 308.2M1862.77 37.4l.82-.18v-6.35h-167.48l-155.51 365.5-155.51-365.5h-180.48v6.35l.81.18c30.57 6.9 46.09 17.19 46.09 54.3v434.45c0 37.11-15.58 47.4-46.15 54.3l-.81.18V587H1327v-6.35l-.81-.18c-30.57-6.9-46.09-17.19-46.09-54.3V116.9L1479.87 587h11.33l205.59-483.21V536.9c-2.62 29.31-18 38.36-45.68 44.61l-.82.19v6.3h213.3v-6.3l-.82-.19c-27.71-6.25-43.46-15.3-46.08-44.61l-.14-445.2h.14c0-37.11 15.52-47.4 46.08-54.3m97.43 287.8c3.49-78.06 31.52-134.4 78.56-135.37 14.51.24 26.68 5 36.14 14.16 20.1 19.51 29.55 60.28 28.09 121.21zm-2.11 22h250v-1.05c-.71-59.69-18-106.12-51.34-138-28.82-27.55-71.49-42.71-116.31-42.71h-1c-23.26 0-51.79 5.64-72.09 15.86-23.11 10.7-43.49 26.7-60.45 47.7-27.3 33.83-43.84 79.55-47.86 130.93-.13 1.54-.24 3.08-.35 4.62s-.18 2.92-.25 4.39a332.64 332.64 0 0 0-.36 21.69C1860.79 507 1923.65 600 2035.3 600c98 0 155.07-71.64 169.3-167.8l-7.19-2.53c-25 51.68-69.9 83-121 79.18-69.76-5.22-123.2-75.95-118.35-161.63m532.69 157.68c-8.2 19.45-25.31 30.15-48.24 30.15s-43.89-15.74-58.78-44.34c-16-30.7-24.42-74.1-24.42-125.51 0-107 33.28-176.21 84.79-176.21 21.57 0 38.55 10.7 46.65 29.37zm165.84 76.28c-30.57-7.23-46.09-18-46.09-57V5.28L2424.77 60v6.7l1.14-.09c25.62-2.07 43 1.47 53.09 10.79 7.9 7.3 11.75 18.5 11.75 34.26v71.14c-18.31-11.69-40.09-17.38-66.52-17.38-53.6 0-102.59 22.57-137.92 63.56-36.83 42.72-56.3 101.1-56.3 168.81C2230 518.72 2289.53 600 2378.13 600c51.83 0 93.53-28.4 112.62-76.3V588h166.65v-6.66zm159.29-505.33c0-37.76-28.47-66.24-66.24-66.24-37.59 0-67 29.1-67 66.24s29.44 66.24 67 66.24c37.77 0 66.24-28.48 66.24-66.24m43.84 505.33c-30.57-7.23-46.09-18-46.09-57h-.13V166.65l-166.66 47.85v6.5l1 .09c36.06 3.21 45.93 15.63 45.93 57.77V588h166.8v-6.66zm427.05 0c-30.57-7.23-46.09-18-46.09-57V166.65L3082 212.92v6.52l.94.1c29.48 3.1 38 16.23 38 58.56v226c-9.83 19.45-28.27 31-50.61 31.78-36.23 0-56.18-24.47-56.18-68.9V166.66l-166.66 47.85V221l1 .09c36.06 3.2 45.94 15.62 45.94 57.77v191.27a214.48 214.48 0 0 0 3.47 39.82l3 13.05c14.11 50.56 51.08 77 109 77 49.06 0 92.06-30.37 111-77.89v66h166.66v-6.66zM3934.2 588v-6.67l-.81-.19c-33.17-7.65-46.09-22.07-46.09-51.43v-243.2c0-75.83-42.59-121.09-113.93-121.09-52 0-95.85 30.05-112.73 76.86-13.41-49.6-52-76.86-109.06-76.86-50.12 0-89.4 26.45-106.25 71.13v-69.87l-166.66 45.89v6.54l1 .09c35.63 3.16 45.93 15.94 45.93 57V588h155.5v-6.66l-.82-.2c-26.46-6.22-35-17.56-35-46.66V255.72c7-16.35 21.11-35.72 49-35.72 34.64 0 52.2 24 52.2 71.28V588h155.54v-6.66l-.82-.2c-26.46-6.22-35-17.56-35-46.66v-248a160.45 160.45 0 0 0-2.2-27.68c7.42-17.77 22.34-38.8 51.37-38.8 35.13 0 52.2 23.31 52.2 71.28V588z"></path></svg></a><div class="xh xi xj xk xl xm n cp"><p class="bf b dn do xn"><a class="ek el ce cf cg ch ci cj ck bq tf cl xe xf" href="https://medium.com/about?autoplay=1&amp;source=post_page-----af816aaea61-----------------------------------" rel="noopener follow">About</a></p><p class="bf b dn do xn"><a class="ek el ce cf cg ch ci cj ck bq tf cl xe xf" href="https://medium.com/new-story?source=post_page-----af816aaea61-----------------------------------" rel="noopener follow">Write</a></p><p class="bf b dn do xn"><a class="ek el ce cf cg ch ci cj ck bq tf cl xe xf" href="https://help.medium.com/hc/en-us?source=post_page-----af816aaea61-----------------------------------" rel="noopener follow">Help</a></p><p class="bf b dn do xn"><a class="ek el ce cf cg ch ci cj ck bq tf cl xe xf" href="https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----af816aaea61-----------------------------------" rel="noopener follow">Legal</a></p></div></div><div class="aq xo xp xq cr"><p class="bf b dn do xr">Get the Medium app</p></div><div class="aq xs va cr xt"><div class="be s"><a class="ek el ce cf cg ch ci cj ck bq xc xd cl xe xf" href="https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&amp;mt=8&amp;ct=post_page&amp;source=post_page-----af816aaea61-----------------------------------" rel="noopener follow"><img alt="A button that says 'Download on the App Store', and if clicked it will lead you to the iOS App store" class="" src="https://miro.medium.com/max/135/1*Crl55Tm6yDNMoucPo1tvDg.png" width="135" height="41"></a></div><div class="s"><a class="ek el ce cf cg ch ci cj ck bq xc xd cl xe xf" href="https://play.google.com/store/apps/details?id=com.medium.reader&amp;source=post_page-----af816aaea61-----------------------------------" rel="noopener follow"><img alt="A button that says 'Get it on, Google Play', and if clicked it will lead you to the Google Play store" class="" src="https://miro.medium.com/max/135/1*W_RAPQ62h0em559zluJLdQ.png" width="135" height="41"></a></div></div></div></div></div></div></div></div></div><script>window.__BUILD_ID__="main-20220218-215851-56c903d0c8"</script><script>window.__GRAPHQL_URI__ = "https://towardsdatascience.com/_/graphql"</script><script>window.__PRELOADED_STATE__ = {"algolia":{"queries":{}},"auroraPage":{"isAuroraPageEnabled":true},"bookReader":{"assets":{},"reader":{"currentAsset":null,"currentGFI":null,"settingsPanelIsOpen":false,"settings":{"fontFamily":"CHARTER","fontScale":"M","publisherStyling":false,"textAlignment":"start","theme":"White","lineSpacing":0,"wordSpacing":0,"letterSpacing":0},"internalNavCounter":0,"currentSelection":null}},"cache":{"experimentGroupSet":true,"reason":"This request is not using the cache middleware worker","group":"disabled","tags":["group-edgeCachePosts","post-af816aaea61","user-524f24852f3c","collection-7f60cf5620c9"],"serverVariantState":"","middlewareEnabled":false,"cacheStatus":"DYNAMIC","shouldUseCache":false,"vary":[]},"client":{"hydrated":false,"isUs":false,"isNativeMedium":false,"isSafariMobile":false,"isSafari":false,"isFirefox":false,"routingEntity":{"type":"COLLECTION","id":"7f60cf5620c9","explicit":true},"viewerIsBot":false},"debug":{"requestId":"eb953cc8-cfdb-4ffa-971a-45803804bfa7","hybridDevServices":[],"showBookReaderDebugger":false,"originalSpanCarrier":{"ot-tracer-spanid":"52371b682ffc74f8","ot-tracer-traceid":"48de97ed2fec995d","ot-tracer-sampled":"true"}},"multiVote":{"clapsPerPost":{}},"navigation":{"branch":{"show":null,"hasRendered":null,"blockedByCTA":false},"hideGoogleOneTap":false,"hasRenderedGoogleOneTap":null,"hasRenderedAlternateUserBanner":null,"currentLocation":"https:\u002F\u002Ftowardsdatascience.com\u002Fneural-network-pruning-101-af816aaea61","host":"towardsdatascience.com","hostname":"towardsdatascience.com","referrer":"","hasSetReferrer":false,"susiModal":{"step":null,"operation":"register"},"postRead":false},"tracing":{},"userOnboarding":{"showFirstBookPurchaseTooltip":false},"config":{"nodeEnv":"production","version":"main-20220218-215851-56c903d0c8","isTaggedVersion":false,"isMediumDotApp":false,"isMediumDotAppVariant":false,"target":"production","productName":"Medium","publicUrl":"https:\u002F\u002Fcdn-client.medium.com\u002Flite","authDomain":"medium.com","authGoogleClientId":"216296035834-k1k6qe060s2tp2a2jam4ljdcms00sttg.apps.googleusercontent.com","favicon":"production","glyphUrl":"https:\u002F\u002Fglyph.medium.com","branchKey":"key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm","lightStep":{"name":"lite-web","host":"lightstep.medium.systems","token":"ce5be895bef60919541332990ac9fef2","appVersion":"main-20220218-215851-56c903d0c8","disableClientReporting":true},"algolia":{"appId":"MQ57UUUQZ2","apiKeySearch":"394474ced050e3911ae2249ecc774921","indexPrefix":"medium_","host":"-dsn.algolia.net"},"recaptchaKey":"6Lfc37IUAAAAAKGGtC6rLS13R1Hrw_BqADfS1LRk","recaptcha3Key":"6Lf8R9wUAAAAABMI_85Wb8melS7Zj6ziuf99Yot5","datadog":{"applicationId":"6702d87d-a7e0-42fe-bbcb-95b469547ea0","clientToken":"pub853ea8d17ad6821d9f8f11861d23dfed","rumToken":"pubf9cc52896502b9413b68ba36fc0c7162","context":{"deployment":{"target":"production","tag":"main-20220218-215851-56c903d0c8","commit":"56c903d0c825cd67467ea5573007ef07dd5a9a39"}},"datacenter":"us"},"googleAnalyticsCode":"UA-24232453-2","googlePay":{"apiVersion":"2","apiVersionMinor":"0","merchantId":"BCR2DN6TV7EMTGBM","merchantName":"Medium","instanceMerchantId":"13685562959212738550"},"applePay":{"version":3},"signInWallCustomDomainCollectionIds":["3a8144eabfe3","336d898217ee","61061eb0c96b","138adf9c44c","819cc2aaeee0"],"mediumOwnedAndOperatedCollectionIds":["8a9336e5bb4","b7e45b22fec3","193b68bd4fba","8d6b8a439e32","54c98c43354d","3f6ecf56618","d944778ce714","92d2092dc598","ae2a65f35510","1285ba81cada","544c7006046e","fc8964313712","40187e704f1c","88d9857e584e","7b6769f2748b","bcc38c8f6edf","cef6983b292","cb8577c9149e","444d13b52878","713d7dbc99b0","ef8e90590e66","191186aaafa0","55760f21cdc5","9dc80918cc93","bdc4052bbdba","8ccfed20cbb2"],"tierOneDomains":["medium.com","thebolditalic.com","arcdigital.media","towardsdatascience.com","uxdesign.cc","codeburst.io","psiloveyou.xyz","writingcooperative.com","entrepreneurshandbook.co","prototypr.io","betterhumans.coach.me","theascent.pub"],"topicsToFollow":["d61cf867d93f","8a146bc21b28","1eca0103fff3","4d562ee63426","aef1078a3ef5","e15e46793f8d","6158eb913466","55f1c20aba7a","3d18b94f6858","4861fee224fd","63c6f1f93ee","1d98b3a9a871","decb52b64abf","ae5d4995e225","830cded25262"],"topicToTagMappings":{"accessibility":"accessibility","addiction":"addiction","android-development":"android-development","art":"art","artificial-intelligence":"artificial-intelligence","astrology":"astrology","basic-income":"basic-income","beauty":"beauty","biotech":"biotech","blockchain":"blockchain","books":"books","business":"business","cannabis":"cannabis","cities":"cities","climate-change":"climate-change","comics":"comics","coronavirus":"coronavirus","creativity":"creativity","cryptocurrency":"cryptocurrency","culture":"culture","cybersecurity":"cybersecurity","data-science":"data-science","design":"design","digital-life":"digital-life","disability":"disability","economy":"economy","education":"education","equality":"equality","family":"family","feminism":"feminism","fiction":"fiction","film":"film","fitness":"fitness","food":"food","freelancing":"freelancing","future":"future","gadgets":"gadgets","gaming":"gaming","gun-control":"gun-control","health":"health","history":"history","humor":"humor","immigration":"immigration","ios-development":"ios-development","javascript":"javascript","justice":"justice","language":"language","leadership":"leadership","lgbtqia":"lgbtqia","lifestyle":"lifestyle","machine-learning":"machine-learning","makers":"makers","marketing":"marketing","math":"math","media":"media","mental-health":"mental-health","mindfulness":"mindfulness","money":"money","music":"music","neuroscience":"neuroscience","nonfiction":"nonfiction","outdoors":"outdoors","parenting":"parenting","pets":"pets","philosophy":"philosophy","photography":"photography","podcasts":"podcast","poetry":"poetry","politics":"politics","privacy":"privacy","product-management":"product-management","productivity":"productivity","programming":"programming","psychedelics":"psychedelics","psychology":"psychology","race":"race","relationships":"relationships","religion":"religion","remote-work":"remote-work","san-francisco":"san-francisco","science":"science","self":"self","self-driving-cars":"self-driving-cars","sexuality":"sexuality","social-media":"social-media","society":"society","software-engineering":"software-engineering","space":"space","spirituality":"spirituality","sports":"sports","startups":"startup","style":"style","technology":"technology","transportation":"transportation","travel":"travel","true-crime":"true-crime","tv":"tv","ux":"ux","venture-capital":"venture-capital","visual-design":"visual-design","work":"work","world":"world","writing":"writing"},"defaultImages":{"avatar":{"imageId":"1*dmbNkD5D-u45r44go_cf0g.png","height":150,"width":150},"orgLogo":{"imageId":"1*OMF3fSqH8t4xBJ9-6oZDZw.png","height":106,"width":545},"postLogo":{"imageId":"1*kFrc4tBFM_tCis-2Ic87WA.png","height":810,"width":1440},"postPreviewImage":{"imageId":"1*hn4v1tCaJy7cWMyb0bpNpQ.png","height":386,"width":579}},"collectionStructuredData":{"8d6b8a439e32":{"name":"Elemental","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F980\u002F1*9ygdqoKprhwuTVKUM0DLPA@2x.png","width":980,"height":159}}},"3f6ecf56618":{"name":"Forge","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F596\u002F1*uULpIlImcO5TDuBZ6lm7Lg@2x.png","width":596,"height":183}}},"ae2a65f35510":{"name":"GEN","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F264\u002F1*RdVZMdvfV3YiZTw6mX7yWA.png","width":264,"height":140}}},"88d9857e584e":{"name":"LEVEL","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*JqYMhNX6KNNb2UlqGqO2WQ.png","width":540,"height":108}}},"7b6769f2748b":{"name":"Marker","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F383\u002F1*haCUs0wF6TgOOvfoY-jEoQ@2x.png","width":383,"height":92}}},"444d13b52878":{"name":"OneZero","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*cw32fIqCbRWzwJaoQw6BUg.png","width":540,"height":123}}},"8ccfed20cbb2":{"name":"Zora","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*tZUQqRcCCZDXjjiZ4bDvgQ.png","width":540,"height":106}}}},"embeddedPostIds":{"coronavirus":"cd3010f9d81f"},"sharedCdcMessaging":{"COVID_APPLICABLE_TAG_SLUGS":[],"COVID_APPLICABLE_TOPIC_NAMES":[],"COVID_APPLICABLE_TOPIC_NAMES_FOR_TOPIC_PAGE":[],"COVID_MESSAGES":{"tierA":{"text":"For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":66,"end":73,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"tierB":{"text":"Anyone can publish on Medium per our Policies, but we don’t fact-check every story. For more info about the coronavirus, see cdc.gov.","markups":[{"start":37,"end":45,"href":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Fcategories\u002F201931128-Policies-Safety"},{"start":125,"end":132,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"paywall":{"text":"This article has been made free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":56,"end":70,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":138,"end":145,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"unbound":{"text":"This article is free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":45,"end":59,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":127,"end":134,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]}},"COVID_BANNER_POST_ID_OVERRIDE_WHITELIST":["3b31a67bff4a"]},"sharedVoteMessaging":{"TAGS":["politics","election-2020","government","us-politics","election","2020-presidential-race","trump","donald-trump","democrats","republicans","congress","republican-party","democratic-party","biden","joe-biden","maga"],"TOPICS":["politics","election"],"MESSAGE":{"text":"Find out more about the U.S. election results here.","markups":[{"start":46,"end":50,"href":"https:\u002F\u002Fcookpolitical.com\u002F2020-national-popular-vote-tracker"}]},"EXCLUDE_POSTS":["397ef29e3ca5"]},"embedPostRules":[],"recircOptions":{"v1":{"limit":3},"v2":{"limit":8}},"braintreeClientKey":"production_zjkj96jm_m56f8fqpf7ngnrd4","braintree":{"enabled":true,"merchantId":"m56f8fqpf7ngnrd4","merchantAccountId":{"usd":"AMediumCorporation_instant","eur":"amediumcorporation_EUR","cad":"amediumcorporation_CAD"},"publicKey":"cwr8xtycwgjryv82","braintreeEnvironment":"production","dashboardUrl":"https:\u002F\u002Fwww.braintreegateway.com\u002Fmerchants","gracePeriodDurationInDays":14,"mediumMembershipPlanId":{"monthly":"ce105f8c57a3","monthlyWithTrial":"d5ee3dbe3db8","yearly":"a40ad4a43185","yearlyStaff":"d74fb811198a","yearlyWithTrial":"b3bc7350e5c7"},"braintreeDiscountId":{"oneMonthFree":"MONTHS_FREE_01","threeMonthsFree":"MONTHS_FREE_03","sixMonthsFree":"MONTHS_FREE_06"},"3DSecureVersion":"2","defaultCurrency":"usd","providerPlanIdCurrency":{"4ycw":"usd","rz3b":"usd","3kqm":"usd","jzw6":"usd","c2q2":"usd","nnsw":"usd"}},"paypalClientId":"AXj1G4fotC2GE8KzWX9mSxCH1wmPE3nJglf4Z2ig_amnhvlMVX87otaq58niAg9iuLktVNF_1WCMnN7v","paypal":{"host":"https:\u002F\u002Fapi.paypal.com:443","clientMode":"production","serverMode":"live","webhookId":"4G466076A0294510S","monthlyPlan":{"planId":"P-9WR0658853113943TMU5FDQA","name":"Medium Membership (Monthly) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"yearlyPlan":{"planId":"P-7N8963881P8875835MU5JOPQ","name":"Medium Membership (Annual) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"oneYearGift":{"name":"Medium Membership (1 Year, Digital Gift Code)","description":"Unlimited access to the best and brightest stories on Medium. Gift codes can be redeemed at medium.com\u002Fredeem.","price":"50.00","currency":"USD","sku":"membership-gift-1-yr"},"oldMonthlyPlan":{"planId":"P-96U02458LM656772MJZUVH2Y","name":"Medium Membership (Monthly)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"oldYearlyPlan":{"planId":"P-59P80963JF186412JJZU3SMI","name":"Medium Membership (Annual)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"monthlyPlanWithTrial":{"planId":"P-66C21969LR178604GJPVKUKY","name":"Medium Membership (Monthly) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"yearlyPlanWithTrial":{"planId":"P-6XW32684EX226940VKCT2MFA","name":"Medium Membership (Annual) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"oldMonthlyPlanNoSetupFee":{"planId":"P-4N046520HR188054PCJC7LJI","name":"Medium Membership (Monthly)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"oldYearlyPlanNoSetupFee":{"planId":"P-7A4913502Y5181304CJEJMXQ","name":"Medium Membership (Annual)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"sdkUrl":"https:\u002F\u002Fwww.paypal.com\u002Fsdk\u002Fjs"},"stripePublishableKey":"pk_live_7FReX44VnNIInZwrIIx6ghjl","log":{"json":true,"level":"info"}},"session":{"xsrf":""}}</script><script>window.__APOLLO_STATE__ = {"ROOT_QUERY":{"__typename":"Query","viewer":null,"variantFlags":[{"__typename":"VariantFlag","name":"allow_access","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"allow_signup","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"allow_test_auth","valueType":{"__typename":"VariantFlagString","value":"disallow"}},{"__typename":"VariantFlag","name":"author_fair_distribution_non_qp3","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"author_under_quota_fair_distribution","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"available_annual_plan","valueType":{"__typename":"VariantFlagString","value":"2c754bcc2995"}},{"__typename":"VariantFlag","name":"available_monthly_plan","valueType":{"__typename":"VariantFlagString","value":"60e220181034"}},{"__typename":"VariantFlag","name":"browsable_stream_config_bucket","valueType":{"__typename":"VariantFlagString","value":"curated-topics"}},{"__typename":"VariantFlag","name":"calibration_experiment","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"coronavirus_topic_recirc","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"covid_19_cdc_banner","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"disable_mobile_featured_chunk","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"disable_partner_program_enrollment","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_annual_renewal_reminder_email","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_app_flirty_thirty","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_apple_sign_in","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_apple_webhook","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_about_page_routing","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_nav","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_pub_follower_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_tag_page_routing","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_author_cards","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_author_cards_byline","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_auto_follow_on_subscribe","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_automod","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_apple_pay","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_client","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_google_pay","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_integration","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_paypal","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_trial_membership","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_webhook","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_branch_io","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_branch_text_me_the_app","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_creator_about_editor","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_creator_welcome_email","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_custom_domain_v2_settings","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_digest_generation_pipeline","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_digest_tagline","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_email_sign_in_captcha","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_evhead_com_to_ev_medium_com_redirect","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_expanded_feature_chunk_pool","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_fdh_hybrid_fallback","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_filter_by_resend_rules","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_fix_collection_follow_counts","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_fix_follow_counts","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_footer_app_buttons","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_google_one_tap","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_google_webhook","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_group_gifting","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_highlander_member_digest","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_hightower_user_bonus","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_homepage_posts_reduced_min","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_hot_topics","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_hot_topics_v2","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_iceland_forced_android","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_import","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_in_context_sharing","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_legacy_feed_in_iceland","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_li_homepage_write_cta","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_canada_plan","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_continue_this_thread","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_homepage","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_pub_homepage_for_selected_domains","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_response_markup","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_server_upstream_deadlines","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_stories","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_topics","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_topics_edge_cache","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_login_code_flow","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_marketing_emails","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_medium2_kbfd","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ml_rank_rex_anno","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_mobile_web_editor_redirect_route","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_mute","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_new_member_welcome_email_enhancement","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_new_three_dot_menu","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_newsletter_lo_flow_custom_domains","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_paywall_conversions_for_referred_members","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_pill_based_home_feed","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_post_settings_screen","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_pp_dashboard_referred_earnings","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_publish_to_email_for_publication_posts","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_recirc_reboot_lo","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_referred_memberships","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_referred_memberships_custom_messaging","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_reply_to_email","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_rex_reading_history","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_rito_upstream_deadlines","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_robometric_scanner","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_seamless_social_sharing","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_signup_friction","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_starspace","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_subscriber_stats_referred","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_susi_email_simplified_copy","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tag_recs","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tick_landing_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tipalti_onboarding","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tribute_landing_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_trumpland_landing_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_twitter_auth_suggestions","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_updated_follower_email","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_updated_new_member_email","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_updated_new_user_onboarding","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"glyph_font_set","valueType":{"__typename":"VariantFlagString","value":"m2-unbound"}},{"__typename":"VariantFlag","name":"ios_enable_home_post_menu","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_enable_lock_responses","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_iceland_nux","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_in_app_free_trial","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_social_share_sheet","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"limit_post_referrers","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"limit_user_follows","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"post_edge_cache_enabled","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"post_edge_cache_enabled_moc","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"posts_under_quota_fair_distribution","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"provider_for_credit_card_form","valueType":{"__typename":"VariantFlagString","value":"BRAINTREE"}},{"__typename":"VariantFlag","name":"pub_sidebar","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"reader_fair_distribution_non_qp","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"show_pp_awareness_banner","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"signin_services","valueType":{"__typename":"VariantFlagString","value":"twitter,facebook,google,email,google-fastidv,google-one-tap,apple"}},{"__typename":"VariantFlag","name":"signup_services","valueType":{"__typename":"VariantFlagString","value":"twitter,facebook,google,email,google-fastidv,google-one-tap,apple"}},{"__typename":"VariantFlag","name":"skip_sign_in_recaptcha","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"unhide_mobile_ctas","valueType":{"__typename":"VariantFlagBoolean","value":true}}],"meterPost({\"postId\":\"af816aaea61\",\"postMeteringOptions\":{\"referrer\":\"\",\"sk\":null,\"source\":null}})":{"__ref":"MeteringInfo:{}"},"postResult({\"id\":\"af816aaea61\"})":{"__ref":"Post:af816aaea61"}},"MeteringInfo:{}":{"__typename":"MeteringInfo","postIds":[],"maxUnlockCount":3,"unlocksRemaining":0},"User:524f24852f3c":{"id":"524f24852f3c","__typename":"User","name":"Hugo Tessier","username":"hugo.tessier","newsletterV3":{"__ref":"NewsletterV3:71cc63d0ec07"},"customStyleSheet":null,"isSuspended":false,"bio":"PHD student in deep learning, working on neural network compression and, especially, pruning.","imageId":"1*PAy1sna3YNoKY4jQl9znVw.jpeg","hasCompletedProfile":false,"isAuroraVisible":true,"mediumMemberAt":0,"socialStats":{"__typename":"SocialStats","followerCount":37,"followingCount":1,"collectionFollowingCount":0},"customDomainState":null,"hasSubdomain":false,"bookAuthor":null,"isPartnerProgramEnrolled":false,"viewerEdge":{"__ref":"UserViewerEdge:userId:524f24852f3c-viewerId:lo_cbe4fe29de94"},"viewerIsUser":false,"homepagePostsConnection({\"paging\":{\"limit\":1}})":{"__typename":"PostConnection","posts":[{"__ref":"Post:af816aaea61"}]},"postSubscribeMembershipUpsellShownAt":0,"allowNotes":true,"twitterScreenName":"","followedCollections":0,"referredMembershipCustomHeadline":"","referredMembershipCustomBody":"","atsQualifiedAt":1631610169172},"ImageMetadata:1*ChFMdf--f5jbm-AYv6VdYA@2x.png":{"id":"1*ChFMdf--f5jbm-AYv6VdYA@2x.png","__typename":"ImageMetadata"},"CustomStyleSheet:dc5d6afeee0a":{"id":"dc5d6afeee0a","__typename":"CustomStyleSheet","global":{"__typename":"GlobalStyles","colorPalette":{"__typename":"StyleSheetColorPalette","primary":{"__typename":"ColorValue","colorPalette":{"__typename":"ColorPalette","highlightSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FFEDF4FC","point":0},{"__typename":"ColorPoint","color":"#FFE9F2FD","point":0.1},{"__typename":"ColorPoint","color":"#FFE6F1FD","point":0.2},{"__typename":"ColorPoint","color":"#FFE2EFFD","point":0.3},{"__typename":"ColorPoint","color":"#FFDFEEFD","point":0.4},{"__typename":"ColorPoint","color":"#FFDBECFE","point":0.5},{"__typename":"ColorPoint","color":"#FFD7EBFE","point":0.6},{"__typename":"ColorPoint","color":"#FFD4E9FE","point":0.7},{"__typename":"ColorPoint","color":"#FFD0E7FF","point":0.8},{"__typename":"ColorPoint","color":"#FFCCE6FF","point":0.9},{"__typename":"ColorPoint","color":"#FFC8E4FF","point":1}]},"defaultBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FF668AAA","point":0},{"__typename":"ColorPoint","color":"#FF61809D","point":0.1},{"__typename":"ColorPoint","color":"#FF5A7690","point":0.2},{"__typename":"ColorPoint","color":"#FF546C83","point":0.3},{"__typename":"ColorPoint","color":"#FF4D6275","point":0.4},{"__typename":"ColorPoint","color":"#FF455768","point":0.5},{"__typename":"ColorPoint","color":"#FF3D4C5A","point":0.6},{"__typename":"ColorPoint","color":"#FF34414C","point":0.7},{"__typename":"ColorPoint","color":"#FF2B353E","point":0.8},{"__typename":"ColorPoint","color":"#FF21282F","point":0.9},{"__typename":"ColorPoint","color":"#FF161B1F","point":1}]},"tintBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FF355876","colorPoints":[{"__typename":"ColorPoint","color":"#FF355876","point":0},{"__typename":"ColorPoint","color":"#FF4D6C88","point":0.1},{"__typename":"ColorPoint","color":"#FF637F99","point":0.2},{"__typename":"ColorPoint","color":"#FF7791A8","point":0.3},{"__typename":"ColorPoint","color":"#FF8CA2B7","point":0.4},{"__typename":"ColorPoint","color":"#FF9FB3C6","point":0.5},{"__typename":"ColorPoint","color":"#FFB2C3D4","point":0.6},{"__typename":"ColorPoint","color":"#FFC5D2E1","point":0.7},{"__typename":"ColorPoint","color":"#FFD7E2EE","point":0.8},{"__typename":"ColorPoint","color":"#FFE9F1FA","point":0.9},{"__typename":"ColorPoint","color":"#FFFBFFFF","point":1}]}}},"background":null},"fonts":{"__typename":"StyleSheetFonts","font1":{"__typename":"StyleSheetFont","name":"SANS_SERIF_1"},"font2":{"__typename":"StyleSheetFont","name":"SANS_SERIF_1"},"font3":{"__typename":"StyleSheetFont","name":"SERIF_2"}}},"header":{"__typename":"HeaderStyles","backgroundColor":{"__typename":"ColorValue","colorPalette":{"__typename":"ColorPalette","tintBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FF355876","colorPoints":[{"__typename":"ColorPoint","color":"#FF355876","point":0},{"__typename":"ColorPoint","color":"#FF4D6C88","point":0.1},{"__typename":"ColorPoint","color":"#FF637F99","point":0.2},{"__typename":"ColorPoint","color":"#FF7791A8","point":0.3},{"__typename":"ColorPoint","color":"#FF8CA2B7","point":0.4},{"__typename":"ColorPoint","color":"#FF9FB3C6","point":0.5},{"__typename":"ColorPoint","color":"#FFB2C3D4","point":0.6},{"__typename":"ColorPoint","color":"#FFC5D2E1","point":0.7},{"__typename":"ColorPoint","color":"#FFD7E2EE","point":0.8},{"__typename":"ColorPoint","color":"#FFE9F1FA","point":0.9},{"__typename":"ColorPoint","color":"#FFFBFFFF","point":1}]}},"rgb":"355876","alpha":"99"},"postBackgroundColor":null,"backgroundImage":{"__ref":"ImageMetadata:1*sfUruIusLq6tbpLx0sDYZQ.png"},"headerScale":"HEADER_SCALE_MEDIUM","horizontalAlignment":"CENTER","backgroundImageDisplayMode":"IMAGE_DISPLAY_MODE_FILL","backgroundImageVerticalAlignment":"END","backgroundColorDisplayMode":"COLOR_DISPLAY_MODE_SOLID","secondaryBackgroundColor":null,"nameColor":null,"nameTreatment":"NAME_TREATMENT_LOGO","postNameTreatment":"NAME_TREATMENT_LOGO","logoImage":{"__ref":"ImageMetadata:1*AGyTPCaRzVqL77kFwUwHKg.png"},"logoScale":"HEADER_SCALE_LARGE","taglineColor":{"__typename":"ColorValue","rgb":"ffffff","alpha":"ff"},"taglineTreatment":"TAGLINE_TREATMENT_HEADER"},"navigation":{"__typename":"HeaderNavigation","navItems":[{"__typename":"HeaderNavigationItem","name":"Editors' Picks","href":null,"type":"NAV_TYPE_TAG","tags":[{"__ref":"Tag:editors-pick"}],"tagSlugs":["editors-pick"]},{"__typename":"HeaderNavigationItem","name":"Features","href":null,"type":"NAV_TYPE_TAG","tags":[{"__ref":"Tag:tds-features"}],"tagSlugs":["tds-features"]},{"__typename":"HeaderNavigationItem","name":"Deep Dives","href":null,"type":"NAV_TYPE_TAG","tags":[{"__ref":"Tag:deep-dives"}],"tagSlugs":["deep-dives"]},{"__typename":"HeaderNavigationItem","name":"Grow","href":"https:\u002F\u002Ftowardsdatascience.com\u002Fhow-to-get-the-most-out-of-towards-data-science-3bf37f75a345","type":"NAV_TYPE_LINK","tags":[],"tagSlugs":[]},{"__typename":"HeaderNavigationItem","name":"Contribute","href":"https:\u002F\u002Ftowardsdatascience.com\u002Fquestions-96667b06af5","type":"NAV_TYPE_LINK","tags":[],"tagSlugs":[]}]},"postBody":null,"blogroll":{"__typename":"BlogrollConfiguration","visibility":"BLOGROLL_VISIBILITY_SIDEBAR"}},"ImageMetadata:1*sfUruIusLq6tbpLx0sDYZQ.png":{"id":"1*sfUruIusLq6tbpLx0sDYZQ.png","__typename":"ImageMetadata","originalWidth":1401},"CollectionViewerEdge:collectionId:7f60cf5620c9-viewerId:lo_cbe4fe29de94":{"id":"collectionId:7f60cf5620c9-viewerId:lo_cbe4fe29de94","__typename":"CollectionViewerEdge","isEditor":false},"ImageMetadata:1*mG6i4Bh_LgixUYXJgQpYsg@2x.png":{"id":"1*mG6i4Bh_LgixUYXJgQpYsg@2x.png","__typename":"ImageMetadata","originalWidth":337,"originalHeight":122},"User:7e12c71dfa81":{"id":"7e12c71dfa81","__typename":"User","atsQualifiedAt":1612205680542},"ImageMetadata:1*CJe3891yB1A1mzMdqemkdg.jpeg":{"id":"1*CJe3891yB1A1mzMdqemkdg.jpeg","__typename":"ImageMetadata"},"NewsletterV3:d6fe9076899":{"id":"d6fe9076899","__typename":"NewsletterV3","slug":"the-variable","showPromo":true,"name":"The Variable","description":"Every Thursday, the Variable delivers the very best of Towards Data Science: from hands-on tutorials and cutting-edge research to original features you don't want to miss.","promoHeadline":"","promoBody":"","collection":{"__ref":"Collection:7f60cf5620c9"},"type":"NEWSLETTER_TYPE_COLLECTION","user":{"__ref":"User:895063a310f4"}},"Collection:7f60cf5620c9":{"id":"7f60cf5620c9","__typename":"Collection","domain":"towardsdatascience.com","googleAnalyticsId":null,"slug":"towards-data-science","colorBehavior":"ACCENT_COLOR_AND_FILL_BACKGROUND","isAuroraVisible":true,"favicon":{"__ref":"ImageMetadata:1*ChFMdf--f5jbm-AYv6VdYA@2x.png"},"name":"Towards Data Science","colorPalette":{"__typename":"ColorPalette","highlightSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FFEDF4FC","point":0},{"__typename":"ColorPoint","color":"#FFE9F2FD","point":0.1},{"__typename":"ColorPoint","color":"#FFE6F1FD","point":0.2},{"__typename":"ColorPoint","color":"#FFE2EFFD","point":0.3},{"__typename":"ColorPoint","color":"#FFDFEEFD","point":0.4},{"__typename":"ColorPoint","color":"#FFDBECFE","point":0.5},{"__typename":"ColorPoint","color":"#FFD7EBFE","point":0.6},{"__typename":"ColorPoint","color":"#FFD4E9FE","point":0.7},{"__typename":"ColorPoint","color":"#FFD0E7FF","point":0.8},{"__typename":"ColorPoint","color":"#FFCCE6FF","point":0.9},{"__typename":"ColorPoint","color":"#FFC8E4FF","point":1}]},"defaultBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FF668AAA","point":0},{"__typename":"ColorPoint","color":"#FF61809D","point":0.1},{"__typename":"ColorPoint","color":"#FF5A7690","point":0.2},{"__typename":"ColorPoint","color":"#FF546C83","point":0.3},{"__typename":"ColorPoint","color":"#FF4D6275","point":0.4},{"__typename":"ColorPoint","color":"#FF455768","point":0.5},{"__typename":"ColorPoint","color":"#FF3D4C5A","point":0.6},{"__typename":"ColorPoint","color":"#FF34414C","point":0.7},{"__typename":"ColorPoint","color":"#FF2B353E","point":0.8},{"__typename":"ColorPoint","color":"#FF21282F","point":0.9},{"__typename":"ColorPoint","color":"#FF161B1F","point":1}]},"tintBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FF355876","colorPoints":[{"__typename":"ColorPoint","color":"#FF355876","point":0},{"__typename":"ColorPoint","color":"#FF4D6C88","point":0.1},{"__typename":"ColorPoint","color":"#FF637F99","point":0.2},{"__typename":"ColorPoint","color":"#FF7791A8","point":0.3},{"__typename":"ColorPoint","color":"#FF8CA2B7","point":0.4},{"__typename":"ColorPoint","color":"#FF9FB3C6","point":0.5},{"__typename":"ColorPoint","color":"#FFB2C3D4","point":0.6},{"__typename":"ColorPoint","color":"#FFC5D2E1","point":0.7},{"__typename":"ColorPoint","color":"#FFD7E2EE","point":0.8},{"__typename":"ColorPoint","color":"#FFE9F1FA","point":0.9},{"__typename":"ColorPoint","color":"#FFFBFFFF","point":1}]}},"customStyleSheet":{"__ref":"CustomStyleSheet:dc5d6afeee0a"},"tagline":"A Medium publication sharing concepts, ideas and codes.","isAuroraEligible":true,"viewerEdge":{"__ref":"CollectionViewerEdge:collectionId:7f60cf5620c9-viewerId:lo_cbe4fe29de94"},"logo":{"__ref":"ImageMetadata:1*mG6i4Bh_LgixUYXJgQpYsg@2x.png"},"navItems":[{"__typename":"NavItem","title":"Data Science","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fdata-science\u002Fhome","type":"TOPIC_PAGE"},{"__typename":"NavItem","title":"Machine Learning","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fmachine-learning\u002Fhome","type":"TOPIC_PAGE"},{"__typename":"NavItem","title":"Programming","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fprogramming\u002Fhome","type":"TOPIC_PAGE"},{"__typename":"NavItem","title":"Visualization","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fdata-visualization\u002Fhome","type":"TOPIC_PAGE"},{"__typename":"NavItem","title":"Video","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fvideo\u002Fhome","type":"TOPIC_PAGE"},{"__typename":"NavItem","title":"★","url":"https:\u002F\u002Ftowardsdatascience.com\u002Feditors-picks\u002Fhome","type":"TOPIC_PAGE"},{"__typename":"NavItem","title":"About","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fabout-us\u002Fhome","type":"TOPIC_PAGE"},{"__typename":"NavItem","title":"Contribute","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fcontribute\u002Fhome","type":"EXTERNAL_LINK_NAV_ITEM"}],"creator":{"__ref":"User:7e12c71dfa81"},"subscriberCount":622835,"avatar":{"__ref":"ImageMetadata:1*CJe3891yB1A1mzMdqemkdg.jpeg"},"newsletterV3":{"__ref":"NewsletterV3:d6fe9076899"},"canToggleEmail":true,"description":"Your home for data science. A Medium publication sharing concepts, ideas and codes.","twitterUsername":"TDataScience","facebookPageId":null,"customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","status":"ACTIVE","isSubdomain":false}},"ptsQualifiedAt":1616092952992},"UserViewerEdge:userId:524f24852f3c-viewerId:lo_cbe4fe29de94":{"id":"userId:524f24852f3c-viewerId:lo_cbe4fe29de94","__typename":"UserViewerEdge","isFollowing":false,"isUser":false},"NewsletterV3:71cc63d0ec07":{"id":"71cc63d0ec07","__typename":"NewsletterV3","type":"NEWSLETTER_TYPE_AUTHOR","slug":"524f24852f3c","name":"524f24852f3c","collection":null,"user":{"__ref":"User:524f24852f3c"},"description":"","promoHeadline":"","promoBody":"","showPromo":false,"subscribersCount":2},"Post:af816aaea61":{"id":"af816aaea61","__typename":"Post","creator":{"__ref":"User:524f24852f3c"},"canonicalUrl":"","collection":{"__ref":"Collection:7f60cf5620c9"},"content({\"postMeteringOptions\":{\"referrer\":\"\",\"sk\":null,\"source\":null}})":{"__typename":"PostContent","isLockedPreviewOnly":false,"validatedShareKey":"","bodyModel":{"__typename":"RichText","paragraphs":[{"__ref":"Paragraph:58956a883341_0"},{"__ref":"Paragraph:58956a883341_1"},{"__ref":"Paragraph:58956a883341_2"},{"__ref":"Paragraph:58956a883341_3"},{"__ref":"Paragraph:58956a883341_4"},{"__ref":"Paragraph:58956a883341_5"},{"__ref":"Paragraph:58956a883341_6"},{"__ref":"Paragraph:58956a883341_7"},{"__ref":"Paragraph:58956a883341_8"},{"__ref":"Paragraph:58956a883341_9"},{"__ref":"Paragraph:58956a883341_10"},{"__ref":"Paragraph:58956a883341_11"},{"__ref":"Paragraph:58956a883341_12"},{"__ref":"Paragraph:58956a883341_13"},{"__ref":"Paragraph:58956a883341_14"},{"__ref":"Paragraph:58956a883341_15"},{"__ref":"Paragraph:58956a883341_16"},{"__ref":"Paragraph:58956a883341_17"},{"__ref":"Paragraph:58956a883341_18"},{"__ref":"Paragraph:58956a883341_19"},{"__ref":"Paragraph:58956a883341_20"},{"__ref":"Paragraph:58956a883341_21"},{"__ref":"Paragraph:58956a883341_22"},{"__ref":"Paragraph:58956a883341_23"},{"__ref":"Paragraph:58956a883341_24"},{"__ref":"Paragraph:58956a883341_25"},{"__ref":"Paragraph:58956a883341_26"},{"__ref":"Paragraph:58956a883341_27"},{"__ref":"Paragraph:58956a883341_28"},{"__ref":"Paragraph:58956a883341_29"},{"__ref":"Paragraph:58956a883341_30"},{"__ref":"Paragraph:58956a883341_31"},{"__ref":"Paragraph:58956a883341_32"},{"__ref":"Paragraph:58956a883341_33"},{"__ref":"Paragraph:58956a883341_34"},{"__ref":"Paragraph:58956a883341_35"},{"__ref":"Paragraph:58956a883341_36"},{"__ref":"Paragraph:58956a883341_37"},{"__ref":"Paragraph:58956a883341_38"},{"__ref":"Paragraph:58956a883341_39"},{"__ref":"Paragraph:58956a883341_40"},{"__ref":"Paragraph:58956a883341_41"},{"__ref":"Paragraph:58956a883341_42"},{"__ref":"Paragraph:58956a883341_43"},{"__ref":"Paragraph:58956a883341_44"},{"__ref":"Paragraph:58956a883341_45"},{"__ref":"Paragraph:58956a883341_46"},{"__ref":"Paragraph:58956a883341_47"},{"__ref":"Paragraph:58956a883341_48"},{"__ref":"Paragraph:58956a883341_49"},{"__ref":"Paragraph:58956a883341_50"},{"__ref":"Paragraph:58956a883341_51"},{"__ref":"Paragraph:58956a883341_52"},{"__ref":"Paragraph:58956a883341_53"},{"__ref":"Paragraph:58956a883341_54"},{"__ref":"Paragraph:58956a883341_55"},{"__ref":"Paragraph:58956a883341_56"},{"__ref":"Paragraph:58956a883341_57"},{"__ref":"Paragraph:58956a883341_58"},{"__ref":"Paragraph:58956a883341_59"},{"__ref":"Paragraph:58956a883341_60"},{"__ref":"Paragraph:58956a883341_61"},{"__ref":"Paragraph:58956a883341_62"},{"__ref":"Paragraph:58956a883341_63"},{"__ref":"Paragraph:58956a883341_64"},{"__ref":"Paragraph:58956a883341_65"},{"__ref":"Paragraph:58956a883341_66"},{"__ref":"Paragraph:58956a883341_67"},{"__ref":"Paragraph:58956a883341_68"},{"__ref":"Paragraph:58956a883341_69"},{"__ref":"Paragraph:58956a883341_70"},{"__ref":"Paragraph:58956a883341_71"},{"__ref":"Paragraph:58956a883341_72"},{"__ref":"Paragraph:58956a883341_73"},{"__ref":"Paragraph:58956a883341_74"},{"__ref":"Paragraph:58956a883341_75"},{"__ref":"Paragraph:58956a883341_76"},{"__ref":"Paragraph:58956a883341_77"},{"__ref":"Paragraph:58956a883341_78"},{"__ref":"Paragraph:58956a883341_79"},{"__ref":"Paragraph:58956a883341_80"},{"__ref":"Paragraph:58956a883341_81"},{"__ref":"Paragraph:58956a883341_82"},{"__ref":"Paragraph:58956a883341_83"},{"__ref":"Paragraph:58956a883341_84"},{"__ref":"Paragraph:58956a883341_85"},{"__ref":"Paragraph:58956a883341_86"},{"__ref":"Paragraph:58956a883341_87"},{"__ref":"Paragraph:58956a883341_88"},{"__ref":"Paragraph:58956a883341_89"},{"__ref":"Paragraph:58956a883341_90"},{"__ref":"Paragraph:58956a883341_91"},{"__ref":"Paragraph:58956a883341_92"},{"__ref":"Paragraph:58956a883341_93"},{"__ref":"Paragraph:58956a883341_94"},{"__ref":"Paragraph:58956a883341_95"},{"__ref":"Paragraph:58956a883341_96"},{"__ref":"Paragraph:58956a883341_97"},{"__ref":"Paragraph:58956a883341_98"},{"__ref":"Paragraph:58956a883341_99"},{"__ref":"Paragraph:58956a883341_100"},{"__ref":"Paragraph:58956a883341_101"},{"__ref":"Paragraph:58956a883341_102"},{"__ref":"Paragraph:58956a883341_103"},{"__ref":"Paragraph:58956a883341_104"},{"__ref":"Paragraph:58956a883341_105"},{"__ref":"Paragraph:58956a883341_106"},{"__ref":"Paragraph:58956a883341_107"},{"__ref":"Paragraph:58956a883341_108"},{"__ref":"Paragraph:58956a883341_109"},{"__ref":"Paragraph:58956a883341_110"},{"__ref":"Paragraph:58956a883341_111"},{"__ref":"Paragraph:58956a883341_112"},{"__ref":"Paragraph:58956a883341_113"},{"__ref":"Paragraph:58956a883341_114"},{"__ref":"Paragraph:58956a883341_115"},{"__ref":"Paragraph:58956a883341_116"},{"__ref":"Paragraph:58956a883341_117"},{"__ref":"Paragraph:58956a883341_118"},{"__ref":"Paragraph:58956a883341_119"},{"__ref":"Paragraph:58956a883341_120"},{"__ref":"Paragraph:58956a883341_121"},{"__ref":"Paragraph:58956a883341_122"},{"__ref":"Paragraph:58956a883341_123"},{"__ref":"Paragraph:58956a883341_124"},{"__ref":"Paragraph:58956a883341_125"},{"__ref":"Paragraph:58956a883341_126"},{"__ref":"Paragraph:58956a883341_127"},{"__ref":"Paragraph:58956a883341_128"},{"__ref":"Paragraph:58956a883341_129"},{"__ref":"Paragraph:58956a883341_130"},{"__ref":"Paragraph:58956a883341_131"},{"__ref":"Paragraph:58956a883341_132"},{"__ref":"Paragraph:58956a883341_133"},{"__ref":"Paragraph:58956a883341_134"},{"__ref":"Paragraph:58956a883341_135"},{"__ref":"Paragraph:58956a883341_136"},{"__ref":"Paragraph:58956a883341_137"},{"__ref":"Paragraph:58956a883341_138"},{"__ref":"Paragraph:58956a883341_139"}],"sections":[{"__typename":"Section","name":"7520","startIndex":0,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null}]}},"customStyleSheet":{"__ref":"CustomStyleSheet:dc5d6afeee0a"},"firstPublishedAt":1631169416338,"isIndexable":true,"isLocked":false,"isPublished":true,"isShortform":false,"layerCake":3,"primaryTopic":{"__ref":"Topic:ae5d4995e225"},"title":"Neural Network Pruning 101","isMarkedPaywallOnly":false,"mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Fneural-network-pruning-101-af816aaea61","isLimitedState":false,"visibility":"PUBLIC","license":"ALL_RIGHTS_RESERVED","inResponseToPostResult":null,"allowResponses":true,"newsletterId":"","sequence":null,"tags":[{"__ref":"Tag:neural-networks"},{"__ref":"Tag:pruning"},{"__ref":"Tag:compression"},{"__ref":"Tag:deep-learning"},{"__ref":"Tag:deep-dives"}],"topics":[{"__typename":"Topic","topicId":"1eca0103fff3","name":"Machine Learning"},{"__typename":"Topic","topicId":"ae5d4995e225","name":"Data Science"}],"isNewsletter":false,"socialTitle":"","socialDek":"","noIndex":null,"curationStatus":"CURATION_STATUS_DISTRIBUTED","metaDescription":"","latestPublishedAt":1631519525992,"readingTime":21.278616352201258,"previewContent":{"__typename":"PreviewContent","subtitle":"All you need to know not to get lost"},"previewImage":{"__ref":"ImageMetadata:1*7qwYH1r-h6VOGiE6C2tpGg.png"},"clapCount":258,"postResponses":{"__typename":"PostResponses","count":0},"isSuspended":false,"pendingCollection":null,"statusForCollection":"APPROVED","lockedSource":"LOCKED_POST_SOURCE_NONE","inResponseToEntityType":null,"internalLinks({\"paging\":{\"limit\":8}})":{"__typename":"InternalLinksConnection","items":[{"__ref":"Post:1bf22f28b83"},{"__ref":"Post:b6047b743220"},{"__ref":"Post:d38df0893668"},{"__ref":"Post:7ff1ab58cff8"},{"__ref":"Post:962be7b348ce"},{"__ref":"Post:37caa2796cd9"},{"__ref":"Post:ec7ea0c2a3f3"},{"__ref":"Post:56b6c6f1963e"}]},"pinnedAt":0,"viewerEdge":{"__ref":"PostViewerEdge:postId:af816aaea61-viewerId:lo_cbe4fe29de94"},"collaborators":[{"__ref":"Collaborator:af816aaea61-a71060a2ef24"}],"translationSourcePost":null,"seoTitle":"","updatedAt":1641390863953,"shortformType":"SHORTFORM_TYPE_LINK","structuredData":"","seoDescription":"","latestPublishedVersion":"58956a883341","pinnedByCreatorAt":0,"curationEligibleAt":0,"responseDistribution":"NOT_DISTRIBUTED","inResponseToCatalogResult":null,"isAuthorNewsletter":false,"voterCount":56,"recommenders":[]},"ImageMetadata:1*AGyTPCaRzVqL77kFwUwHKg.png":{"id":"1*AGyTPCaRzVqL77kFwUwHKg.png","__typename":"ImageMetadata","originalWidth":1376,"originalHeight":429},"Tag:editors-pick":{"id":"editors-pick","__typename":"Tag","normalizedTagSlug":"editors-pick"},"Tag:tds-features":{"id":"tds-features","__typename":"Tag","normalizedTagSlug":"tds-features"},"Tag:deep-dives":{"id":"deep-dives","__typename":"Tag","normalizedTagSlug":"deep-dives","displayTitle":"Deep Dives"},"Topic:ae5d4995e225":{"id":"ae5d4995e225","__typename":"Topic","name":"Data Science","slug":"data-science"},"Paragraph:58956a883341_0":{"id":"58956a883341_0","__typename":"Paragraph","name":"06b7","text":"Neural Network Pruning 101","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_1":{"id":"58956a883341_1","__typename":"Paragraph","name":"c2f6","text":"All you need to know not to get lost","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_2":{"id":"58956a883341_2","__typename":"Paragraph","name":"ca09","text":"Whether it is in computer vision, natural language processing or image generation, deep neural networks yield the state of the art. However, their cost in terms of computational power, memory or energy consumption can be prohibitive, making some of them downright unaffordable for most limited hardware. Yet, many domains would benefit from neural networks, hence the need to reduce their cost while maintaining their performance.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_3":{"id":"58956a883341_3","__typename":"Paragraph","name":"375f","text":"That is the whole point of neural networks compression. This field counts multiple families of methods, such as quantization [11], factorization [13], distillation [32] or, and this will be the focus of this post, pruning.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_4":{"id":"58956a883341_4","__typename":"Paragraph","name":"24e1","text":"Neural network pruning is a method that revolves around the intuitive idea of removing superfluous parts of a network that performs well but costs a lot of resources. Indeed, even though large neural networks have proven countless times how well they could learn, it turns out that not all of their parts are still useful after the training process is over. The idea is to eliminate these parts without impacting the network’s performance.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_5":{"id":"58956a883341_5","__typename":"Paragraph","name":"9a45","text":"Unfortunately, the dozens, if not hundreds, of papers published each year are revealing the hidden complexity of a supposedly straight-forward idea. Indeed, a quick overview of the literature yields countless ways of identifying said useless parts or removing them before, during or after training; it even turns out that not all kinds of pruning actually allow for accelerating neural networks, which is supposed to be the whole point.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_6":{"id":"58956a883341_6","__typename":"Paragraph","name":"b038","text":"The goal of this post is to provide a solid foundation to tackle the intimidatingly wild literature around neural network pruning. We will review successively three questions that seem to be at the core of the whole domain: “What kind of part should I prune?”, “How to tell which parts can be pruned?” and “How to prune parts without harming the network?”. To sum it up, we will detail pruning structures, pruning criteria and pruning methods.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":386,"end":404,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":406,"end":422,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":427,"end":442,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}]},"Paragraph:58956a883341_7":{"id":"58956a883341_7","__typename":"Paragraph","name":"1f16","text":"1 — Pruning structures","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_8":{"id":"58956a883341_8","__typename":"Paragraph","name":"8cb0","text":"1.1 — Unstructured pruning","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_9":{"id":"58956a883341_9","__typename":"Paragraph","name":"fdc8","text":"When talking about the cost of neural networks, the count of parameters is surely one of the most widely used metrics, along with FLOPS (floating-point operations per second). It is indeed intimidating to see networks displaying astronomical amounts of weights (up to billions for some), often correlated with stellar performance. Therefore, it is quite intuitive to aim at reducing directly this count by removing parameters themselves. Actually, pruning connections is one of the most widespread paradigms in the literature, enough to be considered as the default framework when dealing with pruning. The seminal work of Han et al.[26] presented this kind of pruning and served as a basis for numerous contributions [18, 21, 25].","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_10":{"id":"58956a883341_10","__typename":"Paragraph","name":"462b","text":"Directly pruning parameters has many advantages. First, it is simple, since replacing the value of their weight with zero, within the parameter tensors, is enough to prune a connection. Widespread deep learning frameworks, such as Pytorch, allow to easily access all the parameters of a network, making it extremely simple to implement. Still, the greatest advantage of pruning connections remains yet that they are the smallest, most fundamental elements of networks and, therefore, they are numerous enough to prune them in large quantities without impacting performance. Such a fine granularity allows pruning very subtle patterns, up to parameters within convolution kernels, for example. As pruning weights is not limited by any constraint at all and is the finest way to prune a network, such a paradigm is called unstructured pruning.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":820,"end":840,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}]},"Paragraph:58956a883341_11":{"id":"58956a883341_11","__typename":"Paragraph","name":"67a2","text":"However, this method presents a major, fatal drawback: most frameworks and hardware cannot accelerate sparse matrices’ computation, meaning that no matter how many zeros you fill the parameter tensors with, it will not impact the actual cost of the network. What does impact it, however, is pruning in a way that directly alters the very architecture of the network, which any framework can handle.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_12":{"id":"58956a883341_12","__typename":"Paragraph","name":"a727","text":"Difference between unstructured (left) and structured (right) pruning: structured pruning removes both convolution filters and rows of kernels instead of just pruning connections. This leads to fewer feature maps within intermediate representations. (image by author)","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*7qwYH1r-h6VOGiE6C2tpGg.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_13":{"id":"58956a883341_13","__typename":"Paragraph","name":"01ae","text":"1.2 — Structured pruning","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_14":{"id":"58956a883341_14","__typename":"Paragraph","name":"d73b","text":"This is the reason why many works have focused on pruning larger structures, such as whole neurons [36] or, for its direct equivalent within the more modern deep convolutional networks, convolution filters [40, 41, 66]. Filter pruning allows for an exploitable and yet fine enough granularity, as large networks tend to include numerous convolution layers, each counting up to hundreds or thousands of filters. Not only does removing such structures result in sparse layers that can be directly instantiated as thinner ones, but doing so also eliminates the feature maps that are the outputs of such filters.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_15":{"id":"58956a883341_15","__typename":"Paragraph","name":"4a73","text":"Therefore, not only are such networks lighter to store, due to fewer parameters, but also they require less computations and generate lighter intermediate representations, hence needing less memory during runtime. Actually, it is sometimes more beneficial to reduce bandwidth rather than the parameter count. Indeed, for tasks that involve large images, such as semantic segmentation or object detection, intermediate representations may be prohibitively memory-consuming, way more than the network itself. For these reasons, filter pruning is now seen as the default kind of structured pruning.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":576,"end":594,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}]},"Paragraph:58956a883341_16":{"id":"58956a883341_16","__typename":"Paragraph","name":"b13b","text":"Yet, when applying such a pruning, one should pay attention to the following aspects. Let’s consider how a convolution layer is built: for Cin input channels and Cout output ones, a convolution layer is made of Cout filters, each counting Cin kernels; each filter outputs one feature map and within each filter, one kernel is dedicated to each input channel. Considering this architecture, and acknowledging a regular convolutional network basically stacks convolution layers, when pruning whole filters, one may observe that pruning a filter, and then the feature map it outputs, actually results in pruning the corresponding kernels in the ensuing layer too. That means that, when pruning filters, one may actually prune twice the amount of parameters thought to be removed in the first place.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":139,"end":142,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":162,"end":166,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":211,"end":215,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":239,"end":242,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}]},"Paragraph:58956a883341_17":{"id":"58956a883341_17","__typename":"Paragraph","name":"920a","text":"Let’s consider too that, when a whole layer happens to get pruned (which tends to happen because of layer collapse [62], but does not always break the network, depending on the architecture), the previous layer’s outputs are now totally unconnected, hence pruned too: pruning a whole layer may actually prune all its previous layers whose outputs are not somehow connected elsewhere (because of residual connections [28] or whole parallel paths [61]). Therefore, when pruning filters, one should consider computing the exact number of actually pruned parameters. Indeed, pruning the same amount of filters, depending on their distribution within the architecture, may not lead to the same actual amount of pruned parameters, making any result impossible to compare with.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":463,"end":561,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}]},"Paragraph:58956a883341_18":{"id":"58956a883341_18","__typename":"Paragraph","name":"64ad","text":"Before changing topic, let’s just mention that, albeit a minority, some works focus on pruning convolution kernels, intra-kernel structures [2,24, 46] or even specific parameter-wise structures. However, such structures need special implementations to lead to any kind of speedup (as for unstructured pruning). Another kind of exploitable structure, though, is to turn convolutions into “shift layers” by pruning all but one parameter in each kernel, which can then be summed up as a combination of a shifting operation and a 1 × 1 convolution [24].","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":159,"end":193,"href":"https:\u002F\u002Fdeveloper.nvidia.com\u002Fblog\u002Faccelerating-inference-with-sparsity-using-ampere-and-tensorrt\u002F","anchorType":"LINK","userId":null,"linkMetadata":null}]},"Paragraph:58956a883341_19":{"id":"58956a883341_19","__typename":"Paragraph","name":"5242","text":"The danger of structured pruning: altering the input and output dimensions of layers can lead to some discrepancies. If on the left, both layers output the same number of feature maps, that can be summed up well afterward, their pruned counterparts on the right produce intermediate representations of different dimensions, that cannot be summed up without processing them. (image by author)","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*o0Qh-ORMytWTA2xdCFbPiQ.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_20":{"id":"58956a883341_20","__typename":"Paragraph","name":"7400","text":"2 — Pruning criteria","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_21":{"id":"58956a883341_21","__typename":"Paragraph","name":"af47","text":"Once one has decided what kind of structure to prune, the next question one may ask could be: “Now, how do I figure out which ones to keep and which ones to prune?”. To answer that one needs a proper pruning criteria, that will rank the relative importance of the parameters, filters or else.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_22":{"id":"58956a883341_22","__typename":"Paragraph","name":"a3f6","text":"2.1 — Weight magnitude criterion","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_23":{"id":"58956a883341_23","__typename":"Paragraph","name":"ab7c","text":"One criterion that is quite intuitive and surprisingly efficient is pruning weights whose absolute value (or “magnitude”) is the smallest. Indeed, under the constraint of a weight-decay, those which do not contribute significantly to the function are expected to have their magnitude shrink during training. Therefore, the superfluous weights are expected to be those of lesser magnitude [8]. Notwithstanding its simplicity, the magnitude criterion is still widely used in modern works [21, 26, 58], making it a staple of the domain.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_24":{"id":"58956a883341_24","__typename":"Paragraph","name":"b739","text":"However, although this criterion seems trivial to implement in the case of unstructured pruning, one may wonder how to adapt it to structured pruning. One straightforward way is to order filters depending on their norm (L 1 or L 2 for example) [40, 70]. If this method is quite straightforward one may desire to encapsulate multiple sets of parameters within one measure: for example, a convolutional filter, its bias and its batch-normalization parameters together, or even corresponding filters within parallel layers whose outputs are then fused and whose channels we would like to reduce.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_25":{"id":"58956a883341_25","__typename":"Paragraph","name":"44f2","text":"One way to do that, without having to compute the combined norm of these parameters, involves inserting a learnable multiplicative parameter for each feature map after each set of layers you want to prune. This gate, when reduced to zero, effectively prunes the whole set of parameters responsible for this channel and the magnitude of this gate accounts for the importance of all of them. The method hence consists in pruning the gates of lesser magnitude [36, 41].","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_26":{"id":"58956a883341_26","__typename":"Paragraph","name":"a4d6","text":"2.2 — Gradient magnitude pruning","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_27":{"id":"58956a883341_27","__typename":"Paragraph","name":"e034","text":"Magnitude of the weight is not the only popular criterion (or family of criteria) that exists. Actually, the other main criterion to have lasted up to now is the magnitude of the gradient. Indeed, back in the 80's some fundamental works [37, 53] theorized, through a Taylor decomposition of the impact of removing a parameter on the loss, that some metrics, derived from the back-propagated gradient, may provide a good way to determine which parameters could be pruned without damaging the network.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_28":{"id":"58956a883341_28","__typename":"Paragraph","name":"50c3","text":"More modern implementations of this criterion [4, 50] actually accumulate gradients over a minibatch of training data and prune on the basis of the product between this gradient and the corresponding weight of each parameter. This criterion can be applied to the aforementioned gates too [49].","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_29":{"id":"58956a883341_29","__typename":"Paragraph","name":"f74e","text":"2.3 — Global or local pruning","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_30":{"id":"58956a883341_30","__typename":"Paragraph","name":"7f2b","text":"One final aspect to take into consideration is whether the chosen criterion is applied globally to all parameters or filters of the network, or if it is computed independently for each layer. While global pruning has proven many times to yield better results, it can lead to layer collapse [62]. A simple way to avoid this problem is to resort to layer-wise local pruning, namely pruning the same rate at each layer, when the used method cannot prevent layer collapse.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_31":{"id":"58956a883341_31","__typename":"Paragraph","name":"89e2","text":"Difference between local pruning (left) and global pruning (right): local pruning applies the same rate to each layer while global applies it on the whole network at once. (image by author)","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*rMLCgVa380ZBcgM0Iqg84Q.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_32":{"id":"58956a883341_32","__typename":"Paragraph","name":"703c","text":"3 — Pruning method","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_33":{"id":"58956a883341_33","__typename":"Paragraph","name":"e967","text":"Now that we have got our pruning structure and criterion, the only parameter left is which method should we use to prune a network. This is actually the topic on which the literature can be the most confusing, as each paper will bring its own quirks and gimmicks, so much that one may get lost between what is methodically relevant and what is just a specificity of a given paper.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_34":{"id":"58956a883341_34","__typename":"Paragraph","name":"7b8d","text":"This is why we will thematically overview some of the most popular families of method to prune neural networks, in an order that highlights the evolution of the use of sparsity during training.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_35":{"id":"58956a883341_35","__typename":"Paragraph","name":"45d5","text":"3.1 — The classic framework: train, prune and fine-tune","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_36":{"id":"58956a883341_36","__typename":"Paragraph","name":"f197","text":"The first basic framework to know is the train, prune and fine-tune method, which obviously involves 1) training the network 2) pruning it by setting to 0 all parameters targeted by the pruning structures and criterion (these parameters cannot recover afterwhile) and 3) training the network for a few extra epochs, with the lowest learning rate, to give it a chance to recover from the loss in performance induced by pruning. Usually, these last two steps can be iterated, with each time a growing pruning rate.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_37":{"id":"58956a883341_37","__typename":"Paragraph","name":"50e4","text":"The method proposed by Han et al. [26] applies this method, with 5 iterations between pruning and fine-tuning, to weight magnitude pruning. Iterating has shown to improve performance, at the cost of extra computation and training time. This simple framework serves as a basis for many works [26, 40, 41, 50, 66] and can be seen as the default method over which all the others have built.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_38":{"id":"58956a883341_38","__typename":"Paragraph","name":"62f4","text":"3.2 — Extending the classic framework","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_39":{"id":"58956a883341_39","__typename":"Paragraph","name":"3d86","text":"While not straying too far, some methods have brought significant modifications to the aforementioned classic framework by Han et al. [26]. Gale et al. [21] have pushed the principle of iterations further by removing an increasing amount of weights progressively all along the training process, which allows benefiting from the advantages of iterations and to remove the whole fine-tuning process. He et al. [29] reduce prunable filters to 0, at each epoch, while not preventing them from learning and being updated afterward, in order to let their weights grow back after pruning while enforcing sparsity during training.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_40":{"id":"58956a883341_40","__typename":"Paragraph","name":"67de","text":"Finally, the method of Renda et al. [58] involves fully retraining a network once it is pruned. Unlike fine-tuning, which is performed at the lowest learning-rate, retraining follows the same learning-rate schedule as training, hence its name: “Learning-Rate Rewinding”. This retraining has shown to yield better performance than mere fine-tuning, at a significantly higher cost.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_41":{"id":"58956a883341_41","__typename":"Paragraph","name":"062d","text":"3.3 — Pruning at initialization","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_42":{"id":"58956a883341_42","__typename":"Paragraph","name":"6ba9","text":"In order to speed up training, avoid fine-tuning and prevent any alteration of the architecture during or after training, multiple works have focused on pruning before training. In the wake of SNIP [39], many works have studied the use of the work of Le Cun et al. [37] or of Mozer and Smolensky [53] to prune at initialization [12, 64], including intensive theoretical studies [27, 38, 62]. However, Optimal Brain Damage [37] relies on multiple approximations including an “extremal” approximation that “assumes that parameter deletion will be performed after training has converged” [37]; this fact is rarely mentioned, even among works that are based on it. Some works have raised reservations about the ability of such methods to generate masks whose relevance outshines random ones of similar distribution per layer [20].","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_43":{"id":"58956a883341_43","__typename":"Paragraph","name":"98e1","text":"Another family of methods that study the relationship between pruning and initialization gravitates around the “Lottery Ticket Hypothesis” [18]. This hypothesis states that “randomly-initialized, dense neural network contains a subnet-work that is initialized such that — when trained in isolation — it can match the test accuracy of the original network after training for at most the same number of iterations”. In practice, this literature studies how well a pruning mask, defined using an already converged network, can be applied to the network back when it was just initialized. Multiple works have expanded, stabilized or studied this hypothesis [14, 19, 45, 51, 69]. However, once again multiple works tend to question the validity of the hypothesis and of the method used to study it [21, 42] and some even tend to show that its benefits rather came from the principle of fully training with the definitive mask instead of a hypothetical “Winning Ticket” [58].","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_44":{"id":"58956a883341_44","__typename":"Paragraph","name":"9383","text":"Comparison between the classic “train, prune and fine-tune” framework [26], the lottery ticket experiment [18] and learning rate rewinding [58]. (image by author)","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*ALVyE5U7jC692UGVKCVY8Q.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_45":{"id":"58956a883341_45","__typename":"Paragraph","name":"0d30","text":"3.4 — Sparse training","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_46":{"id":"58956a883341_46","__typename":"Paragraph","name":"fd21","text":"The previous methods are linked by a seemingly shared underlying theme: training under sparsity constraints. This principle is at the core of a family of methods, called sparse training, which consists in enforcing a constant rate of sparsity during training while its distribution varies and is progressively adjusted. Introduced by Mocanu et al. [47], it involves: 1) initializing the network with a random mask that prunes a certain proportion of the network 2) training this pruned network during one epoch 3) pruning a certain amount of weights of lower magnitude and 4) regrowing the same amount of random weights.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":170,"end":185,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}]},"Paragraph:58956a883341_47":{"id":"58956a883341_47","__typename":"Paragraph","name":"4cad","text":"That way, the pruning mask, at first random, is progressively adjusted to target the least import weights while enforcing sparsity all throughout training. The sparsity level can be the same for each layer [47] or global [52]. Other methods have extended sparse training by using a certain criterion to regrow weights instead of choosing them randomly [15, 17].","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_48":{"id":"58956a883341_48","__typename":"Paragraph","name":"ecaa","text":"Sparse training cuts and grows different weights periodically during training, which leads to an adjusted mask that should target only relevant parameters. (image by author)","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*3hP9xPMOSnsxqtLIvGrhOA.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_49":{"id":"58956a883341_49","__typename":"Paragraph","name":"f9f3","text":"3.5 — Mask learning","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_50":{"id":"58956a883341_50","__typename":"Paragraph","name":"88ec","text":"Instead of relying on arbitrary criteria to prune or regrow weights, multiple methods focus on learning a pruning mask during training. Two types of methods seem to prevail in this domain: 1) mask learning through separate networks or layers and 2) mask learning through auxiliary parameters. Multiple kinds of strategies can fit in the methods of the first type: training separate agents to prune as many filters of a layer as possible while maximizing the accuracy [33], inserting attention-based layers [68] or using reinforcement learning [30]. The second kind of methods aims at considering pruning as an optimization problem that tends to minimize both the L0 norm of the network and its supervised loss.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_51":{"id":"58956a883341_51","__typename":"Paragraph","name":"1475","text":"Since the L0 is non-differentiable, the various methods mainly involve circumventing this problem through the use of penalized auxiliary parameters that are multiplied with their corresponding parameter during the forward pass [59, 23]. Many methods [44, 60, 67] rely on a method analogous to that of “Binary Connect” [11], namely: applying stochastic gates over parameters whose values are each randomly drawn from their own Bernoulli distribution of parameter p that is learned using a “Straight Through Estimator” [3] or other means [44].","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":462,"end":463,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}]},"Paragraph:58956a883341_52":{"id":"58956a883341_52","__typename":"Paragraph","name":"7a36","text":"3.6 — Penalty-based methods","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_53":{"id":"58956a883341_53","__typename":"Paragraph","name":"b905","text":"Many methods, instead of pruning connections manually or penalizing auxiliary parameters, rather apply various kinds of penalties to weights themselves to make them progressively shrink toward 0. This notion is actually pretty ancient [57], as weight-decay is already an essential element to the weight magnitude criterion. Beyond using a mere weight-decay, even back then multiple works focused on elaborating penalties specifically designed to enforce sparsity [55, 65]. Today, various methods apply different regularizations, on top of the weight decay, to increase further the sparsity (typically, using L 1 norm [41]).","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_54":{"id":"58956a883341_54","__typename":"Paragraph","name":"ba3b","text":"Among modern works, multiple methods rely on the LASSO (Least Absolute Shrinkage and Selection Operator) [22, 31, 66] to prune weights or groups. Other methods develop penalties that target weak connections to increase the gap between the parameters to keep and those to prune, so that their removal has less impact [7, 16]. Some methods show that targeting a subset of weights with a penalization that grows all throughout training can progressively prune them and make their removal seamless [6, 9, 63]. The literature also counts a whole range of methods built around the principle of “Variational Dropout” [34], a method based on variational inference [5] applied to deep learning [35]. As a pruning method [48], it birthed multiple works that adapt its principle to structured pruning [43, 54].","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_55":{"id":"58956a883341_55","__typename":"Paragraph","name":"344e","text":"4 — Available frameworks","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_56":{"id":"58956a883341_56","__typename":"Paragraph","name":"d420","text":"If most of these methods have to be implemented from scratch (or can be reused from the provided sources of each paper, if they do provide them), some frameworks exist to apply basic methods or make the aforementioned implementation easier.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_57":{"id":"58956a883341_57","__typename":"Paragraph","name":"1145","text":"4.1 — Pytorch","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_58":{"id":"58956a883341_58","__typename":"Paragraph","name":"9c63","text":"Pytorch [56] provide multiple quality-of-life features to help pruning networks. The provided tools allow to easily apply a mask to a network and maintain this mask during training, as well as it allows to easily revert that mask if needed. Pytorch also provide some basic pruning methods, such as global or local pruning, whether it is structured or not. Structured pruning can be applied on any dimension of the weights tensors, which lets pruning filters, rows of kernels or even some rows and columns inside kernels. Those in-built basic methods also allow pruning randomly or depending on various norms.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":0,"end":7,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}]},"Paragraph:58956a883341_59":{"id":"58956a883341_59","__typename":"Paragraph","name":"3f1c","text":"4.2 — Tensorflow","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_60":{"id":"58956a883341_60","__typename":"Paragraph","name":"db73","text":"The Keras [10] library from Tensorflow [1] provide some basic tools to prune weights of lower magnitudes. Such as in the work of Han et al [25], the efficiency of pruning is measured in terms of how much does the redundancy, introduced by all the inserted zeros, allows to compress the model better (which combines well with quantization).","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":4,"end":9,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":28,"end":38,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}]},"Paragraph:58956a883341_61":{"id":"58956a883341_61","__typename":"Paragraph","name":"c61c","text":"4.3 — ShrinkBench","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_62":{"id":"58956a883341_62","__typename":"Paragraph","name":"29c2","text":"Blalock et al. [4] provide in their work a custom library in an effort to help the community normalize how pruning algorithm are compared. Based on Pytorch, ShrinkBench aims at making the implementation of pruning methods easier while normalizing the conditions under which they are trained and tested. It provides different baselines, such as random pruning, global or layerwise and weight magnitude or gradient magnitude pruning.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":148,"end":155,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":157,"end":168,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}]},"Paragraph:58956a883341_63":{"id":"58956a883341_63","__typename":"Paragraph","name":"0db7","text":"5 — Brief recap of reviewed methods","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_64":{"id":"58956a883341_64","__typename":"Paragraph","name":"4f0a","text":"In this article, many papers have been cited. Here is a simple table to roughly summarize what they do and what differentiates them (provided dates are those of first publication):","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_65":{"id":"58956a883341_65","__typename":"Paragraph","name":"0635","text":"","type":"IFRAME","href":null,"layout":"INSET_CENTER","metadata":null,"hasDropCap":null,"iframe":{"__typename":"Iframe","mediaResource":{"__ref":"MediaResource:5b60387af4bb2dc372bdb5cd4701b98c"}},"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_66":{"id":"58956a883341_66","__typename":"Paragraph","name":"5fc5","text":"6 — Conclusion","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_67":{"id":"58956a883341_67","__typename":"Paragraph","name":"dbd7","text":"In our quick overview of the literature, we saw that 1) pruning structures define which kind of gain to expect from pruning 2) pruning criteria are based on various theoretical or practical justifications and 3) pruning methods tend to revolve around introducing sparsity during training to reconcile performance and cost. We also saw that, even though its founding works date back from the late 80’s, neural network pruning is a very dynamic field that still experiences fundamental discoveries and new basic concepts today.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_68":{"id":"58956a883341_68","__typename":"Paragraph","name":"8cda","text":"Despite the daily contributions in the domain, there seems to be still plenty of room for exploration and innovation. If each subfamily of method can be seen as an attempt to answer a question (“How to regrow pruned weights ?”, “How to learn pruning masks through optimization ?”, “How to relax the weight removal by a softer mean ?”…), then the evolution of the literature seems to point out a certain direction: that of sparsity throughout training. This direction raises itself many questions, such as: “do pruning criteria work well on networks that haven’t converged yet?” or “how to tell the benefit of the choice of the weights to prune from that of training with any kind of sparsity from the start?”","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_69":{"id":"58956a883341_69","__typename":"Paragraph","name":"b0a7","text":"References","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_70":{"id":"58956a883341_70","__typename":"Paragraph","name":"333c","text":"[1] Martı́n Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dandelion Mané, Rajat Monga, Sherry Moore, Derek Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Viégas, Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. TensorFlow: Large-scale machine learning on heterogeneous systems, 2015. Software available from tensorflow.org.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_71":{"id":"58956a883341_71","__typename":"Paragraph","name":"1fba","text":"[2] Sajid Anwar, Kyuyeon Hwang, and Wonyong Sung. Structured pruning of deep convolutional neural networks. ACM Journal on Emerging Technologies in Computing Systems (JETC), 13(3):1–18, 2017.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_72":{"id":"58956a883341_72","__typename":"Paragraph","name":"9ab6","text":"[3] Yoshua Bengio, Nicholas Léonard, and Aaron Courville. Estimating or propagating gradients through stochastic neurons for conditional computation. arXiv preprint arXiv:1308.3432, 2013.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_73":{"id":"58956a883341_73","__typename":"Paragraph","name":"4225","text":"[4] Davis Blalock, Jose Javier Gonzalez Ortiz, Jonathan Frankle, and John Guttag. What is the state of neural network pruning? arXiv preprint arXiv:2003.03033, 2020.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_74":{"id":"58956a883341_74","__typename":"Paragraph","name":"1893","text":"[5] David M Blei, Alp Kucukelbir, and Jon D McAuliffe. Variational inference: A review for statisticians. Journal of the American statistical Association, 112(518):859–877, 2017.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_75":{"id":"58956a883341_75","__typename":"Paragraph","name":"4edf","text":"[6] Miguel A Carreira-Perpinán and Yerlan Idelbayev. “learning-compression” algorithms for neural net pruning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 8532–8541, 2018.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_76":{"id":"58956a883341_76","__typename":"Paragraph","name":"5a92","text":"[7] Jing Chang and Jin Sha. Prune deep neural networks with the modified L1\u002F2 penalty. IEEE Access, 7:2273–2280, 2018.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_77":{"id":"58956a883341_77","__typename":"Paragraph","name":"7d74","text":"[8] Yves Chauvin. A back-propagation algorithm with optimal use of hidden units. In NIPS, volume 1, pages 519–526, 1988.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_78":{"id":"58956a883341_78","__typename":"Paragraph","name":"2b0e","text":"[9] Yoojin Choi, Mostafa El-Khamy, and Jungwon Lee. Compression of deep convolutional neural networks under joint sparsity constraints. arXiv preprint arXiv:1805.08303, 2018.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_79":{"id":"58956a883341_79","__typename":"Paragraph","name":"5860","text":"[10] Francois Chollet et al. Keras, 2015.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_80":{"id":"58956a883341_80","__typename":"Paragraph","name":"a78f","text":"[11] Matthieu Courbariaux, Yoshua Bengio, and Jean-Pierre David. Binaryconnect: Training deep neural networks with binary weights during propagations. In NIPS, 2015.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_81":{"id":"58956a883341_81","__typename":"Paragraph","name":"f314","text":"[12] Pau de Jorge, Amartya Sanyal, Harkirat S Behl, Philip HS Torr, Gregory Rogez, and Puneet K Dokania. Progressive skeletonization: Trimming more fat from a network at initialization. arXiv preprint arXiv:2006.09081, 2020.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_82":{"id":"58956a883341_82","__typename":"Paragraph","name":"5849","text":"[13] Emily Denton, Wojciech Zaremba, Joan Bruna, Yann LeCun, and Rob Fergus. Exploiting linear structure within convolutional networks for efficient evaluation. In 28th Annual Conference on Neural Information Processing Systems 2014, NIPS 2014, pages 1269–1277. Neural information processing systems foundation, 2014.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_83":{"id":"58956a883341_83","__typename":"Paragraph","name":"2aed","text":"[14] Shrey Desai, Hongyuan Zhan, and Ahmed Aly. Evaluating lottery tickets under distributional shifts. In Proceedings of the 2nd Workshop on Deep Learning Approaches for Low-Resource NLP (DeepLo 2019), pages 153–162, 2019.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_84":{"id":"58956a883341_84","__typename":"Paragraph","name":"eb74","text":"[15] Tim Dettmers and Luke Zettlemoyer. Sparse networks from scratch: Faster training without losing performance. arXiv preprint arXiv:1907.04840, 2019.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_85":{"id":"58956a883341_85","__typename":"Paragraph","name":"b415","text":"[16] Xiaohan Ding, Guiguang Ding, Xiangxin Zhou, Yuchen Guo, Jungong Han, and Ji Liu. Global sparse momentum sgd for pruning very deep neural networks. arXiv preprint arXiv:1909.12778, 2019.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_86":{"id":"58956a883341_86","__typename":"Paragraph","name":"f184","text":"[17] Utku Evci, Trevor Gale, Jacob Menick, Pablo Samuel Castro, and Erich Elsen. Rigging the lottery: Making all tickets winners. In International Conference on Machine Learning, pages 2943–2952. PMLR, 2020.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_87":{"id":"58956a883341_87","__typename":"Paragraph","name":"bf6f","text":"[18] Jonathan Frankle and Michael Carbin. The lottery ticket hypothesis: Finding sparse, trainable neural networks. arXiv preprint arXiv:1803.03635, 2018.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_88":{"id":"58956a883341_88","__typename":"Paragraph","name":"3617","text":"[19] Jonathan Frankle, Gintare Karolina Dziugaite, Daniel M Roy, and Michael Carbin. Stabilizing the lottery ticket hypothesis. arXiv preprint arXiv:1903.01611, 2019.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_89":{"id":"58956a883341_89","__typename":"Paragraph","name":"58c0","text":"[20] Jonathan Frankle, Gintare Karolina Dziugaite, Daniel M Roy, and Michael Carbin. Pruning neural networks at initialization: Why are we missing the mark? arXiv preprint arXiv:2009.08576, 2020.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_90":{"id":"58956a883341_90","__typename":"Paragraph","name":"4f5f","text":"[21] Trevor Gale, Erich Elsen, and Sara Hooker. The state of sparsity in deep neural networks. arXiv preprint arXiv:1902.09574, 2019.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_91":{"id":"58956a883341_91","__typename":"Paragraph","name":"74d8","text":"[22] Susan Gao, Xin Liu, Lung-Sheng Chien, William Zhang, and Jose M Alvarez. Vacl: Variance-aware cross-layer regularization for pruning deep residual networks. In Proceedings of the IEEE\u002FCVF International Conference on Computer Vision Workshops, pages 0–0, 2019.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_92":{"id":"58956a883341_92","__typename":"Paragraph","name":"a37e","text":"[23] Yiwen Guo, Anbang Yao, and Yurong Chen. Dynamic network surgery for efficient dnns. In NIPS, 2016.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_93":{"id":"58956a883341_93","__typename":"Paragraph","name":"771a","text":"[24] Ghouthi Boukli Hacene, Carlos Lassance, Vincent Gripon, Matthieu Courbariaux, and Yoshua Bengio. Attention based pruning for shift networks. In 2020 25th International Conference on Pattern Recognition (ICPR), pages 4054–4061. IEEE, 2021.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_94":{"id":"58956a883341_94","__typename":"Paragraph","name":"c933","text":"[25] Song Han, Huizi Mao, and William J Dally. Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding. arXiv preprint arXiv:1510.00149, 2015.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_95":{"id":"58956a883341_95","__typename":"Paragraph","name":"a6e9","text":"[26] Song Han, Jeff Pool, John Tran, and William J Dally. Learning both weights and connections for efficient neural network. In NIPS, 2015.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_96":{"id":"58956a883341_96","__typename":"Paragraph","name":"3b8d","text":"[27] Soufiane Hayou, Jean-Francois Ton, Arnaud Doucet, and Yee Whye Teh. Robust pruning at initialization.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_97":{"id":"58956a883341_97","__typename":"Paragraph","name":"ff92","text":"[28] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770–778, 2016.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_98":{"id":"58956a883341_98","__typename":"Paragraph","name":"9f85","text":"[29] Yang He, Guoliang Kang, Xuanyi Dong, Yanwei Fu, and Yi Yang. Soft filter pruning for accelerating deep convolutional neural networks. arXiv preprint arXiv:1808.06866, 2018.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_99":{"id":"58956a883341_99","__typename":"Paragraph","name":"14d2","text":"[30] Yihui He, Ji Lin, Zhijian Liu, Hanrui Wang, Li-Jia Li, and Song Han. Amc: Automl for model compression and acceleration on mobile devices. In Proceedings of the European Conference on Computer Vision (ECCV), pages 784–800, 2018.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_100":{"id":"58956a883341_100","__typename":"Paragraph","name":"af2f","text":"[31] Yihui He, Xiangyu Zhang, and Jian Sun. Channel pruning for accelerating very deep neural networks. In Proceedings of the IEEE International Conference on Computer Vision, pages 1389–1397, 2017.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_101":{"id":"58956a883341_101","__typename":"Paragraph","name":"7371","text":"[32] Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distilling the knowledge in a neural network. stat, 1050:9, 2015.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_102":{"id":"58956a883341_102","__typename":"Paragraph","name":"55ce","text":"[33] Qiangui Huang, Kevin Zhou, Suya You, and Ulrich Neumann. Learning to prune filters in convolutional neural networks. In 2018 IEEE Winter Conference on Applications of Computer Vision (WACV), pages 709–718. IEEE, 2018.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_103":{"id":"58956a883341_103","__typename":"Paragraph","name":"3f8f","text":"[34] Diederik P Kingma, Tim Salimans, and Max Welling. Variational dropout and the local reparameterization trick. stat, 1050:8, 2015.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_104":{"id":"58956a883341_104","__typename":"Paragraph","name":"93d7","text":"[35] Diederik P Kingma and Max Welling. Auto-encoding variational bayes. stat, 1050:1, 2014.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_105":{"id":"58956a883341_105","__typename":"Paragraph","name":"38d1","text":"[36] John K Kruschke and Javier R Movellan. Benefits of gain: Speeded learning and minimal hidden layers in back-propagation networks. IEEE Transactions on systems, Man, and Cybernetics, 21(1):273–280, 1991.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_106":{"id":"58956a883341_106","__typename":"Paragraph","name":"1b89","text":"[37] Yann LeCun, John S Denker, and Sara A Solla. Optimal brain damage. In Advances in neural information processing systems, pages 598–605, 1990.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_107":{"id":"58956a883341_107","__typename":"Paragraph","name":"b9d6","text":"[38] Namhoon Lee, Thalaiyasingam Ajanthan, Stephen Gould, and Philip HS Torr. A signal propagation perspective for pruning neural networks at initialization. In International Conference on Learning Representations, 2019.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_108":{"id":"58956a883341_108","__typename":"Paragraph","name":"c8c3","text":"[39] Namhoon Lee, Thalaiyasingam Ajanthan, and Philip HS Torr. Snip: Single-shot network pruning based on connection sensitivity. International Conference on Learning Representations, ICLR, 2019.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_109":{"id":"58956a883341_109","__typename":"Paragraph","name":"fa53","text":"[40] Hao Li, Asim Kadav, Igor Durdanovic, Hanan Samet, and Hans Peter Graf. Pruning filters for efficient convnets. arXiv preprint arXiv:1608.08710, 2016.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_110":{"id":"58956a883341_110","__typename":"Paragraph","name":"5975","text":"[41] Zhuang Liu, Jianguo Li, Zhiqiang Shen, Gao Huang, Shoumeng Yan, and Changshui Zhang. Learning efficient convolutional networks through network slimming. In Proceedings of the IEEE International Conference on Computer Vision, pages 2736–2744, 2017.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_111":{"id":"58956a883341_111","__typename":"Paragraph","name":"3879","text":"[42] Zhuang Liu, Mingjie Sun, Tinghui Zhou, Gao Huang, and Trevor Darrell. Rethinking the value of network pruning. In International Conference on Learning Representations, 2018.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_112":{"id":"58956a883341_112","__typename":"Paragraph","name":"8d02","text":"[43] C Louizos, K Ullrich, and M Welling. Bayesian compression for deep learning. In 31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA., 2017.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_113":{"id":"58956a883341_113","__typename":"Paragraph","name":"eb44","text":"[44] Christos Louizos, Max Welling, and Diederik P Kingma. Learning sparse neural networks through l 0 regularization. arXiv preprint arXiv:1712.01312, 2017.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_114":{"id":"58956a883341_114","__typename":"Paragraph","name":"4866","text":"[45] Eran Malach, Gilad Yehudai, Shai Shalev-Schwartz, and Ohad Shamir. Proving the lottery ticket hypothesis: Pruning is all you need. In International Conference on Machine Learning, pages 6682–6691. PMLR, 2020.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_115":{"id":"58956a883341_115","__typename":"Paragraph","name":"235f","text":"[46] Huizi Mao, Song Han, Jeff Pool, Wenshuo Li, Xingyu Liu, Yu Wang, and William J Dally. Exploring the regularity of sparse structure in convolutional neural networks. arXiv preprint arXiv:1705.08922, 2017.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_116":{"id":"58956a883341_116","__typename":"Paragraph","name":"6721","text":"[47] Decebal Constantin Mocanu, Elena Mocanu, Peter Stone, Phuong H Nguyen, Madeleine Gibescu, and Antonio Liotta. Scalable training of artificial neural networks with adaptive sparse connectivity inspired by network science. Nature communications, 9(1):1–12, 2018.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_117":{"id":"58956a883341_117","__typename":"Paragraph","name":"2a85","text":"[48] Dmitry Molchanov, Arsenii Ashukha, and Dmitry Vetrov. Variational dropout sparsifies deep neural networks. In International Conference on Machine Learning, pages 2498–2507. PMLR, 2017.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_118":{"id":"58956a883341_118","__typename":"Paragraph","name":"9f44","text":"[49] Pavlo Molchanov, Arun Mallya, Stephen Tyree, Iuri Frosio, and Jan Kautz. Importance estimation for neural network pruning. In Proceedings of the IEEE\u002FCVF Conference on Computer Vision and Pattern Recognition, pages 11264–11272, 2019.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_119":{"id":"58956a883341_119","__typename":"Paragraph","name":"1ef1","text":"[50] Pavlo Molchanov, Stephen Tyree, Tero Karras, Timo Aila, and Jan Kautz. Pruning convolutional neural networks for resource efficient inference. arXiv preprint arXiv:1611.06440, 2016.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_120":{"id":"58956a883341_120","__typename":"Paragraph","name":"aa9b","text":"[51] Ari S Morcos, Haonan Yu, Michela Paganini, and Yuandong Tian. One ticket to win them all: generalizing lottery ticket initializations across datasets and optimizers. stat, 1050:6, 2019.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_121":{"id":"58956a883341_121","__typename":"Paragraph","name":"79eb","text":"[52] Hesham Mostafa and Xin Wang. Parameter efficient training of deep convolutional neural networks by dynamic sparse reparameterization. In International Conference on Machine Learning, pages 4646–4655. PMLR, 2019.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_122":{"id":"58956a883341_122","__typename":"Paragraph","name":"ce0a","text":"[53] Michael C Mozer and Paul Smolensky. Skeletonization: A technique for trimming the fat from a network via relevance assessment. In Advances in neural information processing systems, pages 107–115, 1989.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_123":{"id":"58956a883341_123","__typename":"Paragraph","name":"d3f1","text":"[54] Kirill Neklyudov, Dmitry Molchanov, Arsenii Ashukha, and Dmitry Vetrov. Structured bayesian pruning via log-normal multiplicative noise. In Proceedings of the 31st International Conference on Neural Information Processing Systems, pages 6778–6787, 2017.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_124":{"id":"58956a883341_124","__typename":"Paragraph","name":"bc88","text":"[55] Steven J Nowlan and Geoffrey E Hinton. Simplifying neural networks by soft weight-sharing. Neural Computation, 4(4):473–493, 1992.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_125":{"id":"58956a883341_125","__typename":"Paragraph","name":"b046","text":"[56] Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic differentiation in pytorch. 2017.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_126":{"id":"58956a883341_126","__typename":"Paragraph","name":"d7b3","text":"[57] Russell Reed. Pruning algorithms-a survey. IEEE transactions on Neural Networks, 4(5):740–747, 1993.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_127":{"id":"58956a883341_127","__typename":"Paragraph","name":"3bf3","text":"[58] Alex Renda, Jonathan Frankle, and Michael Carbin. Comparing rewinding and fine-tuning in neural network pruning. arXiv preprint arXiv:2003.02389, 2020.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_128":{"id":"58956a883341_128","__typename":"Paragraph","name":"3d25","text":"[59] Pedro Savarese, Hugo Silva, and Michael Maire. Winning the lottery with continuous sparsification. Advances in Neural Information Processing Systems, 33, 2020.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_129":{"id":"58956a883341_129","__typename":"Paragraph","name":"5eb0","text":"[60] Suraj Srinivas, Akshayvarun Subramanya, and R Venkatesh Babu. Training sparse neural networks. In Proceedings of the IEEE conference on computer vision and pattern recognition workshops, pages 138–145, 2017.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_130":{"id":"58956a883341_130","__typename":"Paragraph","name":"5fd8","text":"[61] Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going deeper with convolutions. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 1–9, 2015.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_131":{"id":"58956a883341_131","__typename":"Paragraph","name":"1d5f","text":"[62] Hidenori Tanaka, Daniel Kunin, Daniel L Yamins, and Surya Ganguli. Pruning neural networks without any data by iteratively conserving synaptic flow. Advances in Neural Information Processing Systems, 33, 2020.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_132":{"id":"58956a883341_132","__typename":"Paragraph","name":"44d2","text":"[63] Hugo Tessier, Vincent Gripon, Mathieu Léonardon, Matthieu Arzel, Thomas Hannagan, and David Bertrand. Rethinking weight decay for efficient neural network pruning. 2021.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_133":{"id":"58956a883341_133","__typename":"Paragraph","name":"1727","text":"[64] Chaoqi Wang, Guodong Zhang, and Roger Grosse. Picking winning tickets before training by preserving gradient flow. In International Conference on Learning Representations, 2019.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_134":{"id":"58956a883341_134","__typename":"Paragraph","name":"c94b","text":"[65] Andreas S Weigend, David E Rumelhart, and Bernardo A Huberman. Generalization by weight-elimination with application to forecasting. In Advances in neural information processing systems, pages 875–882, 1991.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_135":{"id":"58956a883341_135","__typename":"Paragraph","name":"ce36","text":"[66] Wei Wen, Chunpeng Wu, Yandan Wang, Yiran Chen, and Hai Li. Learning structured sparsity in deep neural networks. In NIPS, 2016.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_136":{"id":"58956a883341_136","__typename":"Paragraph","name":"45b5","text":"[67] Xia Xiao, Zigeng Wang, and Sanguthevar Rajasekaran. Autoprune: Automatic network pruning by regularizing auxiliary parameters. Advances in neural information processing systems, 32, 2019.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_137":{"id":"58956a883341_137","__typename":"Paragraph","name":"8e2b","text":"[68] Kohei Yamamoto and Kurato Maeno. Pcas: Pruning channels with attention statistics for deep network compression. arXiv preprint arXiv:1806.05382, 2018.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_138":{"id":"58956a883341_138","__typename":"Paragraph","name":"7479","text":"[69] Hattie Zhou, Janice Lan, Rosanne Liu, and Jason Yosinski. Deconstructing lottery tickets: Zeros, signs, and the supermask. arXiv preprint arXiv:1905.01067, 2019.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:58956a883341_139":{"id":"58956a883341_139","__typename":"Paragraph","name":"726f","text":"[70] Zhuangwei Zhuang, Mingkui Tan, Bohan Zhuang, Jing Liu, Yong Guo, Qingyao Wu, Junzhou Huang, and Jin-Hui Zhu. Discrimination-aware channel pruning for deep neural networks. In NeurIPS, 2018.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"ImageMetadata:1*7qwYH1r-h6VOGiE6C2tpGg.png":{"id":"1*7qwYH1r-h6VOGiE6C2tpGg.png","__typename":"ImageMetadata","originalHeight":1436,"originalWidth":2430,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*o0Qh-ORMytWTA2xdCFbPiQ.png":{"id":"1*o0Qh-ORMytWTA2xdCFbPiQ.png","__typename":"ImageMetadata","originalHeight":1950,"originalWidth":2268,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*rMLCgVa380ZBcgM0Iqg84Q.png":{"id":"1*rMLCgVa380ZBcgM0Iqg84Q.png","__typename":"ImageMetadata","originalHeight":879,"originalWidth":2048,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*ALVyE5U7jC692UGVKCVY8Q.png":{"id":"1*ALVyE5U7jC692UGVKCVY8Q.png","__typename":"ImageMetadata","originalHeight":838,"originalWidth":2058,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*3hP9xPMOSnsxqtLIvGrhOA.png":{"id":"1*3hP9xPMOSnsxqtLIvGrhOA.png","__typename":"ImageMetadata","originalHeight":1217,"originalWidth":2048,"focusPercentX":null,"focusPercentY":null,"alt":null},"MediaResource:5b60387af4bb2dc372bdb5cd4701b98c":{"id":"5b60387af4bb2dc372bdb5cd4701b98c","__typename":"MediaResource","iframeSrc":"","iframeHeight":0,"iframeWidth":0,"title":"Neural Network Pruning Methods"},"User:895063a310f4":{"id":"895063a310f4","__typename":"User","name":"Ludovic Benistant","username":"ludobenistant","newsletterV3":{"__ref":"NewsletterV3:2375c85c8da7"}},"NewsletterV3:2375c85c8da7":{"id":"2375c85c8da7","__typename":"NewsletterV3"},"Tag:neural-networks":{"id":"neural-networks","__typename":"Tag","displayTitle":"Neural Networks","normalizedTagSlug":"neural-networks"},"Tag:pruning":{"id":"pruning","__typename":"Tag","displayTitle":"Pruning","normalizedTagSlug":"pruning"},"Tag:compression":{"id":"compression","__typename":"Tag","displayTitle":"Compression","normalizedTagSlug":"compression"},"Tag:deep-learning":{"id":"deep-learning","__typename":"Tag","displayTitle":"Deep Learning","normalizedTagSlug":"deep-learning"},"ImageMetadata:1*EYPZZTzfwaQauHg3O5cu6g.png":{"id":"1*EYPZZTzfwaQauHg3O5cu6g.png","__typename":"ImageMetadata","focusPercentX":null,"focusPercentY":null},"UserViewerEdge:userId:fce5a4821198-viewerId:lo_cbe4fe29de94":{"id":"userId:fce5a4821198-viewerId:lo_cbe4fe29de94","__typename":"UserViewerEdge","isFollowing":false,"isUser":false},"NewsletterV3:8d0ea2655290":{"id":"8d0ea2655290","__typename":"NewsletterV3","type":"NEWSLETTER_TYPE_AUTHOR","slug":"fce5a4821198","name":"fce5a4821198","collection":null,"user":{"__ref":"User:fce5a4821198"}},"User:fce5a4821198":{"id":"fce5a4821198","__typename":"User","name":"Crawford Collins","username":"crawftv","newsletterV3":{"__ref":"NewsletterV3:8d0ea2655290"},"bio":"Software Engineer. Sharing what I learn. CrawfordC.com","imageId":"1*95tX8ugiPXY-s3zZ15og4A.jpeg","mediumMemberAt":0,"isPartnerProgramEnrolled":false,"viewerEdge":{"__ref":"UserViewerEdge:userId:fce5a4821198-viewerId:lo_cbe4fe29de94"},"viewerIsUser":false,"customDomainState":null,"hasSubdomain":false,"postSubscribeMembershipUpsellShownAt":0},"Post:1bf22f28b83":{"id":"1bf22f28b83","__typename":"Post","title":"Analyzing Chess with Pandas to Learn from the Best and Raise My Rating.","mediumUrl":"https:\u002F\u002Fmedium.com\u002F@crawftv\u002Fanalyzing-chess-with-pandas-to-learn-from-the-best-raise-my-rating-1bf22f28b83","previewImage":{"__ref":"ImageMetadata:1*EYPZZTzfwaQauHg3O5cu6g.png"},"isPublished":true,"firstPublishedAt":1543369285607,"readingTime":3.7726415094339627,"statusForCollection":null,"isLocked":false,"visibility":"PUBLIC","collection":null,"creator":{"__ref":"User:fce5a4821198"},"previewContent":{"__typename":"PreviewContent","isFullContent":false}},"ImageMetadata:1*JyzoGFreEkuApM7GVl9MBA.png":{"id":"1*JyzoGFreEkuApM7GVl9MBA.png","__typename":"ImageMetadata","focusPercentX":null,"focusPercentY":null},"UserViewerEdge:userId:98698838c808-viewerId:lo_cbe4fe29de94":{"id":"userId:98698838c808-viewerId:lo_cbe4fe29de94","__typename":"UserViewerEdge","isFollowing":false,"isUser":false},"NewsletterV3:805b3a17d7ee":{"id":"805b3a17d7ee","__typename":"NewsletterV3","type":"NEWSLETTER_TYPE_AUTHOR","slug":"98698838c808","name":"98698838c808","collection":null,"user":{"__ref":"User:98698838c808"}},"User:98698838c808":{"id":"98698838c808","__typename":"User","name":"Sai Durga Mahesh","username":"maheshsai252","newsletterV3":{"__ref":"NewsletterV3:805b3a17d7ee"},"bio":"Using Data Science to provide better solutions to real word problems","imageId":"1*nTL0DeGdeXlejBTbmH5B-w.jpeg","mediumMemberAt":1603818270000,"isPartnerProgramEnrolled":false,"viewerEdge":{"__ref":"UserViewerEdge:userId:98698838c808-viewerId:lo_cbe4fe29de94"},"viewerIsUser":false,"customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"maheshsai252.medium.com"}},"hasSubdomain":true,"postSubscribeMembershipUpsellShownAt":0},"Post:b6047b743220":{"id":"b6047b743220","__typename":"Post","title":"Exploring  Udemy Courses","mediumUrl":"https:\u002F\u002Fmaheshsai252.medium.com\u002Fexploring-udemy-courses-b6047b743220","previewImage":{"__ref":"ImageMetadata:1*JyzoGFreEkuApM7GVl9MBA.png"},"isPublished":true,"firstPublishedAt":1589742938997,"readingTime":2.797169811320755,"statusForCollection":null,"isLocked":false,"visibility":"PUBLIC","collection":null,"creator":{"__ref":"User:98698838c808"},"previewContent":{"__typename":"PreviewContent","isFullContent":false}},"ImageMetadata:1*ax1v3BR0cRwSqnB2AH_sYg.png":{"id":"1*ax1v3BR0cRwSqnB2AH_sYg.png","__typename":"ImageMetadata","focusPercentX":null,"focusPercentY":null},"UserViewerEdge:userId:405fe11cf4bf-viewerId:lo_cbe4fe29de94":{"id":"userId:405fe11cf4bf-viewerId:lo_cbe4fe29de94","__typename":"UserViewerEdge","isFollowing":false,"isUser":false},"User:405fe11cf4bf":{"id":"405fe11cf4bf","__typename":"User","name":"Maxime LENORMAND","username":"lenormand.maxime314","bio":"Junior remote sensing engineer at Iceye; MSc in aerospace engineering. Interested in machine learning, satellite imagery, computer vision and aerospace.","imageId":"0*VXn_j95Cn2PPvTPg","mediumMemberAt":0,"isPartnerProgramEnrolled":false,"viewerEdge":{"__ref":"UserViewerEdge:userId:405fe11cf4bf-viewerId:lo_cbe4fe29de94"},"viewerIsUser":false,"newsletterV3":null,"customDomainState":null,"hasSubdomain":false,"postSubscribeMembershipUpsellShownAt":0},"Post:d38df0893668":{"id":"d38df0893668","__typename":"Post","title":"The status of (geo) data science competitions","mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Fthe-status-of-geo-data-science-competitions-d38df0893668","previewImage":{"__ref":"ImageMetadata:1*ax1v3BR0cRwSqnB2AH_sYg.png"},"isPublished":true,"firstPublishedAt":1604760542104,"readingTime":8.119182389937107,"statusForCollection":"APPROVED","isLocked":false,"visibility":"PUBLIC","collection":{"__ref":"Collection:7f60cf5620c9"},"creator":{"__ref":"User:405fe11cf4bf"},"previewContent":{"__typename":"PreviewContent","isFullContent":false}},"ImageMetadata:1*KBRYys-rO_HlD2XGt00ckw.jpeg":{"id":"1*KBRYys-rO_HlD2XGt00ckw.jpeg","__typename":"ImageMetadata","focusPercentX":null,"focusPercentY":null},"CollectionViewerEdge:collectionId:98111c9905da-viewerId:lo_cbe4fe29de94":{"id":"collectionId:98111c9905da-viewerId:lo_cbe4fe29de94","__typename":"CollectionViewerEdge","isEditor":false},"Collection:98111c9905da":{"id":"98111c9905da","__typename":"Collection","name":"Towards AI","description":"Towards AI is the world’s leading AI and technology publication. Publishing unbiased AI and technology-related articles. Read by thought-leaders and decision-makers around the world.","tagline":"The World’s Leading AI and Technology Publication","domain":"pub.towardsai.net","slug":"towards-artificial-intelligence","isAuroraEligible":true,"isAuroraVisible":false,"viewerEdge":{"__ref":"CollectionViewerEdge:collectionId:98111c9905da-viewerId:lo_cbe4fe29de94"},"canToggleEmail":false},"UserViewerEdge:userId:e1995df315cb-viewerId:lo_cbe4fe29de94":{"id":"userId:e1995df315cb-viewerId:lo_cbe4fe29de94","__typename":"UserViewerEdge","isFollowing":false,"isUser":false},"User:e1995df315cb":{"id":"e1995df315cb","__typename":"User","name":"Anirudh Chandra","username":"wazzup-ani","bio":"|| Civil servant || Story teller || Data science enthusiast ||","imageId":"1*7eO0vsaZr8uYqEb8TTnsVQ.png","mediumMemberAt":0,"isPartnerProgramEnrolled":false,"viewerEdge":{"__ref":"UserViewerEdge:userId:e1995df315cb-viewerId:lo_cbe4fe29de94"},"viewerIsUser":false,"newsletterV3":null,"customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"wazzup-ani.medium.com"}},"hasSubdomain":true,"postSubscribeMembershipUpsellShownAt":0},"Post:7ff1ab58cff8":{"id":"7ff1ab58cff8","__typename":"Post","title":"Predicting Heart Failure Survival with Machine Learning Models — Part I","mediumUrl":"https:\u002F\u002Fpub.towardsai.net\u002Fpredicting-heart-failure-survival-with-machine-learning-models-part-i-7ff1ab58cff8","previewImage":{"__ref":"ImageMetadata:1*KBRYys-rO_HlD2XGt00ckw.jpeg"},"isPublished":true,"firstPublishedAt":1598313663352,"readingTime":10.726415094339623,"statusForCollection":"APPROVED","isLocked":true,"visibility":"LOCKED","collection":{"__ref":"Collection:98111c9905da"},"creator":{"__ref":"User:e1995df315cb"},"previewContent":{"__typename":"PreviewContent","isFullContent":false}},"ImageMetadata:1*rE-uw8goXI-p4qNEHWWWLA.png":{"id":"1*rE-uw8goXI-p4qNEHWWWLA.png","__typename":"ImageMetadata","focusPercentX":null,"focusPercentY":null},"UserViewerEdge:userId:90a4cd0da51c-viewerId:lo_cbe4fe29de94":{"id":"userId:90a4cd0da51c-viewerId:lo_cbe4fe29de94","__typename":"UserViewerEdge","isFollowing":false,"isUser":false},"NewsletterV3:d30297792fb1":{"id":"d30297792fb1","__typename":"NewsletterV3","type":"NEWSLETTER_TYPE_AUTHOR","slug":"90a4cd0da51c","name":"90a4cd0da51c","collection":null,"user":{"__ref":"User:90a4cd0da51c"}},"User:90a4cd0da51c":{"id":"90a4cd0da51c","__typename":"User","name":"Edoardo Romani","username":"edo-romani1","newsletterV3":{"__ref":"NewsletterV3:d30297792fb1"},"bio":"Strategy & Analytics professional based in London, UK. Enjoyed one of my articles? Connect with me on LinkedIn:https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Fedoardo-romani\u002F","imageId":"1*9JcWhqjB8pAziRA5g6mPXA.jpeg","mediumMemberAt":1595402267000,"isPartnerProgramEnrolled":true,"viewerEdge":{"__ref":"UserViewerEdge:userId:90a4cd0da51c-viewerId:lo_cbe4fe29de94"},"viewerIsUser":false,"customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"edo-romani1.medium.com"}},"hasSubdomain":true,"postSubscribeMembershipUpsellShownAt":0},"Post:962be7b348ce":{"id":"962be7b348ce","__typename":"Post","title":"Developing a simple Udemy online course tracker with Tableau","mediumUrl":"https:\u002F\u002Fedo-romani1.medium.com\u002Fdeveloping-a-simple-udemy-online-course-tracker-with-tableau-962be7b348ce","previewImage":{"__ref":"ImageMetadata:1*rE-uw8goXI-p4qNEHWWWLA.png"},"isPublished":true,"firstPublishedAt":1600636881944,"readingTime":2.0965408805031447,"statusForCollection":null,"isLocked":true,"visibility":"LOCKED","collection":null,"creator":{"__ref":"User:90a4cd0da51c"},"previewContent":{"__typename":"PreviewContent","isFullContent":false}},"ImageMetadata:0*6LqRJqfgGafAYgGA":{"id":"0*6LqRJqfgGafAYgGA","__typename":"ImageMetadata","focusPercentX":null,"focusPercentY":null},"UserViewerEdge:userId:380da45435d3-viewerId:lo_cbe4fe29de94":{"id":"userId:380da45435d3-viewerId:lo_cbe4fe29de94","__typename":"UserViewerEdge","isFollowing":false,"isUser":false},"NewsletterV3:51c63443de13":{"id":"51c63443de13","__typename":"NewsletterV3","type":"NEWSLETTER_TYPE_AUTHOR","slug":"380da45435d3","name":"380da45435d3","collection":null,"user":{"__ref":"User:380da45435d3"}},"User:380da45435d3":{"id":"380da45435d3","__typename":"User","name":"Ramya Vidiyala","username":"ramyavidiyala","newsletterV3":{"__ref":"NewsletterV3:51c63443de13"},"bio":"Interested in computers and machine learning. Likes to write about it | https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Framya-vidiyala\u002F","imageId":"1*xPXsyK7aXOuVPDpA2laGog.jpeg","mediumMemberAt":0,"isPartnerProgramEnrolled":true,"viewerEdge":{"__ref":"UserViewerEdge:userId:380da45435d3-viewerId:lo_cbe4fe29de94"},"viewerIsUser":false,"customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"ramyavidiyala.medium.com"}},"hasSubdomain":true,"postSubscribeMembershipUpsellShownAt":0},"Post:37caa2796cd9":{"id":"37caa2796cd9","__typename":"Post","title":"Topic Modelling on NYT articles using Gensim, LDA","mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Ftopic-modelling-on-nyt-articles-using-gensim-lda-37caa2796cd9","previewImage":{"__ref":"ImageMetadata:0*6LqRJqfgGafAYgGA"},"isPublished":true,"firstPublishedAt":1623180167722,"readingTime":6.435849056603773,"statusForCollection":"APPROVED","isLocked":true,"visibility":"LOCKED","collection":{"__ref":"Collection:7f60cf5620c9"},"creator":{"__ref":"User:380da45435d3"},"previewContent":{"__typename":"PreviewContent","isFullContent":false}},"ImageMetadata:0*Dj2kfLv07TGdHiG4.jpg":{"id":"0*Dj2kfLv07TGdHiG4.jpg","__typename":"ImageMetadata","focusPercentX":null,"focusPercentY":null},"UserViewerEdge:userId:51e9f7436218-viewerId:lo_cbe4fe29de94":{"id":"userId:51e9f7436218-viewerId:lo_cbe4fe29de94","__typename":"UserViewerEdge","isFollowing":false,"isUser":false},"NewsletterV3:97a13ca851c1":{"id":"97a13ca851c1","__typename":"NewsletterV3","type":"NEWSLETTER_TYPE_AUTHOR","slug":"51e9f7436218","name":"51e9f7436218","collection":null,"user":{"__ref":"User:51e9f7436218"}},"User:51e9f7436218":{"id":"51e9f7436218","__typename":"User","name":"Kirtipurohit","username":"kirtipurohit025","newsletterV3":{"__ref":"NewsletterV3:97a13ca851c1"},"bio":"Programmer | Technical content Writer | Lives in India | Wanna go where I can breathe freedom","imageId":"2*mUw_SayitXlvp9BSv_gMRg.jpeg","mediumMemberAt":0,"isPartnerProgramEnrolled":false,"viewerEdge":{"__ref":"UserViewerEdge:userId:51e9f7436218-viewerId:lo_cbe4fe29de94"},"viewerIsUser":false,"customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"kirtipurohit025.medium.com"}},"hasSubdomain":true,"postSubscribeMembershipUpsellShownAt":0},"Post:ec7ea0c2a3f3":{"id":"ec7ea0c2a3f3","__typename":"Post","title":"Linux-Python Modules for Data Analysis Installation and basics with Jupyter NoteBook","mediumUrl":"https:\u002F\u002Fkirtipurohit025.medium.com\u002Flinux-python-modules-for-data-analysis-installation-and-basics-with-jupyter-notebook-ec7ea0c2a3f3","previewImage":{"__ref":"ImageMetadata:0*Dj2kfLv07TGdHiG4.jpg"},"isPublished":true,"firstPublishedAt":1596816736331,"readingTime":1.8367924528301887,"statusForCollection":null,"isLocked":false,"visibility":"PUBLIC","collection":null,"creator":{"__ref":"User:51e9f7436218"},"previewContent":{"__typename":"PreviewContent","isFullContent":false}},"ImageMetadata:1*KFujX6iiYrzH5C8bm7JW3g.png":{"id":"1*KFujX6iiYrzH5C8bm7JW3g.png","__typename":"ImageMetadata","focusPercentX":null,"focusPercentY":null},"UserViewerEdge:userId:d88bd4c178bb-viewerId:lo_cbe4fe29de94":{"id":"userId:d88bd4c178bb-viewerId:lo_cbe4fe29de94","__typename":"UserViewerEdge","isFollowing":false,"isUser":false},"User:d88bd4c178bb":{"id":"d88bd4c178bb","__typename":"User","name":"Kishor Shankaranarayan","username":"ksalmamater","bio":"Learning & Development specialist with diverse experience and a strong focus on talent development across businesses.","imageId":"1*wGKnXfQV1e6DX_y-ngJcPg.png","mediumMemberAt":0,"isPartnerProgramEnrolled":false,"viewerEdge":{"__ref":"UserViewerEdge:userId:d88bd4c178bb-viewerId:lo_cbe4fe29de94"},"viewerIsUser":false,"newsletterV3":null,"customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"ksalmamater.medium.com"}},"hasSubdomain":true,"postSubscribeMembershipUpsellShownAt":0},"Post:56b6c6f1963e":{"id":"56b6c6f1963e","__typename":"Post","title":"Getting into the world of Data Science","mediumUrl":"https:\u002F\u002Fksalmamater.medium.com\u002Fgetting-into-the-world-of-data-science-56b6c6f1963e","previewImage":{"__ref":"ImageMetadata:1*KFujX6iiYrzH5C8bm7JW3g.png"},"isPublished":true,"firstPublishedAt":1595142830281,"readingTime":5.959433962264151,"statusForCollection":null,"isLocked":false,"visibility":"PUBLIC","collection":null,"creator":{"__ref":"User:d88bd4c178bb"},"previewContent":{"__typename":"PreviewContent","isFullContent":false}},"PostViewerEdge:postId:af816aaea61-viewerId:lo_cbe4fe29de94":{"id":"postId:af816aaea61-viewerId:lo_cbe4fe29de94","__typename":"PostViewerEdge","catalogsConnection":null},"User:a71060a2ef24":{"id":"a71060a2ef24","__typename":"User","name":"Anne Bonner"},"Collaborator:af816aaea61-a71060a2ef24":{"id":"af816aaea61-a71060a2ef24","__typename":"Collaborator","user":{"__ref":"User:a71060a2ef24"},"state":"visible"}}</script><script src="https://cdn-client.medium.com/lite/static/js/manifest.4d02ee36.js"></script><script src="https://cdn-client.medium.com/lite/static/js/72022.edf7eee5.js"></script><script src="https://cdn-client.medium.com/lite/static/js/main.8b688db3.js"></script><script src="https://cdn-client.medium.com/lite/static/js/45573.4354ed57.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/instrumentation.4fd6ad3a.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/reporting.950d4050.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/1752.a348f767.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/7794.9590314e.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/48996.0c1a6c43.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/75221.81c0ae68.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/33928.8ae59af2.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/47464.d71003d1.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/95472.20329d15.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/40043.994e879b.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/27497.109a4f26.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/46929.e058aba2.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/97332.f6bdcfe7.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/46836.89ad2df0.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/7321.5802990d.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/70449.7324b5e0.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/88246.a4eb47a9.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/15248.a435ee12.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/28491.30f554c4.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/10887.8c699586.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/21205.3b8682cc.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/37346.c744a48a.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/24883.521f79ea.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/66451.4286c8a9.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/91743.6d65042d.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/96277.a0e68f58.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/50082.3bb93a5f.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/76705.4adc19b5.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/14603.9da6d15d.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/4261.761f57f2.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5892.1bd40c03.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/98453.4185c7d5.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/50020.e2a89974.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/39483.2d01cc2f.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/Post.1a092fe3.chunk.js"></script><script>window.main();</script><script defer="" src="https://static.cloudflareinsights.com/beacon.min.js/v652eace1692a40cfa3763df669d7439c1639079717194" integrity="sha512-Gi7xpJR8tSkrpF7aordPZQlW2DLtzUlZcumS8dMQjwDHEnw9I7ZLyiOj/6tZStRBGtGgN6ceN6cMH8z7etPGlw==" data-cf-beacon="{&quot;rayId&quot;:&quot;6e09dc5fee3224bd&quot;,&quot;token&quot;:&quot;0b5f665943484354a59c39c6833f7078&quot;,&quot;version&quot;:&quot;2021.12.0&quot;,&quot;si&quot;:100}" crossorigin="anonymous"></script>
</body></html>